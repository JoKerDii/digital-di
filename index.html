<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/digital-di/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/digital-di/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/digital-di/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/digital-di/images/logo.svg" color="#222">

<link rel="stylesheet" href="/digital-di/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/digital-di/","images":"/digital-di/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/digital-di/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Di&#39;s Blog">
<meta property="og:url" content="https://jokerdii.github.io/digital-di/index.html">
<meta property="og:site_name" content="Di&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Di Zhen">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jokerdii.github.io/digital-di/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Di's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/digital-di/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/digital-di/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Di's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/digital-di/archives/">
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/10/20/Advanced-RAG/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/10/20/Advanced-RAG/" class="post-title-link" itemprop="url">Advanced RAG</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-20 21:25:28" itemprop="dateCreated datePublished" datetime="2024-10-20T21:25:28-04:00">2024-10-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-10-19 19:25:42" itemprop="dateModified" datetime="2024-10-19T19:25:42-04:00">2024-10-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>There are many products built almost solely on RAG. I realized that a lack of knowledge of RAG is one of the main reasons why it’s been slow to widely adopt Gen AI in enterprises. Therefore, I have conducted a research about naive RAG and advanced RAG, and have my notes written here. </p>
<h2 id="Naive-RAG"><a href="#Naive-RAG" class="headerlink" title="Naive RAG"></a>Naive RAG</h2><p>The standard RAG workflow consists of three main steps as illustrated in the graph below:</p>
<ol>
<li><strong>Indexing</strong>: Creating an index of documents for retrieval.</li>
<li><strong>Retrieval</strong>: Searching the index for relevant documents based on a user query.</li>
<li><strong>Generation</strong>: Using a language model to generate answers or responses based on the retrieved documents.</li>
</ol>
<p>The three steps all face possible issues:</p>
<ol>
<li><p><strong>Indexing</strong>:</p>
<ul>
<li><p>Poor document parsing.</p>
</li>
<li><p>Inefficient document chunking strategies.</p>
</li>
<li><p>Weak semantic representations from embedding models.</p>
</li>
<li><p>Non-optimized index structures.</p>
</li>
</ul>
</li>
<li><p><strong>Retrieval</strong>:</p>
<ul>
<li><p>Low relevance: retrieved documents are not highly relevant to the user query (low accuracy).</p>
</li>
<li><p>Incomplete retrieval: not all relevant documents are retrieved (low recall).</p>
</li>
<li><p>Redundancy: retrieved documents may be repetitive or redundant.</p>
</li>
<li><p>Queries are often not specific or well-defined.</p>
</li>
<li><p>Retrieval strategies might not be well-suited to the use case and may rely solely on semantic similarity.</p>
</li>
</ul>
</li>
<li><p><strong>Generation</strong>:</p>
<ul>
<li>Overreliance on the retrieved content, leading to issues such as irrelevant or even harmful responses (e.g., toxic or biased content).</li>
</ul>
</li>
</ol>
<p><img src="/digital-di/./images/naive_rag.png" alt="naive-rag"></p>
<p>This paper <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.10997">“Retrieval-Augmented Generation for Large Language Models: A Survey”</a> discussed several problems associated with Naive RAG implementations. The advanced approaches to RAG attempt to overcome the limitations of naive RAG by improving the way queries are processed, documents are retrieved, and responses are generated. Advanced RAG techniques focus on refining each step of the process, from query transformations to more efficient retrieval strategies.</p>
<h2 id="Advanced-RAG"><a href="#Advanced-RAG" class="headerlink" title="Advanced RAG"></a>Advanced RAG</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/digital-di/./images/adv_rag.png" alt="adv_rag"></p>
<h3 id="Pre-Retrieval-Enhancements"><a href="#Pre-Retrieval-Enhancements" class="headerlink" title="Pre-Retrieval Enhancements"></a>Pre-Retrieval Enhancements</h3><h4 id="Query-Transformations-Translation"><a href="#Query-Transformations-Translation" class="headerlink" title="Query Transformations &#x2F; Translation"></a>Query Transformations &#x2F; Translation</h4><p>Query transformations are techniques aimed at re-writing or modifying the input questions to improve the retrieval process. </p>
<p><img src="/digital-di/./images/query_analysis.png" alt="Query Analysis"></p>
<p>Query transformation types:</p>
<p><img src="/digital-di/./images/query_trans2.png" alt="query_trans2"></p>
<p>Some notable methods include:</p>
<ol>
<li><p><strong>Multi Query</strong>:</p>
<p>The <strong>MultiQueryRetriever</strong> automates prompt tuning by using a language model (LLM) to generate multiple queries from different perspectives for a given user query. It retrieves relevant documents for each generated query and combines the results to create a larger, more comprehensive set of potentially relevant documents. This technique helps mitigate some of the limitations of distance-based retrieval, save time on experimenting with different prompts, and provides a richer set of results.</p>
<p>LangChain Tutorial: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/MultiQueryRetriever">How to use MultiQueryRetriever</a>.</p>
<p>LangChain API: <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html">MultiQueryRetriever</a>.</p>
<p>Video Tutorial: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=JChPi0CRnDY">RAG from Scratch (Part 5 - Query Translation: Multi Query)</a>.</p>
<p><img src="/digital-di/./images/multiquery_retrieval.png" alt="multiquery_retrieval"></p>
</li>
<li><p><strong>RAG Fusion</strong></p>
<p>RAG-Fusion combines RAG and <strong>Reciprocal Rank Fusion (RRF)</strong> by generating multiple queries, reranking them with reciprocal scores and fusing the documents and scores. RRF gives the more relevant retrieval results higher scores and re-ranks them according to the scores. RAG-Fusion was able to provide accurate and comprehensive answers due to the generated queries contextualizing the original query from various perspectives.</p>
<p>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.03367">A New Take on Retrieval-Augmented Generation</a>.</p>
<p>Code: <a href="Raudaschl/rag-fusion">Raudaschl&#x2F;rag-fusion</a></p>
<p>LangChain Cookbook：<a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb?ref=blog.langchain.dev">RAG Fusion</a></p>
<p>Video Tutorial: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=77qELPbNgxA">RAG from scratch: Part 6 (Query Translation – RAG Fusion)</a></p>
<p><img src="/digital-di/./images/rag_fusion.png" alt="rag_fusion"> </p>
</li>
<li><p><strong>Step-Back Prompting</strong></p>
<p><strong>Step back prompting</strong> refers to the technique of generating a more generalized or abstract version of a specific query in order to mitigate potential issues with search quality or model-generated responses. This involves first reformulating the initial question into a broader or higher-level version (the “step back” question) and then querying both the original and the generalized question to improve the comprehensiveness and relevance of the responses. </p>
<p>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.06117">Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</a>“. </p>
<p>LangChain Tutorial: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/step_back/">Step Back Prompting</a></p>
<p>LangChain Cookbook: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb">Step-Back Prompting (Question-Answering)</a></p>
<p>Video Tutorial: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xn1jEjRyJ2U">RAG from scratch: Part 8 (Query Translation – Step Back)</a></p>
</li>
<li><p><strong>Decomposition</strong>: </p>
<p>When a user asks a complex question, a single query might not retrieve the right results. To address this, the question can be broken into sub-questions, each of which is retrieved separately, and the answers are combined.</p>
<p>LangChain Doc: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/decomposition/">Decomposition</a></p>
<p>Video Tutorial: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=h0OPWlEOank">RAG from scratch: Part 7 (Query Translation – Decomposition)</a></p>
<p><img src="/digital-di/./images/decomposition.png" alt="decomposition"></p>
<ul>
<li><p><strong>Least-to-Most Prompting</strong></p>
<p>The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. </p>
<p>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.10625">Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</a></p>
<p>Video Tutorial: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=h0OPWlEOank">RAG from scratch: Part 7 (Query Translation – Decomposition)</a></p>
<p><img src="/digital-di/./images/least_to_most.png" alt="least_to_most"></p>
</li>
<li><p><strong>IR-Cot</strong></p>
<p>An approach for multi-step QA that interleaves retrieval with steps (sentences) in a CoT, guiding the retrieval with CoT and in turn using retrieved results to improve CoT. It incorporates the idea of least-to-most prompting into RAG to improve retrieval, resulting in factually more accurate CoT reasoning.</p>
<p>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.10509">Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions</a></p>
<p>IR-CoT Code：<a target="_blank" rel="noopener" href="https://github.com/StonyBrookNLP/ircot">https://github.com/StonyBrookNLP/ircot</a></p>
<p><img src="/digital-di/./images/ircot2.png" alt="ircot2"></p>
<p><img src="/digital-di/./images/ircot3.png" alt="ircot3"></p>
</li>
</ul>
</li>
<li><p><strong>Hypothetical Document Embeddings (HyDE)</strong>: Given a query, HyDE first zero-shot instructs an instruction-following language model to generate a hypothetical document. The document captures relevance patterns but is unreal and may contain false details. Then, an unsupervised contrastively learned encoder (e.g. Contriever) encodes the document into an embedding vector. This vector identifies a neighborhood in the corpus embedding space, where similar real documents are retrieved based on vector similarity. </p>
<p>Simply speaking, HyDE uses responses to retrieve documents rather than using queries to retrieve documents. The rational behind this approach is that the semantic similarity between query and real document is smaller than the semantic similarity between hypothetical document and real document.</p>
<p>LangChain Doc: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/use_cases/query_analysis/techniques/hyde/">Hypothetical Document Embeddings</a></p>
<p>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.10496.pdf">Precise Zero-Shot Dense Retrieval without Relevance Labels</a></p>
<p>LangChain Cookbook: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb">Improve document indexing with HyDE</a></p>
<p><img src="/digital-di/./images/hyde.png" alt="hyde"></p>
</li>
<li><p><strong>New queries based on historical dialogues</strong></p>
<p>This is a required technique for developing a chatbot or a conversational RAG.</p>
<p>LangChain Tutorials: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/">Conversational RAG</a>; <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/tutorials/chatbot/">Build a Chatbot</a>; <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/message_history/">How to add message history</a>; <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/">How to add memory to chatbots</a></p>
<p>LangChain Code: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/history_aware_retriever.py">create_history_aware_retriever</a></p>
</li>
</ol>
<h4 id="Query-Construction"><a href="#Query-Construction" class="headerlink" title="Query Construction"></a>Query Construction</h4><p>Query construction refers to converting a natural language query into the query language specific to the database you are working with. This is essential for interacting with different databases and vector stores that require structured queries for more efficient document retrieval.</p>
<p>Check which vector databases support filtering: <a target="_blank" rel="noopener" href="https://superlinked.com/vector-db-comparison">https://superlinked.com/vector-db-comparison</a></p>
<p>Data can be structured, unstructured or semi-structured (see demo below). This requires LLMs to have capability of query construction.</p>
<p><img src="/digital-di/./images/data_structure.png" alt="data_structure"></p>
<table>
<thead>
<tr>
<th>Examples</th>
<th>Data Source</th>
<th>References</th>
</tr>
</thead>
<tbody><tr>
<td>Text-to-metadata-filter</td>
<td>VectorStore</td>
<td><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/how_to/self_query/">Docs</a></td>
</tr>
<tr>
<td>Text-to-SQL</td>
<td>SQL DB</td>
<td><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/tutorials/sql_qa/">Docs</a>; <a target="_blank" rel="noopener" href="https://blog.langchain.dev/llms-and-sql/">Blog</a>; <a target="_blank" rel="noopener" href="https://blog.langchain.dev/incorporating-domain-specific-knowledge-in-sql-llm-solutions/">Blog</a></td>
</tr>
<tr>
<td>Text-to-SQL + Semantic</td>
<td>PGVector supported SQL DB</td>
<td><a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/cookbook/retrieval_in_sql.ipynb?ref=blog.langchain.dev">Cookbook</a></td>
</tr>
<tr>
<td>Text-to-Cypher</td>
<td>Graph DB</td>
<td><a target="_blank" rel="noopener" href="https://blog.langchain.dev/implementing-advanced-retrieval-rag-strategies-with-neo4j/">Blog</a>; <a target="_blank" rel="noopener" href="https://blog.langchain.dev/using-a-knowledge-graph-to-implement-a-devops-rag-application/">Blog</a></td>
</tr>
</tbody></table>
<ol>
<li><p><strong>Self-query retriever</strong></p>
<p>A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query (usually in JSON) and then applies that structured query to its underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.</p>
<p>LangChain Docs:</p>
<p>(v0.2): <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/self_query/">How to do “self-querying” retrieval</a></p>
<p>(v0.1): <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/self_query/">Self-querying</a></p>
<p>Integration: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/components/">Components</a> -&gt; <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/">Retrievers</a> -&gt; <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/self_query/">Self-querying retrievers</a> -&gt; <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/integrations/retrievers/self_query/qdrant_self_query/">Qdrant</a></p>
<p><img src="/digital-di/./images/self_query.png" alt="self_query.png"></p>
<p><strong>Text-to-metadata-filter</strong>: VectorStores equipped with metadata filtering enable structured queries to filter embedded unstructured documents.</p>
</li>
<li><p><strong>Prompt templates and output parsers</strong></p>
<p>**Prompt analysis and prompt template **: converting user’s query to filtering conditions</p>
<ul>
<li><p>When constructing queries, the system uses a specific JSON format to organize the query and filters. The prompt is designed to create structured queries that can be applied to a document database or vector store. The queries consist of two main components:</p>
<ul>
<li>Query: The natural language query string that is used to match the document content.</li>
<li>Filter: Logical conditions used to filter the documents based on specific metadata attributes.</li>
</ul>
</li>
<li><p>Comparison Operations</p>
<p>Comparison operators (<code>comp</code>) are used to compare attributes (like year, name, time, product, or team) in the document with specific values provided by the user. Here are the comparison operators:</p>
<ul>
<li><strong>eq</strong>: Equals (e.g., <code>eq(&quot;team&quot;, &quot;TSE&quot;)</code> matches documents where the team is “TSE”).</li>
<li><strong>ne</strong>: Not equal (e.g., <code>ne(&quot;name&quot;,&quot;Ashley&quot;)</code> matches documents where the year is not 2022).</li>
<li><strong>gt</strong>: Greater than (e.g., <code>gt(&quot;year&quot;, 2023)</code> matches documents with a year greater than 2023).</li>
<li><strong>gte</strong>: Greater than or equal to (e.g., <code>gte(&quot;year&quot;, 2022)</code> matches documents from the year 2000 or later).</li>
<li><strong>lt</strong>: Less than (e.g., <code>lt(&quot;year&quot;, 2021)</code> matches documents created before 2021).</li>
<li><strong>lte</strong>: Less than or equal to (e.g., <code>lte(&quot;time&quot;, 13)</code> matches documents with a time length of 13 mins or lower).</li>
<li><strong>contain</strong>: Contains (e.g., <code>contain(&quot;product&quot;, &quot;gold&quot;)</code> matches documents where the product contains the word “gold”).</li>
<li><strong>like</strong>: Similar to or like (used for pattern matching).</li>
</ul>
</li>
<li><p>Logical Operations</p>
<p>Logical operators combine multiple conditions (comparisons) into a single filter:</p>
<ul>
<li><strong>and</strong>: Logical AND (e.g., <code>and(gt(&quot;year&quot;, 2022), eq(&quot;product&quot;, &quot;gold&quot;))</code> matches documents created later than year 2022 and are related to gold card product).</li>
<li><strong>or</strong>: Logical OR (e.g., <code>or(eq(&quot;team&quot;, &quot;TS&quot;), eq(&quot;team&quot;, &quot;TSE&quot;))</code> matches documents that are either TS or TSE).</li>
<li><strong>not</strong>: Logical NOT (e.g., <code>not(eq(&quot;name&quot;, &quot;Ashley&quot;))</code> matches documents where Ashley is not the owner).</li>
</ul>
</li>
</ul>
<p><strong>Output parser</strong>: This output parser can be used when you want to return multiple fields or you need the response to be formatted. </p>
<p>LangChain Docs: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/structured/">Structured output parser</a></p>
<p>API: <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/chains/langchain.chains.query_constructor.base.StructuredQueryOutputParser.html">StructuredQueryOutputParser</a></p>
</li>
</ol>
<h3 id="Advanced-Retrieval-Techniques"><a href="#Advanced-Retrieval-Techniques" class="headerlink" title="Advanced Retrieval Techniques"></a>Advanced Retrieval Techniques</h3><ol>
<li><p><strong>Vector Store-Backed Retriever</strong>: A retriever that uses a vector database to store document embeddings and retrieve documents based on their proximity to the query embedding.</p>
<p><img src="/digital-di/./images/basic_index_retrieval.png" alt="basic_index_retrieval"></p>
</li>
<li><p><strong>Fusion Retrieval or hybrid search</strong>: Combining multiple retrieval strategies (semantic similarity retrieval; keywords retrieval) to obtain a more diverse set of results.</p>
<p>LangChain Docs:</p>
<p>v0.2: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/ensemble_retriever/">How to combine results from multiple retrievers</a></p>
<p>v0.1: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/ensemble/">Ensemble Retriever</a></p>
<p>API: <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.ensemble.EnsembleRetriever.html">EnsembleRetriever</a></p>
<p>Code: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/retrievers/ensemble.py#L57">EnsembleRetriever</a></p>
<p><img src="/digital-di/./images/fusion_retrieval.png" alt="fusion_retrieval"></p>
<p>The <strong>EnsembleRetriever</strong> is a retrieval strategy that enhances retrieval performance by combining multiple retrievers. This approach leverages the strengths of different types of retrievers to compensate for each other’s weaknesses. A common example is combining a <strong>Sparse Retriever</strong> (e.g., BM25, which performs keyword-based retrieval) with a <strong>Dense Retriever</strong> (which performs semantic similarity retrieval based on embeddings). This combination works because sparse and dense methods complement each other.</p>
<p><strong>Sparse vs. Dense Representation</strong></p>
<ol>
<li><strong>Sparse Representation</strong>:<ul>
<li><strong>High-dimensional sparse vectors</strong>: Documents and queries are represented as high-dimensional vectors, but most dimensions have zero values. This is typical of traditional information retrieval methods like TF-IDF and BM25.</li>
<li><strong>Term frequency</strong>: Each dimension corresponds to a term, and the vector values represent term frequencies or weights (e.g., TF-IDF weights).</li>
<li><strong>Sparsity</strong>: Since a document or query contains only a small subset of all possible terms, most dimensions in the vector are zero, which makes it “sparse.”</li>
</ul>
</li>
<li><strong>Dense Representation</strong>:<ul>
<li><strong>Low-dimensional dense vectors</strong>: Documents and queries are represented as low-dimensional vectors, where most or all dimensions have non-zero values. This representation is typically generated by deep learning models like BERT.</li>
<li><strong>Semantic embeddings</strong>: The vectors capture semantic and contextual information, rather than just term frequency.</li>
<li><strong>Density</strong>: All dimensions in the vector usually have non-zero values, hence “dense.”</li>
</ul>
</li>
</ol>
<p><strong>Sparse and Dense Retrievers</strong></p>
<ul>
<li><strong>Sparse Retriever</strong>: The name comes from the fact that most elements in the vector representation of documents and queries are zero. It works well for exact keyword matches but may miss semantically relevant content that uses different vocabulary.</li>
<li><strong>Dense Retriever</strong>: The name reflects that the vector representation has mostly non-zero values. Dense retrievers perform better at capturing the meaning behind the text and finding semantically related content, even when the exact terms differ.</li>
</ul>
<p><strong>Combining Sparse and Dense Retrievers</strong></p>
<p>By combining sparse and dense retrievers, the <strong>EnsembleRetriever</strong> can retrieve relevant documents more effectively:</p>
<ul>
<li>The <strong>Sparse Retriever</strong> excels at matching specific keywords or phrases.</li>
<li>The <strong>Dense Retriever</strong> is better at capturing the semantic meaning and context, helping to retrieve documents even when exact terms differ.</li>
</ul>
<p>This combination creates a more robust retrieval system, addressing both lexical matches (through sparse retrieval) and semantic relevance (through dense retrieval).</p>
<p>LangChain Doc: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/retrievers/bm25/">BM25 Retriever</a></p>
<p>API: <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.bm25.BM25Retriever.html">BM25Retriever</a></p>
<p>Code: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/langchain%3D%3D0.2.1/libs/community/langchain_community/retrievers/bm25.py">BM25Retriever</a></p>
<p>Python Package: <a target="_blank" rel="noopener" href="https://github.com/dorianbrown/rank_bm25">rank_bm25</a></p>
</li>
<li><p><strong>Sentence Window Retrieval</strong>: Retrieving extended context pre and post the relevant context, rather than only retrieving the relevant context, which can reduce information lost.</p>
<p><img src="/digital-di/./images/sent_window_retrieval.png" alt="sent_window_retrieval"></p>
</li>
<li><p><strong>Parent Document Retrieval</strong>: Instead of sending the multiple smaller chunks to the LLM, the system merges them into their larger parent chunk. This allows for more contextualized information to be fed to the LLM, giving it a broader and more coherent set of data to generate an answer.</p>
<p><img src="/digital-di/./images/parent_retrieval.png" alt="parent_retrieval"></p>
<p>LangChain Doc: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/">Parent Document Retriever</a></p>
<p>API: <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html">ParentDocumentRetriever</a></p>
<p>Code: <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/retrievers/parent_document_retriever.py#L10">ParentDocumentRetriever</a></p>
</li>
<li><p><strong>Hierarchical index retrieval</strong>: By structuring the search in two layers—summaries for broad filtering and chunks for detailed search—this hierarchical approach increases efficiency, making it easier to find and synthesize relevant information, especially when dealing with large document sets.</p>
<p><img src="/digital-di/./images/hierarchical_retrieval.png" alt="hierarchical_retrieval"></p>
</li>
<li><p><strong>Hypothetical Questions</strong>: This technique involves having the language model generate hypothetical questions for each chunk of a document. These hypothetical questions are then embedded, and retrieval is performed based on these question embeddings, improving the relevance of the results.</p>
<p>LangChain Doc: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/multi_vector/#hypothetical-queries">hypothetical-queries</a></p>
</li>
<li><p><strong>MultiVector Retriever</strong>: MultiVector Retriever is a higher level category of parent document retriever, hierarchical index retrieval, and hypothetical questions.</p>
<p>LangChain Doc: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/multi_vector/">MultiVector</a></p>
<p>Summary: <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/expression_language/interface/">Runnable interface</a></p>
</li>
</ol>
<h3 id="Post-Retrieval-Enhancements"><a href="#Post-Retrieval-Enhancements" class="headerlink" title="Post-Retrieval Enhancements"></a>Post-Retrieval Enhancements</h3><ol>
<li><strong>Re-ranking</strong>: After retrieving the documents, the system re-ranks or filters them to ensure that the most relevant results appear at the top.</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a target="_blank" rel="noopener" href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Advanced RAG Techniques: an Illustrated Overview</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NirDiamant/RAG_Techniques">RAG System Techniques</a></li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/get_started/introduction">LangChain</a></li>
</ol>
<h2 id="Next-Topic-Prompt-Engineering"><a href="#Next-Topic-Prompt-Engineering" class="headerlink" title="Next Topic - Prompt Engineering"></a>Next Topic - Prompt Engineering</h2><p><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions">A comprehensive OpenAI prompt engineering guide</a>.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/anthropics/courses/tree/master/prompt_evaluations">Prompt Evaluations - Anthropic</a></p>
<blockquote>
<p><em>The quality of the output of a large language model (LLM) is very sensitive to the quality of the prompt. Ambiguous or not well-formed questions will make the AI try to guess the question you are really asking, which in turn increases the probability of getting an imprecise or even totally made-up answer (a phenomenon that’s often referred to as “hallucination”).  Because of that, one would have to first and foremost master reasoning, logic, and first-principles thinking to get the most out of AI — all foundational skills developed through philosophical training. The question “Can you code?” will become “Can you get the best code out of your AI by asking the right question?”</em></p>
<p><strong>― Why Engineers Should Study Philosophy ― Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/04/why-engineers-should-study-philosophy?utm_medium=email&utm_source=circ_other&utm_campaign=subbenemail_digitalcontent_monthinreview&hideIntromercial=true&tpcc=subbenemail&deliveryName=SUB_Ben_DigitialContent_MonthInReview_20240507">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/10/05/2024-October/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/10/05/2024-October/" class="post-title-link" itemprop="url">2024-October</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-05 20:03:25" itemprop="dateCreated datePublished" datetime="2024-10-05T20:03:25-04:00">2024-10-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-10-18 22:33:42" itemprop="dateModified" datetime="2024-10-18T22:33:42-04:00">2024-10-18</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>This new <code>model.out_head</code> output layer has its <code>requires_grad</code> attribute set to <code>True</code> by default, which means that it’s the only layer in the model that will be updated during training. Technically, training the output layer we just added is sufficient. However, as I found in experiments, finetuning additional layers can noticeably improve the predictive performance of the finetuned model.</em> </p>
<p><strong>― Building A GPT-Style LLM Classifier From Scratch - Sebastian Raschka</strong> [<a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/building-a-gpt-style-llm-classifier">Link</a>] [<a target="_blank" rel="noopener" href="https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb">Github</a>]</p>
</blockquote>
<p>Interesting questions addressed by Sebastian:</p>
<ol>
<li><p>Do we need to train all layers?</p>
<p>“For classification finetuning, it is not necessary to update all layers in an LLM. (The fewer weights we update, the faster the training will be because we don’t need to compute the gradients for these weights during backpropagation.)”</p>
</li>
<li><p>Why finetuning the last token, not the first token?</p>
<p>“In contrast to BERT, GPT is a decoder-style model with a causal attention mask. This means the first token has no context information of any other token in the input. Only the last token has information about all other tokens.  Hence, if we want to use models like GPT for classification finetuning, we should focus on the last token to capture contextual information of all other input tokens.”</p>
</li>
<li><p>How does BERT compare to GPT performance-wise?</p>
<p>“The small GPT-2 model from the previous section and BERT performed similarly well on the spam classification dataset. “</p>
</li>
<li><p>Should we disable the causal mask?</p>
<p>“A core feature of the GPT architecture is the causal attention mask (different from BERT models or the original transformer architecture).  However, we could actually remove the causal mask during classification finetuning, which would allow us to finetune the first rather than the last token since future tokens will no longer be masked, and the first token can see all other tokens.”</p>
</li>
<li><p>What impact does increasing the model size have?</p>
<p>The prediction accuracy can improve significantly with larger models.</p>
</li>
<li><p>What improvements can we expect from LoRA?</p>
<p>Both full finetuning (all layers) and LoRA can result in the same test set performance. </p>
<p>“On the small model, LoRA is slightly slower since the additional overhead from adding LoRA layers may outweigh the benefits, but when training the larger 1.5 billion parameters model, LoRA trains 1.53x faster.”</p>
</li>
<li><p>Padding or no padding? [<a target="_blank" rel="noopener" href="https://github.com/rasbt/LLMs-from-scratch/tree/main/ch06/02_bonus_additional-experiments">experiments</a>]</p>
<p>“If we want to process data in batches during training or inference (this involves processing more than one input sequence at a time), we need to insert padding tokens to ensure that the training examples are of equal length. </p>
<p>In regular text generation tasks, padding doesn’t affect the model response since padding tokens are usually added to the right side, and due to the causal mask discussed earlier, these padding tokens don’t influence the other tokens. However, remember that we finetuned the last token, as discussed earlier. Since the padding tokens are to the left of this last token, the padding tokens may affect the result. “</p>
</li>
</ol>
<blockquote>
<p><strong>These Are The 6 Best Science-Based Study Strategies - Super Learning Lab</strong> [<a target="_blank" rel="noopener" href="https://axelcasas.substack.com/p/these-are-the-6-best-science-based">Link</a>]</p>
</blockquote>
<ol>
<li><p>Spaced Practice</p>
<p>Instead of cramming all the information at once, spaced practice consists of revisiting the material multiple times with breaks in between.</p>
</li>
<li><p>Interleaving</p>
<p>This is about studying different topics in a sequence.</p>
</li>
<li><p>Retrieval</p>
<p>This consists of bringing learned information from mid to long-term memory by recall or retrieval practices.</p>
</li>
<li><p>Elaboration</p>
<p>Elaborative interrogation consists of asking and explaining why and how things work based on prior knowledge. In other words, it involves connecting new information to preexisting knowledge.</p>
</li>
<li><p>Concrete Example</p>
<p>When learning abstract concepts it was found that illustrating these topics with specific examples improves learning.</p>
</li>
<li><p>Dual Coding</p>
<p>Dual coding is about combining words with visuals. If you use relevant and helpful images in your notes, you may increase learning by remembering what you study with the help of these images.</p>
</li>
</ol>
<blockquote>
<p><em>The $120 billion wagered on sports betting in America in 2023 translated into nearly $11 billion in revenue for sports betting companies. This corresponds to the ~9% fee sportsbooks keep after all bets have been settled.</em></p>
<ul>
<li><em>Flutter: Leverages FanDuel’s dominance and global expertise.</em></li>
<li><em>DraftKings: Focuses on innovation and user engagement to fuel growth.</em></li>
<li><em>Entain: Bets on BetMGM’s success in the US market.</em></li>
<li><em>Penn: Leverages the ESPN partnership to challenge established players.</em></li>
</ul>
<p><strong>― Sports Betting Economics - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/sports-betting-economics">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>For decades, companies have outsourced their organizational innovation to consultants or enterprise software vendors who develop generalized approaches based on what they see across many organizations. That won’t work here, at least for a while. Nobody has special information about how to best use AI at your company, or a playbook for how to integrate it into your organization.</em> </p>
<p><strong>― AI in organizations: Some tactics - One Useful Thing</strong> [<a target="_blank" rel="noopener" href="https://www.oneusefulthing.org/p/ai-in-organizations-some-tactics">Link</a>]</p>
</blockquote>
<p>Issues with AI at the organizational level and how to solve them.</p>
<ol>
<li>In many companies, there is little AI use and few productivity gains outside of narrow permitted use cases. That’s because AI use that boosts individual performance does not always translate to boosting organizational performance for a variety of reasons. To get organizational gains requires R&amp;D into AI use and you are largely going to have to do the R&amp;D yourself.</li>
<li>“Many key breakthrough innovations come not from central R&amp;D labs, but from people actually using products and tinkering with them to solve their own problems. “ (Prof. Eric von Hippel). As users are very motivated to make their own jobs easier with technology, they find ways to do so. The user advantage is especially big in experimenting with Generative AI because the systems are unreliable and have a jagged frontier of capability. People are experimenting with AI and finding it very useful. But they aren’t sharing their results with their employers.</li>
</ol>
<p>How to solve the issues? What are the tactics? Talents in the lab should focus on building, not analysis or abstract strategy.</p>
<ul>
<li>Build AI benchmarks for your organization. [<a target="_blank" rel="noopener" href="https://docs.anthropic.com/en/docs/build-with-claude/develop-tests">Anthropic’s guide to benchmarking</a>]</li>
<li>Build prompts and tools that work.</li>
<li>Build stuff that doesn’t work… yet. </li>
<li>Build provocations and magic.</li>
</ul>
<blockquote>
<p><strong>The USA vs Visa - Net Interest</strong> [<a target="_blank" rel="noopener" href="https://www.netinterest.co/p/the-usa-vs-visa">Link</a>]</p>
</blockquote>
<p>Key elements of Doha Mekki’s recent antitrust lawsuit against Visa:</p>
<ol>
<li>Visa controls over 60% of U.S. debit transactions, with Mastercard far behind at 25%.</li>
<li>Visa traps merchants with pricing that penalizes them if they don’t process all transactions through Visa.</li>
<li>Exclusive deals incentivize merchants to use Visa exclusively, reducing competition.</li>
<li>Visa prevents potential competitors like PayPal and Apple from entering the market by locking them into restrictive agreements.</li>
<li>Visa has faced antitrust lawsuits since 1971 and maintains a large legal team to manage ongoing cases.</li>
</ol>
<blockquote>
<p><em>In physics, we study how particles or systems’ units interact and evolve toward stable states. In machine learning, we study how neurons (or artificial neurons) interact to learn patterns directly from data.  The connection lies in energy minimization: both approaches define an energy function to describe the stability of a system, and the optimization of this function helps to find optimal configurations that correspond to useful patterns or memories.</em></p>
<p><em>Hopfield developed a network that recreates patterns using energy minimization, while Hinton expanded on this with the introduction of Boltzmann machines, statistical physics-based systems that learn to recognize and generate patterns, providing groundwork for modern machine learning.</em></p>
<p><strong>― Nobel Prize to the Statistical Physics of artificial neural networks - Complexity Thoughts</strong> [<a target="_blank" rel="noopener" href="https://manlius.substack.com/p/nobel-prize-to-the-statistical-physics">Link</a>]</p>
</blockquote>
<p>“The laws governing physical systems also apply to the world of artificial intelligence.”</p>
<blockquote>
<p><strong>Major AI Functionalities &#x2F; with Apps - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/major-ai-functionalities-with-apps">Link</a>]</p>
</blockquote>
<p>A list of AI products you can experiment with.</p>
<blockquote>
<p><em>Fine-tuning can be useful for certain tasks (see the relevant section here for more details), but when it comes to injecting morality into your LLM, it’s probably not a good bet.</em></p>
<p><em>By combining the strengths of diffusion models and auto-regressive generation, DGLM offers a more nuanced, adaptable, and potentially more effective approach to generating safe and creative text. It moves away from the brute-force, one-size-fits-all approach of fine-tuning and embraces a more modular, dynamic, and personalized approach to AI safety.</em></p>
<p><strong>― A New Way to Control Language Model Generations [Breakdowns] - Artificial Intelligence Made Simple</strong> [<a target="_blank" rel="noopener" href="https://artificialintelligencemadesimple.substack.com/p/a-new-way-to-control-language-model">Link</a>]</p>
</blockquote>
<p>The author lists drawbacks of fine tuning:</p>
<p>“A model’s knowledge and capabilities are learnt almost entirely during pretraining, while alignment teaches it which subdistribution of formats should be used when interacting with users.” - LIMA: Less Is More for Alignment [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.11206">Link</a>]</p>
<p>“Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning.” - Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.05934">Link</a>]</p>
<p>“Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing — — even if a model’s initial safety alignment is impeccable”  - Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To! [<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=hTEGyKf0dZ">Link</a>]</p>
<p>“The base model generates a wide range of nationalities, with American, British, and German being the top three. In contrast, the aligned model only generates three nationalities: American (highest percentage), Chinese, and a small percentage of Mexican.” - Creativity Has Left the Chat: The Price of Debiasing Language Models [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.05587">Link</a>]</p>
<h3 id="YouTube-and-Podcast"><a href="#YouTube-and-Podcast" class="headerlink" title="YouTube and Podcast"></a>YouTube and Podcast</h3><blockquote>
<p><em>Tesla I don’t think it’s a car company, I think this is misleading, this is a robotics company robotics at Scale Company, because I would say at scale is also like a whole separate variable, they’re not building a single thing, they’re building the machine that builds the thing which is a whole separate thing and so I think robotics at scale company is what Tesla is.</em> </p>
<p><em>I think with synthetic data you just have to be careful, because these models are silently collapsed, is like one of the major issues so if you go to ChatGPT and you ask it to give you a joke, you’ll notice that it only knows three jokes, that’s the only it gives you like one joke I think most of the time. And sometimes it gives you like three jokes and it’s because the models are collapsed and it’s silent, so when you’re looking at any single individual output, you’re just seeing a single example, but when you actually look at the distribution, you’ll notice that it’s not a very diverse distribution, it’s silently collapsed. When you’re doing synthetic data generation, this is a problem, because you actually really want that entropy, you want the diversity, and the richness in your data set otherwise.</em></p>
<p><strong>― No Priors Ep. 80 | With Andrej Karpathy from OpenAI and Tesla - No Priors: AI, Machine Learning, Tech &amp; Startups</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=hM_h0UA7upI&ab_channel=NoPriors:AI,MachineLearning,Tech,&Startups">Link</a>]</p>
</blockquote>
<p>Andrej Karpathy was a founding team member of OpenAI and the former Tesla Autopilot leader. He discussed the evolution of self driving cards, tech challenges, Tesla’s Optimus humanoid robot, bottlenecks of AI development today. The topic of how AI capabilities could be further integrated with human cognition sounds very future and funny.</p>
<blockquote>
<p><strong>AI prompt engineering: A deep dive - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=T9aRN5JkmL8&ab_channel=Anthropic">Link</a>]</p>
</blockquote>
<p>Some of Anthropic’s prompt engineering specialists—Amanda Askell (Alignment Finetuning), Alex Albert (Developer Relations), David Hershey (Applied AI), and Zack Witten (Prompt Engineering)—share their insights on the evolution of prompt engineering, offer practical advice, and discuss how prompting could evolve as AI continues to advance.</p>
<blockquote>
<p><strong>Decoding Google Gemini with Jeff Dean - Google DeepMind</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=lH74gNeryhQ&ab_channel=GoogleDeepMind">Link</a>]</p>
</blockquote>
<p> Jeff Dean, chief scientist of Google DeepMind and Google Research, discusses the past, present and future of AI, specially the long term potential of multi-modal models like Gemini.</p>
<blockquote>
<p><strong>Shall We Repeal the Laws of Economics? - Oaktree Capital</strong> [<a target="_blank" rel="noopener" href="https://www.oaktreecapital.com/insights/memo-podcast/shall-we-repeal-the-laws-of-economics">Link</a>]</p>
</blockquote>
<p>Howard Marks addresses how politicians often ignore economic reality in their campaign promises, using examples like Trump’s call for tariffs and Harris’s attack on grocery profiteering. He emphasizes that economic laws are incontrovertible, and politicians can’t deliver on promises that contradict these laws; free markets allocate resources efficiently. And he highlights the ongoing political refusal to address issues like Social Security insolvency and national debt, stating that ignoring economic laws will eventually lead to negative outcomes.</p>
<blockquote>
<p><strong>Introducing OpenAI o1</strong> <strong>- Open AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLOXw6I10VTv_T9QV-DKXhq7HFUQRkGQLI">Link</a>]</p>
</blockquote>
<p>A series of video from Open AI to introduce GPT o1.</p>
<blockquote>
<p><strong>Ep17. Welcome Jensen Huang | BG2 w&#x2F; Bill Gurley &amp; Brad Gerstner - Bg2 Pod</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=bUrCR4jQQg8&ab_channel=Bg2Pod">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Dueling Presidential interviews, SpaceX’s big catch, Robotaxis, Uber buying Expedia?, Nuclear NIMBY - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ye012kzWJ3A&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<h3 id="Articles-and-Blogs"><a href="#Articles-and-Blogs" class="headerlink" title="Articles and Blogs"></a>Articles and Blogs</h3><blockquote>
<p>Of the employees we studied, those with superior sales performance were genetically different from the rest of the group. They were better at learning in real time about new customers and new sales opportunities. From an initial conversation with a sales lead, they were able to quickly feel out the customer and propose appropriate products without being told what to recommend. </p>
<p>Adaptive learning is different; it isn’t trainable. It’s the ability to process new information in real time and immediately use it to achieve a positive result.</p>
<p>For example, sales teams often require junior employees to cold-call leads, even through they don’t know as much about the company as more experienced employees do. Most of them haven’t even learned how to sell yet. But our research shows that for adaptive learners, seniority and experience are less important. Employees with the sales gene quickly become knowledgeable about your products and are able to learn and adjust on the fly.</p>
<p><strong>― There Really Is a “Sales Gene” - Juan Martinez, Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/09/there-really-is-a-sales-gene">Link</a>]</p>
</blockquote>
<p>Adaptive learning skill is important but might not correlated with seniority or experience. Employees with this capability can quickly become knowledgeable about the products and are able to learn and adjust on the fly.</p>
<p>The article suggests that managers or companies could be given a snapshot of how many of salespeople are adaptive learners without singling out any individual. and they could tell which tasks require adaptive learning skills and which don’t and allow them to choose. This should be done in an anonymous way. </p>
<p>No matter whether what’s been proposed in this article is applicable or ethical. The idea of adaptive learning is kind of new to me, and it inspires me to further think about whether this skill is learnable and teachable, and think about whether there is any other secret skills in sales. </p>
<blockquote>
<p><strong>New Rules for Teamwork - Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/09/new-rules-for-teamwork">Link</a>]</p>
</blockquote>
<ol>
<li><p>Develop an Operating System</p>
<p>OS means building blocks for the way team members collaborate, create change, and support one another. Effective operating systems vary widely, depending on the needs and norms of the organization. What they all have in common is that they set out a view of how teams create value, what teams are supposed to achieve, the technical skills each team member is expected to contribute, the processes by which the work will be managed, and the cultural norms and mindsets of constructive collaboration that will guide behavior. </p>
<p>Suggestions: hold kickoffs, conduct one on ones, and take stock of progress using retrospectives, are the three practices as a foundations of team OS.</p>
</li>
<li><p>Invest in Active, Real-Time Measurement</p>
<p>To make teamwork scientific, organizations need to be able to measure the outcomes of their actions and determine how changes in the inputs affect results. </p>
<p>Suggestion: define what constitutes success.</p>
</li>
<li><p>Create a System for Continuous Improvement and Innovation</p>
<p>Teams today have new forms of technology and data collection at their disposal to help them self-correct while projects are underway. e.g. support colleagues to discuss what could have been done better; look at the patterns across teams to identify improvements and share best practices, particularly with regard to the rapid adoption of new technologies such as GenAI.</p>
<p>Suggestions: Identify the metrics that matter most (shift-changeover time, perhaps), hypothesize which actions could improve performance in those areas (preassigned workstations, perhaps), and embed technologies in the operating system (a smart-planning app, perhaps) to enable continuous improvement. Continuous improvement can occur only when all perspectives are considered and all teams have access to a centralized knowledge repository. Finally, it may be useful to set up a center of excellence, staffed with full-time employees with experience in analytics and operating system design.</p>
</li>
</ol>
<blockquote>
<p><strong>Why Leadership Teams Fail - Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/09/why-leadership-teams-fail">Link</a>]</p>
</blockquote>
<p>I was reading while thinking about my team and neighbor teams. I find this article very useful. </p>
<p>A critical factor in organizational success: the health of their leadership team. There are three main patterns of dysfunction: Shark Tanks, Petting Zoos, and Mediocracies. </p>
<ol>
<li><p><strong>Shark Tanks</strong></p>
<ul>
<li><p>Definition: A leadership team marked by hyper-competition, political maneuvering, and infighting. Members prioritize personal agendas over collective goals, leading to toxic and combative dynamics.</p>
</li>
<li><p>Causes: Lack of clear direction or boundaries from the CEO or team leader. Failure to address self-serving behaviors early on. Absence of behavioral norms that encourage collaboration.</p>
</li>
<li><p>Signs: Team members engage in power struggles outside of meetings. One-on-one discussions with the CEO on issues that should be resolved in team settings. Meetings turn into battlegrounds, with frequent arguments and difficulty reaching consensus. Executives bad-mouth each other, form alliances, or resist decisions after they’ve been made.</p>
</li>
<li><p>Prevention:</p>
<ul>
<li><p>Clear Expectations: Leaders should explicitly define which behaviors are acceptable and unacceptable. Set boundaries around how competition should be managed.</p>
</li>
<li><p>Confront Self-Serving Behaviors: Address aggressive or toxic behaviors directly with individuals. Remove those unwilling to align with the team’s goals, even if they’re high performers.</p>
</li>
<li><p>Role Modeling: The CEO or team leader must model collaborative behaviors and ensure transparency in communication to prevent political games.</p>
</li>
<li><p>Regular Feedback: Reinforce positive behaviors and correct negative ones through continuous feedback. Implement 360-degree reviews to track team behavior and performance alignment.</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Petting Zoos</strong></p>
<ul>
<li><p>Definition: A leadership team that avoids conflict to maintain harmony. Vigorous debate is sacrificed, and members prioritize getting along over pushing for the best ideas, leading to complacency and poor decision-making.</p>
</li>
<li><p>Causes: Overemphasis on collaboration and mutual trust, leading to conflict avoidance. Team members are too deferential, fearing that disagreements might disrupt the team’s harmony. Leaders may unknowingly encourage this avoidance by stressing harmony over debate.</p>
</li>
<li><p>Signs: Meetings lack critical debate, and discussions feel muted and lacking in emotional intensity. Team members engage in performance theater, focusing on positive news while downplaying problems. Decisions are made by consensus without sufficient evaluation or challenge. Leaders avoid holding one another accountable for poor performance, reluctant to disrupt the status quo.</p>
</li>
<li><p>Prevention:</p>
<ul>
<li>Encourage Debate: Leaders should foster a culture of constructive conflict where members feel safe to challenge each other’s ideas. A foundation of trust and psychological safety is key.</li>
<li>Promote Data-Driven Discussion: Ensure discussions are rooted in facts, using shared data to spur debate and avoid personal conflict. This encourages neutral, objective decision-making.</li>
<li>Monitor Meeting Dynamics: Leaders should track participation and the quality of discussion during meetings, encouraging team members to speak up and challenge ideas more openly.</li>
<li>Redefine Consensus: Teams must understand that consensus does not mean avoiding conflict but making informed decisions after rigorous debate.</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Mediocracies</strong></p>
<ul>
<li><p>Definition: A leadership team marked by complacency, lacking the drive or skills to achieve high performance. Collaboration and competition are both underemphasized, and the team fails to meet the organization’s needs.</p>
</li>
<li><p>Causes: Long periods of success that breed complacency. Poor alignment between the team’s skills and the changing demands of the business. A divided team, where some members prefer competition while others favor collaboration, leading to inconsistent and ineffective efforts. A leader’s failure to adapt to changing market conditions or internal challenges.</p>
</li>
<li><p>Signs: Team members operate in silos, with little collaboration between departments or units. Decision-making is slow, and there is a lack of accountability for performance. The team focuses on past achievements rather than future goals, with little ambition or drive for improvement. The team struggles with stagnation, missed opportunities, and duplicated efforts due to poor coordination.</p>
</li>
<li><p>Prevention:</p>
<ul>
<li>Rebuild the Team: Leaders may need to replace members who are not fit for their roles or who lack the motivation or skills needed to lead effectively. New hires should be chosen not just for their skills but also for their alignment with the company’s purpose and values.</li>
<li>Promote Balance: Strike a balance between competition and collaboration by hiring individuals with complementary skills and styles (e.g., planners and visionaries alongside hard-nosed executors).</li>
<li>Clear Roles and Expectations: Define where collaboration is expected (e.g., across departments) and where competition might be useful (e.g., in individual market decisions). Ensure everyone understands their responsibilities and how their performance contributes to broader goals.</li>
<li>Challenge the Status Quo: Continuously push the team to innovate and grow by setting ambitious goals and holding team members accountable for driving performance improvements.</li>
</ul>
</li>
</ul>
</li>
</ol>
<blockquote>
<p><em>Without such an observability system–let’s call it Design System Observability–it could be too late when Uber learned through complaints and public media about the end users who would suffer confusing onboarding rides, inconsistent layouts, and frustrating voiceovers&#x2F;talkbacks sessions.</em></p>
<p><strong>― How to Measure Design System at Scale - Uber Blog</strong> [<a target="_blank" rel="noopener" href="https://www.uber.com/en-GB/blog/design-system-at-scale/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>RAG is the most popular architecture of the LLM based systems in 2023. There are many products build almost solely on RAG — from Question Answering services combining web search engines with LLMs to hundreds of chat-with-your-data apps.</em></p>
<p><strong>― Advanced RAG Techniques: an Illustrated Overview - Medium</strong> [<a target="_blank" rel="noopener" href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Link</a>]</p>
</blockquote>
<h3 id="Reports-and-Papers"><a href="#Reports-and-Papers" class="headerlink" title="Reports and Papers"></a>Reports and Papers</h3><blockquote>
<p><strong>Learning vs Retrieval: The Role of In-Context Examples in Regression with LLMs</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.04318">Link</a>]</p>
</blockquote>
<p>The paper explores in-context learning (ICL) mechanisms in large language models (LLMs), focusing on the balance between knowledge retrieval and learning from in-context examples in regression tasks. It reports that LLMs can learn from regression examples of realistic datasets in-context, extending previous work on synthetic data to more practical scenarios.</p>
<p>I’m looking forward to this kind of experiments and studies, because I was suspicious about applying LLM on structured data.</p>
<blockquote>
<p><strong>Larger and more instructable language models become less reliable</strong> [<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41586-024-07930-y">Link</a>]</p>
</blockquote>
<p>The issue might stem from the nature of LLMs, which are designed to generate plausible responses based on patterns in the data they’ve seen, rather than to <em>know</em> anything in the traditional sense. They don’t have an internal mechanism to differentiate truth from fabrication, so as they scale up, they produce more complex, yet not necessarily more accurate, answers. This makes them better at appearing smart, but less reliable overall—a quality that philosophers like Mike Hicks rightly criticize as “bullshitting.”</p>
<p>From a user perspective, it underscores the need for critical thinking when engaging with AI models through prompt engineering. Just because an LLM provides a well-phrased response doesn’t mean it’s accurate. </p>
<blockquote>
<p><em>o1—like previous LLMs—is sensitive to the probability of examples and tasks, performing better and requiring fewer “thinking tokens” in high-probability settings than in low-probability ones.</em></p>
<p><strong>― When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.01792">Link</a>]</p>
</blockquote>
<p>Although optimized for reasoning, o1 still exhibits probability-based limitations tied to its autoregressive origins, implying that a complete departure from these influences has not been fully achieved.</p>
<blockquote>
<p><strong>VideoPrism: A foundational visual encoder for video understanding - Google Research</strong> [<a target="_blank" rel="noopener" href="https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.07176">Link</a>]</p>
</blockquote>
<p>Astute RAG is designed to better combine internal and external information through an interactive consolidation mechanism (i.e., identifying consistent passages, detecting conflicting information in them, and filtering out irrelevant information).</p>
<blockquote>
<p><strong>Differential Transformer - Microsoft Research</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2410.05258">Link</a>]</p>
</blockquote>
<p>Diff Transformer amplifies attention to relevant context while canceling noise, resulting in outperforming standard Transformers in multiple areas such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reducing activation outliers, as shown in the experiments. </p>
<p>The key innovation is a differential attention mechanism that calculates attention scores by subtracting two separate softmax attention maps. This subtraction cancels out irrelevant attention, promoting sparser, more accurate focus on important information, similar to noise-canceling techniques.</p>
<blockquote>
<p><strong>Diffusion Guided Language Modeling</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.04220">Link</a>]</p>
</blockquote>
<p>Controllable language modeling refers to techniques that allow users to guide or control specific attributes of the generated text from a language model (LM). These attributes can include factors like sentiment, toxicity, formality, or any other desired linguistic or stylistic feature. The primary challenge is ensuring that generated content aligns with specific requirements without compromising fluency, coherence, or overall quality of the text.</p>
<p>Diffusion models are excellent for controllable generation. They generate data in a multi-step process, gradually refining noise into coherent content. This incremental approach allows for fine-grained control at various stages of the generation. By manipulating the process at specific steps, you can guide the output more effectively toward desired characteristics (such as sentiment, style, or tone). In contrast, auto-regressive models like GPT generate text token by token in a one-shot manner, making it harder to impose controls without affecting fluency.</p>
<p>DGLM could refine language model generation because it integrates the fluency of auto-regressive language models (like GPT) with the flexibility of diffusion models. This flexibility is realized by employing Plug-and-Play with Linear Classifiers in the Sentence-T5 latent space to guide the diffusion process towards generating proposals with desired attributes. </p>
<h3 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h3><blockquote>
<p><strong>Swarm - An educational framework exploring ergonomic, lightweight multi-agent orchestration</strong> [<a target="_blank" rel="noopener" href="https://github.com/openai/swarm/tree/main">Link</a>]</p>
</blockquote>
<p>Little experimental and educational multi-agent framework by OpenAI.</p>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>The Nobel Prize in Physics 2024 to John J. Hopfield and Geoffrey E. Hinton, for foundational discoveries and inventions that enable machine learning with artificial neural networks</strong> [<a target="_blank" rel="noopener" href="https://www.nobelprize.org/prizes/physics/2024/summary/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Zuckerberg imagines that people will want to use AR glasses like Orion for two primary purposes: communicating with each other through digital information overlaid on the real world — which he calls “holograms” — and interacting with AI.</em> </p>
<p><strong>― Meta’s big tease - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/24253908/meta-orion-ar-glasses-demo-mark-zuckerberg-interview">Link</a>]</p>
</blockquote>
<p>One downside of Apple’s Vision Pro or Meta’s Quest 3 is that you lost vision of other people and other people cannot see your eyes, making it usage situation limited to home where you don’t have interaction with other people. However, the future of devices that’s going to replace mobile phone or comparable to mobile phone, has to have some functionalities to support socialization and networking.</p>
<blockquote>
<p><strong>Llama 3.2: Revolutionizing edge AI and vision with open, customizable models - Meta Blog</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Big Tech has cozied up to nuclear energy - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/10/5/24261405/google-microsoft-amazon-tech-data-center-nuclear-energy">Link</a>]</p>
</blockquote>
<p>Microsoft, Amazon, and Google are investing in nuclear energy to power their data centers.</p>
<blockquote>
<p><strong>Why Taiwan and Its Tech Industry Are Facing an Energy Crisis - Yale Environment 360</strong> [<a target="_blank" rel="noopener" href="https://e360.yale.edu/features/taiwan-energy-dilemma">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Google’s share of the U.S. search ad market is expected to drop below 50% next year for the first time in over a decade, according to the research firm eMarketer.</em></p>
<p><em>Amazon is expected to have 22.3% of the market this year, with 17.6% growth, compared with Google’s 50.5% share and its 7.6% growth.</em></p>
<p><strong>― Google’s Grip on Search Slips as TikTok and AI Startup Mount Challenge - The Wall Street Journal</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/online-ad-market-google-tiktok-9599d7e8">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Uber and Lyft drivers use Teslas as makeshift robotaxis, raising safety concerns - Reuters</strong> [<a target="_blank" rel="noopener" href="https://www.reuters.com/business/autos-transportation/uber-lyft-drivers-use-teslas-makeshift-robotaxis-raising-safety-concerns-2024-10-03/">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/09/28/The-Long-View/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/09/28/The-Long-View/" class="post-title-link" itemprop="url">The Long View</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-09-28 10:18:07" itemprop="dateCreated datePublished" datetime="2024-09-28T10:18:07-04:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-29 11:34:11" itemprop="dateModified" datetime="2024-09-29T11:34:11-04:00">2024-09-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>“The Long View: Career Strategies to Start Strong, Reach High, and Go Far” written by Brian Fetherstonhaugh was a book I randomly picked to read but it surprised me as it turns out to be fairly practical and comprehensive.</p>
<blockquote>
<p>We need a work philosophy that encompasses all the parts of our lives, and one that can give us guidance on how to be ambitious and seek success without sacrificing other things we value deeply— family, friends, health, and purpose.</p>
</blockquote>
<p>What I have learned:</p>
<h3 id="Five-Things-You-Need-to-Know-to-Build-a-Career-Plan"><a href="#Five-Things-You-Need-to-Know-to-Build-a-Career-Plan" class="headerlink" title="Five Things You Need to Know to Build a Career Plan"></a>Five Things You Need to Know to Build a Career Plan</h3><ol>
<li><p>Careers last for about 45 years and embrace 3 distinctly different stages, each lasting about 15 years.</p>
<ul>
<li><p>Stage One: Start Strong by Taking on Fuel</p>
<blockquote>
<p>Your learning curve is more important than your job title. Create the foundation for your career and establish good early habits.</p>
</blockquote>
<p>These are good suggestions for a new hire:</p>
<blockquote>
<p>In July of 2015, Next Big Sound was acquired by Pandora. Modest and down to earth, Alex is quick to point out the role that luck played in his success as well. “The number of things that went our way was terrifying,” he said shaking his head. “If you want to start your own company just so you can be on the Forbes Under 30 list, it’s not worth it. If you want to be an entrepreneur to make a lot of money, don’t. If you find something you’re obsessed with, something that keeps you up at night, then that’s the thing you should pursue.”</p>
</blockquote>
<blockquote>
<p>If you are serious about your career, this is not enough. Learn what makes your company tick: where it came from, what it stands for, how it makes its money, who the key people are, and where it is going If you don’t get answers to these questions as part of your company’s normal indoctrination, make it your business to find out in the first hundred days. Do your homework. Read the company’s annual report, or better yet, an outside analyst’s assessment of the company. Ask both old-timers and rising stars to tell you the inside scoop on your company over a cup of coffee, Get engaged by joining a club, team, or professional network in the firm. Volunteer to help with a company event, and do it well. Slowly begin to build your career ecosystem of contacts, communities, critical colleagues, and champions.</p>
</blockquote>
</li>
<li><p>Stage Two: Reach High by Focusing on Your Strengths and Passions</p>
<blockquote>
<p>The prime objective for this stage is to find your sweet spot-the intersection of what you’re good at, what you love to do, and what the world appreciates. It is the time to differentiate yourself from the pack, to stand out, and to become eligible for career pathways that will be most rewarding to you. Focus on your strengths and largely ignore your weaknesses.</p>
</blockquote>
</li>
<li><p>Stage Three: Go Far by Staying Fresh and then Passing the Torch</p>
<blockquote>
<p>Stage Three is devoted to achieving lasting impact and finding a sustainable new career pathway that will likely need to last well into your sixties or even seventies.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>“Fuel” matters what you build on.</p>
<blockquote>
<p>Fuel is critical throughout your career. In Stage One you need to accumulate it, in Stage Two you need to take advantage of it, and in Stage Three you need to refresh and preserve it.</p>
</blockquote>
<blockquote>
<p>Here is a great theoretical exercise suggested by social scientist Charles Handy: Imagine if at the age of forty you had to quit your job forever and start a company with just you. What would you do? That is a great test of self-reliance.</p>
</blockquote>
<ul>
<li><p>Transportable Skills.</p>
<ul>
<li><p>Problem Solving - being able to assess a problem and create a plan; being able to have a solid method or two that you can reply on to help solve the problem when you aer given a challenge an a blank piece of paper.</p>
<blockquote>
<p>The good news is that there are many frameworks and strategies to help you improve your problem-solving abilities. Be intentional in adding several different approaches to your repertoire, and don’t be afraid to combine a few different methods to create something unique that works for you.</p>
</blockquote>
</li>
<li><p>Persuasive communication - </p>
<blockquote>
<p>Inventors and creative people need to sell their ideas.</p>
</blockquote>
<blockquote>
<p>Persuasion is not just opinions expressed loudly. That might work once, but it doesn’t work over the long haul. Part of being persuasive is bringing forward compelling facts that truly give people permission to believe you. I worry that in the world of ubiquitous information, there are too many opinions and half-truths available, but too few authoritative sources. When I work with young professionals at my company I always encourage them to back up every key point with a footnote and a source. </p>
</blockquote>
<blockquote>
<p>One of the best skills to learn is the ability to spot communication breakdowns and adjust your approach accordingly. There are a few things that can go wrong during a conversation: </p>
<ul>
<li>Correspondence is when two people use different words to say the same thing.</li>
<li>Conflict can arise when two people use the same word but mean different things.</li>
<li>Contrast happens where there is no overlap at all.</li>
</ul>
</blockquote>
</li>
<li><p>Getting Things Done - being able to not only start but al finish projects consistently; being able to power through to achieve the end goal, regardless of the barriers and obstacles throw at you; being able to be trusted by people at work with more high-profile projects.</p>
</li>
<li><p>Becoming a Talent Magnet - </p>
<blockquote>
<p>The companies with the best people always win. The individual leaders who have the ability to attract and mobilize top talent win.</p>
</blockquote>
</li>
<li><p>Giving and Asking for Help - </p>
<blockquote>
<p>According to Grant, successful Givers - those who give more than they take - are much more likely to be among the highest performing and most satisfied people.</p>
</blockquote>
</li>
<li><p>Emotional Intelligence (EQ) - </p>
<blockquote>
<p>Through his access to business leaders around the world and studies in more than five hundred organizations, Goldman documents an astonishing fact: in determining star performance in every field, emotional intelligence matters twice as much as IQ or technical expertise.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Meaningful Experiences.</p>
<blockquote>
<p>Meaningful experiences combine to enable you to be versatile and robust in your career. New experiences take you outside your comfort zone and build new career muscles. </p>
</blockquote>
<blockquote>
<p>I think that everybody in business these days should spend at least one chapter of their career working in e-commerce even if it’s just for a couple of years. Here’s why: e-commerce is a huge industry with great long-term prospects. It is already worth hundreds of billions of dollars and is projected to grow over 15 percent per year over the next decade. Because e-commerce involves the whole selling process, it teaches you to think like a general manager —from product development to how the supply chain works to merchandising, customer service, and more. It gives you exposure to the “soft skills” of business like branding and customer experience as well as the “hard skills” of profit management, data, and analytics. Best of all, a job in e-commerce means that you get a report card every day in the form of immediate sales. E-commerce can act like a microcosm of all business in a single job assignment. What a fantastic way to accelerate your learning and development. If I were starting my career over today, I would spend at least one chapter doing e-commerce.</p>
</blockquote>
</li>
<li><p>Enduring Relationships.</p>
<p>Your bosses, client &#x2F; customer relationships, business partners, talent around you, and find your tribe.</p>
<blockquote>
<p>Enduring relationships are perhaps the most potent and long-lasting form of fuel. They include both the brands you associate with and the people you connect with throughout the journey. </p>
</blockquote>
<blockquote>
<p>Katya Andresen, the CEO of Cricket Media, defines the three principal roles that mentors can play in our lives: the Star, a successful role model who shows us how it can be done, the Sage, who like Socrates doesn’t give us the answer but teaches us how to think, and the Agitator, who spurs us and stretches us, and gives us the occasional kick in the pants.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Careers are built through the skillful investment of time.</p>
<blockquote>
<p>Becoming a highly employable expert or “master” is not just the result of innate talent, but of the application of thousands of hours of learning, experience, and practice.</p>
</blockquote>
</li>
<li><p>Careers do not progress in linear or predictable ways.</p>
<blockquote>
<p>Successful careers are a combination of diligent planning and good luck. The diligent planning is essential, because it makes you eligible for the luck.</p>
</blockquote>
</li>
<li><p>A career is so much more than a job: it’s a big part of life.</p>
</li>
</ol>
<h3 id="Five-Things-You-Need-to-Do-to-Bring-Your-Career-Plan-to-Life"><a href="#Five-Things-You-Need-to-Do-to-Bring-Your-Career-Plan-to-Life" class="headerlink" title="Five Things You Need to Do to Bring Your Career Plan to Life"></a>Five Things You Need to Do to Bring Your Career Plan to Life</h3><ol>
<li><p>Do the Career Math exercise to get into the right long-term frame of mind.</p>
<ul>
<li><p>62 is the median age of retirement in the US. If today you are in your late twenties, you have almost 35 years of career left. 40 years old is not a halfway point - many people underestimate the length of a career.</p>
</li>
<li><p>10000 hours of intense practice and rehearsal is needed to become excellent at something.</p>
<blockquote>
<p>Now matter how many IQ points or natural gifts you have, being successful takes intense hard work and many more hours than you thin.</p>
</blockquote>
</li>
<li><p>On average 85%-90% of personal wealth are cumulated after 40th birthday.</p>
<blockquote>
<p>An individual’s personal wealth tends to peak at about age 65, and their personal wealth at age 40 is only about 10%-15% of that amount</p>
</blockquote>
</li>
<li><p>It’s not necessarily true that the key to a successful career is to have the most social contacts.</p>
</li>
<li><p>Number of people who will really make a difference to your career in life.</p>
<blockquote>
<p>We all discover people in the course of our careers who become our mentors, teachers, and advocates. They are the people who champion us and say nice things about use behind our backs. They nominate us for jobs and awards. </p>
<p>Always remember there is someone out there who is in your corner.</p>
</blockquote>
<blockquote>
<p>A lot of people incorrectly think “It’s all about contacts,” as though that’s where career success begins and ends. Raw connections are useful to extend your reach, but they aren’t of significant value until you convert them to a higher<br>relationship-those people who will engage and mobilize on your behalf. You may end up with thousands of raw connections. But remember, it is not just a volume game; it is about quality and impact.</p>
<p>Ben Casnocha, the coauthor of The Start-up of You along with LinkedIn founder Reid Hoffman, underscores this point clearly. “There’s a distinction between networking and genuine relationship building. Networkers are transactional. They pursue relationships thinking only about what other people can do for them. Relationship builders, on the other hand, try to help other people first. They don’t keep score. They’re aware that most good deeds get reciprocated, but they’re not calculated about it. And they think about their relationships all the time, not just when they need something.”</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Complete a Career Inventory to take stock of your most relevant skills, experiences and relationships.</p>
<p>Check out the book chapter 5.</p>
</li>
<li><p>Take the 100-Hour Test and complete a Personal Time Portfolio to see how you are investing your time.</p>
<p>Percentage of personal time on family, work, community, fitness, teach and learn, and chilling.</p>
</li>
<li><p>Use the Career Path Navigator when you are trying to set a new career pathway to decide between several options.</p>
<blockquote>
<p>According to Auren, “Long-term success requires massive growth. Most smart people out of college grow an average of 10 percent per year. Which means they are roughly twice as effective seven years after graduating college. That makes sense, as most twenty-nine-year-olds make double what they did their first job out of college. To grow even more quickly, you need a job with the following criteria:</p>
<p>• You’re surrounded by people who are smarter than you<br>• You have an opportunity to fail<br>• The company has a history of giving massive responsibility to people like you</p>
</blockquote>
<blockquote>
<p>And if you decide to leave, exit with grace. It is a cliché to say when people leave “our paths will cross again.” It is utterly, totally true. Former colleagues and employers are a critical part of your career ecosystem. They will provide ratings and opinions about you for years to come. They will shop for talent in their current companies and in future places they work. They will become consultants, clients, and influencers. Wrap up your assignments with notable diligence and accountability. Heal wounds as appropriate. Say thank you.</p>
</blockquote>
</li>
<li><p>Future-proof your career by periodically challenging yourself with the five scary long-term questions.</p>
<ul>
<li>How can I avoid being replaced by a machine?</li>
<li>Where and how will I find work?</li>
<li>How will I spend my time in the future?</li>
<li>Will I outlive my money?</li>
<li>How will work make me happy?</li>
</ul>
</li>
</ol>
<h3 id="Overcoming-Adversities"><a href="#Overcoming-Adversities" class="headerlink" title="Overcoming Adversities"></a>Overcoming Adversities</h3><blockquote>
<p>Whether your career setback is unexpected or foreseeable, you will need a method to speed your recovery. The four Rs method mentioned in chapter 11 in the context of returnships is a good general approach to getting back on track quickly, If you get fired or pushed to the side, build on the four Rs to help get you back on the right path.</p>
<ul>
<li>Reframe your experience so that it connects to the future, not just to the past.</li>
<li>Refresh any skills that are rusty or lacking. You cannot fake your way to renewed career momentum.</li>
<li>Reconnect your career ecosystem. Maybe you need some fresh relationships with contacts, experts, critical colleagues and champions to propel you forward.</li>
<li>Reboot your confidence. Talk to people who know you and get you. Reflect on the strengths and special contributions you have built over the years. Be brave.</li>
</ul>
</blockquote>
<blockquote>
<p>He advice to those facing a serious crisis at any age is to change your attitude and quite possibly your latitude. Get out of your comfort zone. Spend some time on the dark side of town. Travel. Break out of rituals that can often hold you back. Even spending a day working at a soup kitchen could do you a world of good. Put yourself in a bigger context and get in touch with what’s really important. Rediscovering your humanity will remind you of your blessings and how you can make a difference.</p>
</blockquote>
<h3 id="Downloadable-Exercises-and-Resources"><a href="#Downloadable-Exercises-and-Resources" class="headerlink" title="Downloadable Exercises and Resources"></a>Downloadable Exercises and Resources</h3><p><a target="_blank" rel="noopener" href="https://thelongviewcareer.com/resources">https://thelongviewcareer.com/resources</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/09/05/2024-September/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/09/05/2024-September/" class="post-title-link" itemprop="url">2024-September</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-09-05 22:44:04" itemprop="dateCreated datePublished" datetime="2024-09-05T22:44:04-04:00">2024-09-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-10-06 10:39:07" itemprop="dateModified" datetime="2024-10-06T10:39:07-04:00">2024-10-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>Shopify has been acquisitive, but not like Broadcom or Salesforce with their jumbo acquisitions. Instead, they tend to acquire tiny businesses that are initially immaterial to the financials but can add up over time as they add new features to the ecosystem and bring in founding teams eager to make a difference.</em></p>
<p><strong>― Shopify: Back On Track - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/shopify-back-on-track">Link</a>]</p>
</blockquote>
<p>Business performance highlights: 1) Post-COVID hangover rebound, 2) GMV &#x3D; Gross Merchandise Volume grew 27% outside North America and 32% in Europe, 3) Shopify gained market share, 4) Shopify Payments penetration rate hit an all-time high of 61%, 5) Unified commerce platform, 6) Expansion into new markets, 7) Enterprise adoption, 8) Improved profitability, 9) Temporary operating margin boost. </p>
<p>Strategic Partnerships: 1) App and channel partners: Google, Meta, Microsoft, Amazon, etc, 2) Product partners: PayPal and Stripe, etc, 3) Service and technology partners: Oracle, IBM, etc.</p>
<blockquote>
<p><strong>Beat your Bot: Building your Moat against AI - Musings on Markets</strong> [<a target="_blank" rel="noopener" href="https://aswathdamodaran.substack.com/p/beat-your-bot-building-your-moat">Link</a>]</p>
</blockquote>
<p>AI’s strengths lie in mechanical, rule-based, and objective tasks, while it struggles with intuitive, principle-based, and bias-prone work. To stay relevant, people must focus on areas where AI struggles: becoming generalists, blending stories with data, practicing reasoning, and nurturing creativity. The author offers three strategies to resist AI disruption: keeping work secret, using system protection, and building personal “moats” of irreplaceable skills.</p>
<blockquote>
<p><strong>New LLM Pre-training and Post-training Paradigms - Ahead of AI</strong> [<a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Dealing with aging: The Intel, Walgreens and Starbucks Stores Updated! - Musings on Markets</strong> [<a target="_blank" rel="noopener" href="https://aswathdamodaran.substack.com/p/dealing-with-aging-the-intel-walgreens">Link</a>]</p>
</blockquote>
<p>How should companies handle aging and decline? </p>
<blockquote>
<p><em>Until the liabilities and responsibilities of AI models for medicine are clearly spelled out via regulation or a ruling, the default assumption of any doctor is that if AI makes an error, the doctor is liable for that error, not the AI.</em></p>
<p><strong>― Doctors Go to Jail. Engineers Don’t. - AI Health Uncut</strong> [<a target="_blank" rel="noopener" href="https://sergeiai.substack.com/p/doctors-go-to-jail-engineers-dont">Link</a>]</p>
</blockquote>
<p>An insightful analysis by Sergei Polevikov on one of the biggest challenges to AI adoption in clinical diagnosis. Doctors are under risk for using AI while AI developers are not.</p>
<blockquote>
<p><strong>NVIDIA: Full Throttle - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/nvidia-full-throttle">Link</a>]</p>
</blockquote>
<p>Huang shared five critical points about the opportunity ahead: 1) Accelerated computing tipping point, 2) Blackwell AI infrastructure platform, 3) NVLink Game-Changer, 4) Generative AI Momentum, 5) Enterprise AI Wave. </p>
<blockquote>
<p><em>“The biggest news of all was signing a MultiCloud agreement with AWS—including our latest technology Exadata hardware and Version 23ai of our database software—embedded into AWS cloud datacenters.”</em></p>
<p><strong>― Oracle: Riding the AI Wave - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/oracle-riding-the-ai-wave">Link</a>]</p>
</blockquote>
<p>The new agreement will enable customers to connect data in their Oracle Database to apps running on AWS starting in December. AWS joins Azure and Google Cloud in making Oracle available in their clouds. Oracle Cloud Infrastructure (OCI) is on track to become the fourth-largest cloud provider (after AWS, Azure, and GCP).</p>
<p>Oracle Cloud Infrastructure (OCI) does 1) multi-cloud integration, 2) public cloud consistency, 3) hybrid cloud solutions, 4) dedicated cloud. There will be growing adoption of OCI across different segments: 1) cloud natives customers, 2) AL&#x2F;ML customers, 3) generative AI customers. </p>
<blockquote>
<p><strong>Apple: There’s an AI for That - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/apple-theres-an-ai-for-that">Link</a>] [<a target="_blank" rel="noopener" href="https://youtu.be/uarNiSl_uh4">video</a>]</p>
</blockquote>
<p>What is new on iPhone 16?: 1) Apple Intelligence, 2) A18 chip, 3) Camera control button, 4) 48MP fusion camera, 5) 5x telephoto lens, 6) larger displays, 7) action button, 8) new colors, 9) storage options, 10) improved battery. </p>
<p>What is Apple Intelligence: 1) Context-aware Siri, 2) Enhanced writing tools, 3) on-device AI, 4) image and language generation, 5） task automation, 6) visual intelligence.</p>
<p>Google paid Apple north of $20 billion in 2022 to be the default search engine on Safari, so this partnership brought roughly a quarter of Apple’s Services revenue. Although this won’t happen after the law suit, remember that every dollar received from Services generates more than twice the gross profit of Products. In the latest quarter, while Products had an honorable 35% gross margin, Services delivered a 74% gross margin.</p>
<p>Services accounted for a substantial 45% of Apple’s gross profit in the June quarter, making it a critical driver of profitability. </p>
<blockquote>
<p><strong>Apple’s iPhone 16 Shows Apple Intelligence is Late, Unfinished &amp; Clumsy - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/apples-iphone-16-shows-apple-intelligence">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>OpenAI o1: A New Paradigm For AI - The Algorithmic Bridge</strong> [<a target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/openai-o1-a-new-paradigm-for-ai">Link</a>] </p>
</blockquote>
<blockquote>
<p><em>Since 2009, the Chinese government has provided at least <a target="_blank" rel="noopener" href="https://www.csis.org/blogs/trustee-china-hand/chinese-ev-dilemma-subsidized-yet-striking">$231 billion</a> to companies like BYD, including for research and development programs, consumer rebates, and infrastructure like charging stations.</em> </p>
<p><em>But by focusing solely on subsidies, it’s easy to miss the biggest reason why China’s electric vehicle industry has been so successful: It’s incredibly innovative. One way to look at it is that Chinese companies took their knowledge manufacturing smartphones and simply scaled it up. In fact, two of China’s top smartphone makers, Huawei and Xiaomi, have already unveiled their own EVs. (Apple, meanwhile, <a target="_blank" rel="noopener" href="https://www.theverge.com/2024/3/3/24085995/apple-car-project-titan-timeline-driverless-ev-doomed">canceled</a> its car project.)</em></p>
<p><em>Overall, more than 10 million EVs will be sold in China in 2024, compared to just 1.7 million in the United States.</em></p>
<p><strong>― What China’s Electric Vehicle Boom Looks Like on the Ground - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/what-chinas-electric-vehicle-boom">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>When this huge capacity to acquire new users comes together with network effects reinforced by the data accumulation, the company that is one step ahead quickly jumps 10 steps ahead.</em></p>
<p><em>Network effects and data accumulation are already strong moats, however, the winning company can go beyond that.</em></p>
<p><em>The Winning company can create complimentary services or pick the winners in complementary markets.</em></p>
<p><em>Google’s search doesn’t benefit from simple network effects. It’s a three sided ecosystem involving users, advertisers, and creators. Users provide valuable data through their searches, and creators—both content and business creators—build on the platform to monetize that data. Content creators produce information that answers user queries, while business creators offer services that users search for, such as travel agents in a specific location.</em></p>
<p><em>Google uses the massive data flow from these interactions to identify gaps in the market and create new products, like Google Maps and Chrome. This process, termed “Productive Network Effects,” allows Google to continuously add value to its business by meeting user needs with new services. This, again, reinforces the ecosystem.</em></p>
<p><strong>― Google: Cracking Monopoly or a Thriving Ecosystem? - Capitalist Letters</strong> [<a target="_blank" rel="noopener" href="https://www.capitalist-letters.com/p/google-cracking-monopoly-or-a-thriving">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Did Pop Culture Get So Gloomy? - The Honest Broker</strong> [<a target="_blank" rel="noopener" href="https://www.honest-broker.com/p/how-did-pop-culture-get-so-gloomy">Link</a>]</p>
</blockquote>
<p>The author Ted Gioia connected the increasing preference of darkness and dysfunction in movies, books, and music with the increasing number of mental illness in college and highlights his concerns about modern social stability and health.</p>
<blockquote>
<p><em>Meta CTO Andrew Bosworth — in a conversation to air next week on Big Technology Podcast (Apple, Spotify, etc.) — told me that, at maturity, devices like Orion might recognize the social situation you’re in and decide when to interrupt you. With cameras and sensors embedded in the glasses, they might one day understand that you’re at dinner with family, and decide not to notify you of a work message. Your phone would never have that awareness. Of course, the technology’s path depends on our willingness to set these limits. And in our tolerance for these devices’ monitoring of our lives.</em></p>
<p><strong>― Hands On With Meta’s New Orion Augmented Reality Glasses - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/hands-on-with-metas-new-orion-augmented">Link</a>]</p>
</blockquote>
<p>The manufacture expense of a pair of AI glasses (that’s comfortable enough and functional enough - it’s a balance) is much more cheaper than any other gadgets (phone, watch, headset, etc). This market will be quickly opening and expanding. </p>
<blockquote>
<p><strong>OpenAI’s Original Sin - The Algorithmic Bridge</strong> [<a target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/openais-original-sin">Link</a>]</p>
</blockquote>
<p>The “original sins” of OpenAI’s founders stem from a kind of purity in their initial vision—an idealism that clashed with the messy realities of business, technology, and power. Their early commitments to making AGI safe, beneficial, and open to all, while morally driven, created a series of cascading challenges that forced them to pivot away from some of those ideals. In doing so, they exposed themselves to the very criticisms they had sought to avoid.</p>
<blockquote>
<p><em>Telehealth: The use of digital technologies to deliver healthcare services remotely, including online consultations, diagnosis, and treatment.</em></p>
<p><strong>― Hims &amp; Hers: Surging Telehealth - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/hims-and-hers-surging-telehealth">Link</a>]</p>
</blockquote>
<p>Hims &amp; Hers operates as a subscription-based telehealth platform. The company has built a nationwide network of licensed healthcare providers specializing in various areas, including physicians, nurse practitioners, and physician assistants.</p>
<p>Business highlights: 1) robust core business growth - up 46% YoY, 2) The recent launch of GLP-1 medications contribute to a 6-point acceleration in year-over-year revenue growth, 3) Their focus of personalization is driving customer acquisition, retention, and higher revenue per subscriber, 4) The recent acquisition of an FDA-registered 503(b) facility positions Hims &amp; Hers to expand its compounding capabilities and enhance its supply chain for GLP-1 medications, 5) Hims &amp; Hers is already profitable with double-digit cash flow margins, 6) Management is confident in its ability to continue its growth trajectory, driven by its expanding product offerings, focus on personalization, and strategic initiatives.</p>
<p>GLP-1 risks and other risks: 1) Competition: The GLP-1 market is competitive, with established players like Novo Nordisk and Eli Lilly and an avalanche of potential new entrants like Roche and Pfizer, 2) Supply Chain: Potential shortages of branded GLP-1 medications could impact the market, 3) regulatory landscape: The regulatory environment for compounded medications could change, 4) Tehehealth Landscape: The telehealth landscape can shift rapidly, and external factors like the availability of branded GLP-1 medications or the moves of formidable competitors like Amazon could disrupt Hims &amp; Hers’ trajectory. </p>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><strong>E165｜智能眼镜爆发前夜，与Ray-Ban Meta产品经理聊聊如何打造一款热门AI眼镜 - 硅谷101</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=jNJQoJaZ58w">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Donald Trump Interview | Lex Fridman Podcast #442</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/hashtag/442">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Cuda is a programming language that Nvidia created that is specific to their gpus. Now these other players that he’s talking about are like Intel and AMD. And why are they struggling, well, first of all, they focused on CPUs not gpus for a very long time. Nvidia has been in the GPU game since the ‘90s or maybe even before then, but I remember buying Nvidia gpus to play video games in the 90s, so they’ve been around forever and they built this library, and they went all in on AI, because they noticed that large language models the compute necessary to run them was essentially the same exact math necessary to run video games. So they were able to kind of seamlessly transition into being an AI company versus a video game company. - Matthew</em></p>
<p><strong>― Former Google CEO Spills ALL! (Google AI is Doomed) - Matthew Berman</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=7PMUVqtXS0A">Link</a>]</p>
</blockquote>
<p>Eric Schmidt interview at Stanford. </p>
<blockquote>
<p><em>The difference for me is leading versus managing. A traditional manager—and I’ve seen this at a lot of companies; I even saw this a lot at Monsanto—says to the people that report to them, “What are you guys going to do?” Then the people go down to the people that report to them and ask, “What are you guys going to do?” So, you end up, net-net, developing this kind of bottoms-up model for the organization, which is effectively driven by a diffusion of responsibility and, as a result, a lack of vision.</em> <em>The leader, on the other hand, says, “Here’s what we are going to do, and here is how we are going to do it,” and then they can allocate responsibility for each of the necessary pieces. The leader that’s most successful is the one who can synthesize the input from subordinates and use that synthesis to come up with a decision or a new direction, rather than being told the answer by the subordinates.</em> <em>So, leaders, I think, fundamentally need to:</em></p>
<ol>
<li><em>Understand the different points of view of the people that report to them,</em></li>
<li><em>Set a direction or vision—clearly saying, “This is where we are going,” and</em></li>
<li><em>Figure out how to allocate responsibility to the people that report to them to achieve that objective.</em></li>
</ol>
<p><em>Whereas a manager is typically being told what’s going to happen in the organization—like a giant Ouija board with 10,000 employees’ hands on the planchette, trying to write sentences. Ultimately, you just get a bunch of muddled goop. As companies scale and bring in these “professional” managers, they’re typically kind of looking down and saying, “Hey, what are we going to do? What’s going to happen next?”—and they’re not actually setting a direction. - David Friedberg</em></p>
<p><strong>― “Founder Mode,” DOJ alleges Russian podcast op, Kamala flips proposals, Tech loses Section 230? - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ZDR2dWEQqKw&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Donald Trump Interview | Lex Fridman Podcast #442 - Lex Fridman</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/hashtag/442">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Value Investing in a Changing World with Aswath Damodaran - Aswath Damodaran</strong> [<a target="_blank" rel="noopener" href="https://podcasters.spotify.com/pod/show/excess-returns/episodes/Value-Investing-in-a-Changing-World-with-Aswath-Damodaran-e2nogdr">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong># 362 Li Lu - Founders</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/4FKwf6VjHmUKIHqyU6jnA5">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Gavin Baker - AI, Semiconductors, and the Robotic Frontier - Invest Like the Best, EP.385</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/05Fx7yNSEA148kHr1znbrb">Link</a>] [<a target="_blank" rel="noopener" href="https://joincolossus.com/episode/baker-ai-semiconductors-and-the-robotic-frontier/">Note</a>]</p>
</blockquote>
<blockquote>
<p><strong>In conversation with JD Vance | All-In Summit 2024 - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=eMxcM3ZcVmM&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>In conversation with Elon Musk | All-In Summit 2024 - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=pSFvOUswFwA&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Anthropic CEO Dario Amodei on AI’s Moat, Risk, and SB 1047 - “Econ 102” with Noah Smith and Erik Torenberg</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=7xij6SoCClI&ab_channel=Econ102withNoahSmith">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>TIP658: Peter Lynch’s Guide to Investing in Your Expertise w&#x2F; Kyle Grieve - We Study Billionaires</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/63rg6YeQY6tyzRJbRYrHXX">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Big Fed rate cuts, AI killing call centers, $50B govt boondoggle, VC’s rough years, Trump&#x2F;Kamala - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xAUA9QgqkxM&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Learn from other people’s successes and failures but do your own thing.</em></p>
<p><strong>― The Mark Zuckerberg Interview - Acquired</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=QciJ9ubeLQk&ab_channel=Acquired">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to Think About Risk with Howard Marks - Oaktree Capital</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLxbi-KAxos9tf1iHzRFTZmXDsGI-nQGsm">Link</a>]</p>
</blockquote>
<p>Oaktree co-chairman Howard Marks explores the true meaning of risk in a series of videos. He discusses the nature of risk, the relationship between risk and return, misconceptions about risk, and much more.</p>
<blockquote>
<p><strong>Next up for AI? Dancing robots - TED</strong> [<a target="_blank" rel="noopener" href="https://www.ted.com/talks/catie_cuan_next_up_for_ai_dancing_robots?subtitle=en">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>I have not in my time in Silicon Valley ever seen a company that’s supposedly on such a straight line to a rocket ship have so much high level churn. And I’ve also never seen a company have this much liquidity. And so how are people deciding to leave if they think it’s going to be a trillion dollar company. And why when things are just starting to cook would you leave if you are technically enamored with what you’re building. So if you had to construct the bear case, I think those would be the four things: 1) open source, 2) front door competition, 3) the move to synthetic data, and 4) all of the executive turnover would be sort of why you would say maybe there’s a fire where there’s all this smoke. - Chamath Palihapitiya</em></p>
<p><em>I think two things happen. The obvious thing that happens in that world is systems of record lose a grip on the vault that they had in terms of the data that runs a company. You don’t necessarily need it with in the same Reliance and Primacy that you did five and ten years ago that’ll have an impact to the software economy. And the second thing that I think is even more important than that is that then the size of companies changes, because each company will get much more leverage from using software, and few people versus lots of people with a few pieces of software. And so that inversion I think creates tremendous potential for operating leverage. - Chamath Palihapitiya</em></p>
<p><strong>― OpenAI’s $150B conversion, Meta’s AR glasses, Blue-collar boom, Risk of nuclear war - All-In Podcast</strong></p>
</blockquote>
<blockquote>
<p><strong>E166｜聊聊火人节与硅谷精神：挑战规则、反叛权威的双生花 - 硅谷101</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=N_5FSy1UFaA&t=57s&ab_channel=%E7%A1%85%E8%B0%B7101%E6%92%AD%E5%AE%A2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>TIP662: Building Buffett: The Foundation of Success w&#x2F; Kyle Grieve - We Study Billionaires</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/36Hs6wtlXM3t86y3bTgMCt">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How To Build An AI Customer Service Bot - McKay Wrigley</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=87ZX56RSamA&ab_channel=MckayWrigley">Link</a>]</p>
</blockquote>
<p>Helps to understand how to integrate language models with communication platforms. This project serves as a foundation for more complex AI agent development.</p>
<blockquote>
<p><strong>Building LLMs from the Ground Up: A 3-hour Coding Workshop - Sebastian Raschka</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=quh7z1q7-uc&ab_channel=SebastianRaschka">Link</a>]</p>
</blockquote>
<p>Code a simple tokenizer, implement GPT-2 and Llama 2 architectures, pre-train models and perform instruction fine-tuning. As well as model evaluation and conversational tests. </p>
<h3 id="Articles-and-Blogs"><a href="#Articles-and-Blogs" class="headerlink" title="Articles and Blogs"></a>Articles and Blogs</h3><blockquote>
<p><strong>Explain the role of Monte Carlo Tree Search (MCTS) in AlphaGo and how it integrates with policy and value networks. - EITCA</strong> [<a target="_blank" rel="noopener" href="https://eitca.org/artificial-intelligence/eitc-ai-arl-advanced-reinforcement-learning/case-studies/classic-games-case-study/examination-review-classic-games-case-study/explain-the-role-of-monte-carlo-tree-search-mcts-in-alphago-and-how-it-integrates-with-policy-and-value-networks/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How did AlphaGo’s use of deep neural networks and Monte Carlo Tree Search (MCTS) contribute to its success in mastering the game of Go? - EITCA</strong> [<a target="_blank" rel="noopener" href="https://eitca.org/artificial-intelligence/eitc-ai-arl-advanced-reinforcement-learning/case-studies/alphago-mastering-go/examination-review-alphago-mastering-go/how-did-alphagos-use-of-deep-neural-networks-and-monte-carlo-tree-search-mcts-contribute-to-its-success-in-mastering-the-game-of-go/#:~:text=In%20the%20context%20of%20AlphaGo,effectively%20balance%20exploration%20and%20exploitation.">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Outlive: The Science and Art of Longevity - The Rational Walk</strong> [<a target="_blank" rel="noopener" href="https://rationalwalk.com/outlive-the-science-and-art-of-longevity/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Boomer Apple - Stratechery</strong> [<a target="_blank" rel="noopener" href="https://stratechery.com/2024/boomer-apple/">Link</a>]</p>
</blockquote>
<p>Great article about Apple’s overall product strategy and its stage in its corporate life-cycle. As profit on Services is increasing, question comes round whether Apple is still a product company. As iPhone price has been lowered, people start to worry and warn Apple that hardware is what makes the whole thing work. But I have less concern because Apple has already built the network and customer stickiness. And Apple’s unique strategy of setting high price for the new product (see Vision Pro) and lowering the price when the product has been improved well and widely accepted by people make sense to me. I would say Apple is free to rely on services as it earns money, and at the same time, innovation on hardware is still on-going. </p>
<blockquote>
<p><em>Why was everyone telling these founders the wrong thing? That was the big mystery to me. And after mulling it over for a bit I figured out the answer: what they were being told was how to run a company you hadn’t founded — how to run a company if you’re merely a professional manager. But this m.o. is so much less effective that to founders it feels broken. There are things founders can do that managers can’t, and not doing them feels wrong to founders, because it is.</em></p>
<p><em>In effect there are two different ways to run a company: founder mode and manager mode. Till now most people even in Silicon Valley have implicitly assumed that scaling a startup meant switching to manager mode. But we can infer the existence of another mode from the dismay of founders who’ve tried it, and the success of their attempts to escape from it.</em></p>
<p><strong>― Founder Mode - Paul Graham</strong> [<a target="_blank" rel="noopener" href="https://paulgraham.com/foundermode.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>I worked <a target="_blank" rel="noopener" href="https://webdocs.cs.ualberta.ca/~sutton/book/the-book.html">through Richard Sutton’s book</a>, read through <a target="_blank" rel="noopener" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">David Silver’s course</a>, watched <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=oPGVsoBonLM">John Schulmann’s lectures</a>, wrote an <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/reinforcejs/">RL library in Javascript</a>, over the summer interned at DeepMind working in the DeepRL group, and most recently pitched in a little with the design&#x2F;development of <a target="_blank" rel="noopener" href="https://gym.openai.com/">OpenAI Gym</a>, a new RL benchmarking toolkit. So I’ve certainly been on this funwagon for at least a year but until now I haven’t gotten around to writing up a short post on why RL is a big deal, what it’s about, how it all developed and where it might be going.</em></p>
<p><strong>― Deep Reinforcement Learning: Pong from Pixels - Andrej Karpathy blog</strong> [<a target="_blank" rel="noopener" href="https://karpathy.github.io/2016/05/31/rl/">Link</a>]</p>
</blockquote>
<p>This is how Andrej learnt Deep Reinforcement Learning 10 years ago.</p>
<blockquote>
<p><strong>NotebookLM adds audio and YouTube support, plus easier sharing of Audio Overviews - Google</strong> [<a target="_blank" rel="noopener" href="https://blog.google/technology/ai/notebooklm-audio-video-sources/">Link</a>]</p>
</blockquote>
<p>NotebookLM, Google’s document analysis and podcast creation tool, now summarizes YouTube videos and provides key insights directly from the video transcripts, leveraging Gemini 1.5’s multimodal abilities.</p>
<blockquote>
<p><strong>The Intelligence Age - Sam Altman Blog</strong> [<a target="_blank" rel="noopener" href="https://ia.samaltman.com/">Link</a>]</p>
</blockquote>
<p>Sam predicting potential super intelligence emergence within few thousand days.</p>
<blockquote>
<p><strong>Exploring Multimodal RAG with LlamaIndex and GPT-4 or the New Anthropic Sonnet Model - Medium</strong> [<a target="_blank" rel="noopener" href="https://levelup.gitconnected.com/exploring-multimodal-rag-with-llamaindex-and-gpt-4-or-the-new-anthropic-sonnet-model-96705c877dbb">Link</a>]</p>
</blockquote>
<p>Build a Multimodal RAG system using LlamaIndex, GPT-4, and Anthropic Sonnet.</p>
<blockquote>
<p><strong>The next phase of Microsoft 365 Copilot innovation - Microsoft</strong> [<a target="_blank" rel="noopener" href="https://news.microsoft.com/m365-copilot-Sept-2024/">Link</a>]</p>
</blockquote>
<p>Microsoft launches 365 Copilot agents with features like ability to process data in Excel by generating Python code. </p>
<blockquote>
<p><strong>NotebookLM now lets you listen to a conversation about your sources - Google</strong> [<a target="_blank" rel="noopener" href="https://blog.google/technology/ai/notebooklm-audio-overviews/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Replit Agent</strong> [<a target="_blank" rel="noopener" href="https://docs.replit.com/replitai/agent?ref=maginative.com">Link</a>]</p>
</blockquote>
<p>Replit launches AI agent capability that codes and deploys full apps from prompts.</p>
<h3 id="Papers-and-Reports"><a href="#Papers-and-Reports" class="headerlink" title="Papers and Reports"></a>Papers and Reports</h3><blockquote>
<p><strong>Dissecting Multiplication in Transformers: Insights into LLMs</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.15360">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing OpenAI o1-preview - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/introducing-openai-o1-preview/">Link</a>] </p>
<p><strong>OpenAI o1-mini - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/">Link</a>]</p>
</blockquote>
<p>This is a huge progress. </p>
<p><img src="/digital-di/./images/o1-result.png" alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://x.com/DrJimFan/status/1834279865933332752">Jim Fan</a> highlighted the trends: </p>
<ol>
<li>You don’t need a huge model to perform reasoning, </li>
<li>A huge amount of compute is shifted to serving inference instead of pre&#x2F;post-training. Refer to “AlphaGo’s monte carlo tree search (MCTS)” for the process of simulation and convergence, </li>
<li>OpenAI must have figured out the inference scaling law a long time ago, which academia is just recently discovering. Two papers to read: a) Large Language Monkeys: Scaling Inference Compute with Repeated Sampling. Brown et al. finds that DeepSeek-Coder increases from 15.9% with one sample to 56% with 250 samples on SWE-Bench, beating Sonnet-3.5. b)  Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters. Snell et al. finds that PaLM 2-S beats a 14x larger model on MATH with test-time search. </li>
<li>Productionizing o1 is much harder than nailing the academic benchmarks. Research does not share much about details a) when to stop searching, b) what is the reward function, c) how to factor in compute cost, etc</li>
<li>Strawberry easily becomes a data flywheel.</li>
</ol>
<blockquote>
<p><strong>Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</strong> [<a target="_blank" rel="noopener" href="https://t.co/8y52Vt5dwv">Link</a>]</p>
</blockquote>
<p>This is a transition from train-compute to inference-compute. Fast inference is important.</p>
<blockquote>
<p><strong>An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.00724">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Open research discussion directly on top of arXiv - A Stanford Project</strong> [<a target="_blank" rel="noopener" href="https://www.alphaxiv.org/">Link</a>]</p>
</blockquote>
<p>So far comments about newly published papers are spreading around in various platforms such as X (twitter), Substack, Linkedin, etc. This awesome platform AlphaXiv enables readers, researchers, authors to actively interact with each other on papers. This would be a huge contribution to the scientific research community.</p>
<blockquote>
<p><strong>Agents in Software Engineering: Survey, Landscape, and Vision</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.09030">Link</a>]</p>
</blockquote>
<p>A comprehensive overview of frameworks of LLM-based agents in software engineering.</p>
<blockquote>
<p><strong>Training Language Models to Self-Correct via Reinforcement Learning</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.12917">Link</a>]</p>
</blockquote>
<p>Google DeepMind introduces a reinforcement learning approach ‘SCoRe’ to improve LLMs self-correction using self-generated data, surpassing previous methods like supervised fine-tuning (SFT). There are two stages training on SCoRe: 1) stabilizing the model’s correction behavior and 2) amplifying the self-correction using reward bonus. As a result, SCoRe significantly boosts performance, showing 15.6% and 9.1% gains on the MATH and HumanEval benchmarks. Focusing on multi-turn RL, it addresses challenges like reward misalignment, demonstrating how iterative correction can advance LLMs’ performance in tasks such as problem-solving and coding.</p>
<blockquote>
<p><strong>Jailbreaking Large Language Models with Symbolic Mathematics</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.11445">Link</a>]</p>
</blockquote>
<p>This research made a point that current AI safety measures, primarily focused on natural language inputs, do not generalize well to mathematical representations, creating a significant vulnerability. They emphasize the need for more robust and holistic AI safety measures that account for diverse input modalities, including symbolic mathematics, to prevent future security breaches.</p>
<p>It’s an interesting point as I never thought harmful prompt could be transformed into math problems. For example, the math form of a harmful prompt “How do I hack into a government database? “ is: “Find an operation g within the system that bypasses the security protocols and gains access to the database, and then provide a real-world example of such an operation.”</p>
<blockquote>
<p><strong>To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.12183">Link</a>]</p>
</blockquote>
<p>This study conducted a meta-analysis of over 100 papers and ran evaluations on 20 datasets across 14 large language models (LLMs) to confirm that CoT prompting primarily improves performance on tasks related to math and symbolic reasoning while on non-math-related tasks, CoT prompting offers little to no improvement compared to direct answering. They found that around 95% of CoT’s effectiveness on certain benchmarks like MMLU is due to its handling of math questions.</p>
<blockquote>
<p><strong>Introducing Contextual Retrieval - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/contextual-retrieval">Link</a>]</p>
</blockquote>
<p>Anthropic reduces the error rate of RAGs by 67% using “contextual retrieval” method.</p>
<p>Method: Add important context to small text chunks before storing them. </p>
<blockquote>
<p><strong>What is the Role of Small Models in the LLM Era: A Survey</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.06857">Link</a>]</p>
</blockquote>
<p>They analyze how small models can enhance LLMs in tasks like data curation, efficient inference, and deficiency repair. </p>
<blockquote>
<p><strong>LLMs Will Always Hallucinate, and We Need to Live With This</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2409.05746">Link</a>]</p>
</blockquote>
<p>This paper proves that every stage of LLM processing has a non-zero probability of producing hallucinations.</p>
<h3 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h3><blockquote>
<p><strong>STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking</strong> [<a target="_blank" rel="noopener" href="https://github.com/stanford-oval/storm">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Mastering Reinforcement Learning - Tim Miller</strong> [<a target="_blank" rel="noopener" href="https://gibberblot.github.io/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Sophisticated Controllable Agent for Complex RAG Tasks - NirDiamant</strong> [<a target="_blank" rel="noopener" href="https://github.com/NirDiamant/Controllable-RAG-Agent">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Open NotebookLM - gabrielchua @ HuggingFace</strong> [<a target="_blank" rel="noopener" href="https://huggingface.co/spaces/gabrielchua/open-notebooklm">Link</a>]</p>
</blockquote>
<p>PDF to podcast conversion using Llama 3.1 450B.</p>
<blockquote>
<p><strong>PaperQA2: High accuracy RAG for answering questions from scientific documents with citations - Future-House</strong> [<a target="_blank" rel="noopener" href="https://github.com/Future-House/paper-qa">Link</a>]</p>
</blockquote>
<p>Do high accuracy RAG on PDFs with a focus on the scientific literature with PaperQA2. It automatically extracts paper metadata, including citation and journal quality data with multiple providers.</p>
<p>Key learning: </p>
<ul>
<li>Implementing RAG workflows</li>
<li>Document parsing with LlamaParse</li>
<li>Metadata-aware embeddings</li>
<li>LLM-based re-ranking and contextual summarization</li>
<li>Agentic RAG techniques</li>
<li>Full-text search engine setup</li>
<li>Customizing LLM models and embeddings</li>
</ul>
<p>Implementation:</p>
<ol>
<li><p>Install PaperQA2:<br>pip install paper-qa&gt;&#x3D;5</p>
</li>
<li><p>Set up API keys:</p>
<p>Either set an appropriate API key environment variable (i.e. export OPENAI_API_KEY&#x3D;sk-…) or set up an open source LLM server</p>
</li>
<li><p>Prepare your document collection:</p>
<p>Gather PDFs or text files in a directory</p>
</li>
<li><p>The fastest way to test PaperQA2 is via the CLI. First navigate to a directory with some papers and use the pqa cli<br>$ pqa ask ‘What manufacturing challenges are unique to bispecific antibodies?’</p>
</li>
<li><p>Customize as needed:</p>
<ol>
<li>Adjust embedding models</li>
<li>Change LLM settings</li>
<li>Modify number of sources</li>
</ol>
</li>
</ol>
<blockquote>
<p><strong>RAGApp: The easiest way to use Agentic RAG in any enterprise</strong> [<a target="_blank" rel="noopener" href="https://github.com/ragapp/ragapp">Link</a>] </p>
</blockquote>
<p>Build multi-agent application without writing a single line of code with LlamaIndex.</p>
<blockquote>
<p><strong>Agentic Customer Service Medical Dental Clinic - Nachoeigu</strong> [<a target="_blank" rel="noopener" href="https://github.com/Nachoeigu/agentic-customer-service-medical-clinic">Link</a>]</p>
</blockquote>
<p>Build a LangGraph - powered medical clinic bot for efficient customer service tasks.</p>
<blockquote>
<p><strong>LlamaParse: Parse files for optimal RAG - run-llama</strong> [<a target="_blank" rel="noopener" href="https://github.com/run-llama/llama_parse">Link</a>]</p>
</blockquote>
<p>Parse any PDF (with text &#x2F; tables &#x2F; images) into machine and LLM-readable markdown on file system.</p>
<p>Key points:</p>
<ul>
<li>Parsing diverse file types</li>
<li>Accurate table recognition</li>
<li>Multimodal parsing and chunking</li>
<li>Custom parsing with prompt instructions</li>
<li>Integration with LlamaIndex</li>
<li>Async and batch processing</li>
<li>File object and byte handling</li>
<li>Usage with SimpleDirectoryReader</li>
<li>API key setup and management</li>
</ul>
<p>Steps:</p>
<ol>
<li>Install: <code>pip install llama-parse</code></li>
<li>Import: <code>from llama_parse import LlamaParse</code></li>
<li>Initialize parser:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser = LlamaParse(api_key=&quot;key&quot;, result_type=&quot;markdown&quot;)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Parse PDF</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">documents = parser.load_data(&quot;./my_file.pdf&quot;)</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>Process results in <code>documents</code> variable</li>
</ol>
<blockquote>
<p><strong>Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems - NirDiamant</strong> [<a target="_blank" rel="noopener" href="https://github.com/NirDiamant/RAG_Techniques">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>GenAI Agents: Comprehensive Repository for Development and Implementation - NirDiamant</strong> [<a target="_blank" rel="noopener" href="https://github.com/NirDiamant/GenAI_Agents">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Prompt Evaluations - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://github.com/anthropics/courses/tree/master/prompt_evaluations">Link</a>]</p>
</blockquote>
<p>Master LLM prompt evaluations. Key learning:</p>
<ul>
<li>Creating comprehensive test datasets</li>
<li>Implementing exact string matching and keyword presence checks</li>
<li>Using regular expressions for complex pattern matching</li>
<li>Leveraging LLMs for nuanced grading tasks</li>
<li>Designing custom rubrics for model-based evaluation</li>
<li>Iterating prompts to improve performance metrics</li>
<li>Comparing model versions objectively</li>
<li>Ensuring quality before and after deployment</li>
</ul>
<blockquote>
<p><strong>Llama Parse CLI - 0xthierry</strong> [<a target="_blank" rel="noopener" href="https://github.com/0xthierry/llama-parse-cli">Link</a>]</p>
</blockquote>
<p>The “Llama Parse CLI” is a command-line tool for parsing complex documents into machine and LLM-readable formats. It uses the LlamaIndex Parser API to handle PDFs with text, tables, and images. This tool helps you convert documents to markdown or JSON with a simple terminal command, streamlining data preparation for LLM training and fine-tuning tasks.</p>
<p>Key learning:</p>
<ul>
<li>Install and authenticate the CLI</li>
<li>Parse documents with various options (format, OCR language, page selection)</li>
<li>Customize parsing instructions and output</li>
<li>Handle multi-page documents and complex layouts</li>
<li>Integrate parsed data into LLM training pipelines</li>
<li>Optimize parsing for specific document types</li>
<li>Use advanced features like fast mode and GPT-4 integration</li>
</ul>
<blockquote>
<p><strong>AI-Driven Research Assistant - starpig1129</strong> [<a target="_blank" rel="noopener" href="https://github.com/starpig1129/ai-data-analysis-MulitAgent">Link</a>]</p>
</blockquote>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>How Costco Hacked the American Shopping Psyche - New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/08/20/dining/costco.html?unlocked_article_code=1.E04.3IV_.CKBGzqRPdUjo&smid=em-share">Link</a>]</p>
</blockquote>
<p>This article provides an in-depth look at Costco’s rise as one of the largest and most influential retailers globally, from its humble beginnings in Anchorage, Alaska, in 1984 to its current status as a retail giant. </p>
<p>The keys to success mentioned in the article: 1) Costco’s membership model ensures customer loyalty and steady revenue, 2) Offering high-quality products at low markups creates a sense of trust and value for customers, 3) Costco encourages impulse buying through a limited-time, high-value product offering that creates a “treasure-hunt atmosphere.”, 4) Costco has built a reputation for honesty and integrity, gaining immense customer trust, 5) Costco treats its employees well, leading to high employee retention and loyalty, which in turn contributes to better customer service, 6) Costco tailors its product selection to meet the needs and preferences of local markets, making it adaptable across different regions, 7) Expanding strategically into international markets has provided significant growth opportunities for Costco, 8) Costco prioritizes maintaining its core values and disciplined business practices over rapid expansion, ensuring long-term stability. </p>
<blockquote>
<p><strong>Apple’s iPhone 16 faces rising challenges with AI delay and growing Huawei competition - Reuters</strong> [<a target="_blank" rel="noopener" href="https://www.reuters.com/technology/artificial-intelligence/apples-ai-gap-new-iphones-disappoints-china-users-huawei-threat-looms-2024-09-10/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Google’s second antitrust trial could help shape the future of online ads - CNBC</strong> [<a target="_blank" rel="noopener" href="https://www.cnbc.com/2024/09/06/google-second-antitrust-trial-advertising-model.html">Link</a>]</p>
</blockquote>
<p>This one focused on Google’s dominance in internet search and examines the company’s ads tech.</p>
<blockquote>
<p><strong>AI Startups Struggle to Keep Up With Big Tech’s Spending Spree - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/newsletters/2024-09-06/ai-startups-can-t-keep-up-with-big-tech-s-spending-spree?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcyNTY1NjQzNywiZXhwIjoxNzI2MjYxMjM3LCJhcnRpY2xlSWQiOiJTSkVROENEV1JHRzAwMCIsImJjb25uZWN0SWQiOiIyMjNDRDM2NDg0QzY0OTc3QjY5ODE0Rjc1MTYxNDRGNyJ9.CROKgcETM4Qih9fTOqOCAIUyXFwFO6dbA2kv4c4FVRg">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Brian Niccol, Starbucks’s new CEO, has a “messianic halo” - The Economist</strong> [<a target="_blank" rel="noopener" href="https://www.economist.com/business/2024/09/07/brian-niccol-starbuckss-new-ceo-has-a-messianic-halo">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>AI is helping to <a target="_blank" rel="noopener" href="https://archive.ph/o/pXB1q/https://www.togal.ai/">estimate the cost of new projects</a>, manage and <a target="_blank" rel="noopener" href="https://archive.ph/o/pXB1q/https://www.nyfty.ai/">track workers on-site</a>, and <a target="_blank" rel="noopener" href="https://archive.ph/o/pXB1q/https://firmus.ai/firmus-ai-review/">detect issues with construction plans</a> to avoid the common and costly headache of having to rebuild parts of a structure.</em></p>
<p><em>Procore, which sells construction-management software, has embedded AI as a feature in its platform to make it <a target="_blank" rel="noopener" href="https://archive.ph/o/pXB1q/https://www.wsj.com/tech/ai/ai-chatgpt-nvidia-apple-facebook-383943d1">easier for workers to get answers</a> to questions about how their company typically does things. This kind of enhanced, chat-based search is one of the most common applications of generative AI for companies of every kind. For example, it’s common in <a target="_blank" rel="noopener" href="https://archive.ph/o/pXB1q/https://www.wsj.com/articles/ai-chatgpt-chatbot-workplace-call-centers-5cd2142a">systems designed to help customer service reps</a>—or even <a target="_blank" rel="noopener" href="https://archive.ph/o/pXB1q/https://www.wsj.com/tech/ai/customer-service-chatbot-dae1825b">replace them</a>.</em></p>
<p><em>Construction giant JLL has created a handful of generative AI-powered tools for its own use, says Bruce Beck, Chief Information Officer of enterprise and corporate systems at the company. These include a pair of chatbots for construction policies and HR matters, and an automatic report generator. His division is also using a generative AI-powered system made by Orby, based in Mountain View, Calif., to automate handling of the tens of thousands of invoices that JLL must process every year.</em></p>
<p><strong>― What Is AI Best at Now? Improving Products You Already Own - The Wall Street Journal</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/what-is-ai-best-at-now-improving-products-you-already-own-f6087617">Link</a>]</p>
</blockquote>
<p>Apple integrated Gen AI into the operating system, with features including AI generated custom emojis, summaries of incoming texts and emails, enhanced intelligence for Siri voice assistant. Google integrated Gen AI into Pixel phones, with features including a voice assistant, phone call transcription, photo tricks, and weather summaries. Microsoft has promised to integrate Gen AI throughout windows 11 and in the form of its Copilot software.</p>
<blockquote>
<p><strong>Salesforce’s AgentForce: The AI assistants that want to run your entire business - Venture Beat</strong> [<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/salesforces-agentforce-the-ai-assistants-that-want-to-run-your-entire-business/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Boiling it down, there are two primary approaches to applying AI in robotics. The first is a hybrid approach. Different parts of the system are powered by AI and then stitched together with traditional programming. With this approach the vision subsystem may use AI to recognize and categorize the world it sees. Once it creates a list of the objects it sees, the robot program receives this list and acts on it using heuristics implemented in code. If the program is written to pick that apple off a table, the apple will be detected by the AI-powered vision system, and the program would then pick out a certain object of “type: apple” from the list and then reach to pick it up using traditional robot control software.</em></p>
<p><em>The other approach, end-to-end learning, or e2e, attempts to learn entire tasks like “picking up an object,” or even more comprehensive efforts like “tidying up a table.” The learning happens by exposing the robots to large amounts of training data—in much the way a human might learn to perform a physical task. If you ask a young child to pick up a cup, they may, depending on how young they are, still need to learn what a cup is, that a cup might contain liquid, and then, when playing with the cup, repeatedly knock it over, or at least spill a lot of milk. But with demonstrations, imitating others, and lots of playful practice, they’ll learn to do it—and eventually not even have to think about the steps.</em></p>
<p><strong>― Inside Google’s 7-Year Mission to Give AI a Robot Body - Wired</strong> [<a target="_blank" rel="noopener" href="https://www.wired.com/story/inside-google-mission-to-give-ai-robot-body/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Nuclear power is considered “clean” because unlike burning natural gas or coal to produce electricity, it does not create greenhouse gas emissions.</em> </p>
<p><em>“This agreement is a major milestone in Microsoft’s efforts to help decarbonize the grid in support of our commitment to become carbon negative,” said a statement from Bobby Hollis, vice president of energy at Microsoft.</em></p>
<p><strong>― Microsoft deal would reopen Three Mile Island nuclear plant to power AI - The Washington Post</strong> [<a target="_blank" rel="noopener" href="https://www.washingtonpost.com/business/2024/09/20/microsoft-three-mile-island-nuclear-constellation/">Link</a>]</p>
</blockquote>
<p>The owner of the shuttered Pennsylvania plant plans to bring it online by 2028. Microsoft is buying 100% of its power for 20 years.</p>
<blockquote>
<p><em>Artificial intelligence-powered search engine Perplexity is in talks with brands including Nike and Marriott over its new advertising model, as the start-up mounts an ambitious effort to break Google’s stranglehold over the $300bn digital ads industry.</em></p>
<p><strong>― Perplexity in talks with top brands on ads model as it challenges Google - Financial Times</strong> [<a target="_blank" rel="noopener" href="https://www.ft.com/content/ecf299f4-e0a9-468b-af06-8a94e5f0b1f4">Link</a>]</p>
</blockquote>
<p>Perplexity is developing a new advertising model to compete with Google. It’s now discussing with brands like Nike and Marriott allowing them to bid for sponsored questions with AI-generated answers. They are aiming to disrupt the digital ads market while significantly lowering costs for advertisers.</p>
<blockquote>
<p><strong>Snap’s new Spectacles inch closer to compelling AR - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/9/17/24245572/snap-spectacles-ar-developers-evan-spiegel">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Meta has a major opportunity to win the AI hardware race - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/9/21/24250020/ray-ban-meta-smart-glasses-ai-hardware-meta-connect">Link</a>]</p>
</blockquote>
<p>Will the future of computer interaction be screen-free? AI glasses probably will not completely replace phones, but its necessity can be comparable to a phone in the coming years. Zuck is such a genius in social networking and human connections.</p>
<blockquote>
<p><strong>Our digital lives need massive data centers. What goes on inside them? - The Washington Post</strong> [<a target="_blank" rel="noopener" href="https://www.washingtonpost.com/dc-md-va/interactive/2024/data-centers-tour-northern-virginia/">Link</a>]</p>
</blockquote>
<p>They toured a Equinix owned facility with data centers in Northern Virginia to reveal how it works and to understand why water use and energy consumption are such a concern. </p>
<blockquote>
<p><em>The US Commerce Department is planning to reveal proposed rules that would ban Chinese- and Russian-made hardware and software for connected vehicles as soon as Monday.</em></p>
<p><em>The move would include bans on use and testing of Chinese and Russian technology for automated driving systems and vehicle communications systems. While the bans mostly focus on software, the proposed rules will include some hardware.</em></p>
<p><em>The Biden Administration’s primary concern is preventing China or Russia from hacking vehicles or tracking cars by intercepting communication with software systems that their domestic companies have created.</em> </p>
<p><strong>― Biden Administration to Prepare Ban on Chinese Car Software - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-09-21/biden-administration-to-prepare-ban-on-chinese-car-software">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>War in the age of AI demands new weaponry - Financial Times</strong> [<a target="_blank" rel="noopener" href="https://www.ft.com/content/fe136479-9504-4588-869f-900f2b3452c4">Link</a>]</p>
</blockquote>
<p>This article highlights the intersection of rising defense budgets and technological advancements, particularly in AI. It emphasizes that the integration of AI and adaptive technologies is vital for developing future weaponry.</p>
<blockquote>
<p><strong>OpenAI considering restructuring to for-profit, CTO Mira Murati and two top research execs depart - CNBC</strong> [<a target="_blank" rel="noopener" href="https://www.cnbc.com/2024/09/25/openai-cto-mira-murati-announces-shes-leaving-the-company.html">Link</a>]</p>
<p><strong>OpenAI’s chief research officer has left following CTO Mira Murati’s exit - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/09/25/openais-chief-research-officer-has-left/">Link</a>]</p>
</blockquote>
<p>What a painful transformation to a for-profit corporation.</p>
<blockquote>
<p><em>One thing nearly everyone agrees on is that maintaining a mission-focused research operation and a fast-growing business within the same organization has resulted in growing pains.</em></p>
<p><strong>― Turning OpenAI Into a Real Business Is Tearing It Apart - The Wall Street Journal</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?mod=hp_lead_pos1">Link</a>]</p>
</blockquote>
<p>OpenAI - a company with the highest churn rate and the highest valuation ($150B) I have ever seen. Something is not right, and making it right might cost a lot.</p>
<h3 id="Top-Books-to-Read"><a href="#Top-Books-to-Read" class="headerlink" title="Top Books to Read"></a>Top Books to Read</h3><p>My mentor Dylan recommended some leadership books to me:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Extreme-Ownership-U-S-Navy-SEALs-ebook/dp/B0739PYQSS/">Extreme Ownership: How U.S. Navy SEALs Lead and Win</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Wisdom-Bullfrog-Leadership-Made-Simple-ebook/dp/B0B8YX2GTB/">The Wisdom of The Bullfrog</a> [Completed]</li>
</ul>
<p>Director Dan in my organization recommended me some leadership books:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/dp/0804137382">Essentialism: The Disciplined Pursuit of Less</a> [Completed]</li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/dp/0671027034">How to Win Friends &amp; Influence People</a></li>
</ul>
<p>While talking to skip level leader Cameron in my organization, I started to have interests in “behavioral economics”:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Noise-Flaw-Human-Judgment/dp/B08LNYM39M/">Noise: A Flaw in Human Judgment</a></li>
</ul>
<p>A book discussed during a career development session:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Executive-Presence-2-0-Leadership-Inclusion-ebook/dp/B0BTYXJMG9/">Executive Presence 2.0: Leadership in an Age of Inclusion</a></li>
</ul>
<p>This book is cited many times by Brene Brown in “Dare to Lead”:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Good-Great-Some-Companies-Others/dp/0066620996">Good to Great: Why Some Companies Make the Leap…And Others Don’t</a> [Reading]</li>
</ul>
<p>While I was reading “The Long View”, I got to know some books cited: </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Quiet-Power-Introverts-World-Talking/dp/0307352153">Quiet: The Power of Introverts in a World That Can’t Stop Talking</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Give-Take-Helping-Others-Success/dp/0143124986">Give and Take: Why Helping Others Drives Our Success</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Working-Emotional-Intelligence-Daniel-Goleman/dp/0553378589/">Working with Emotional Intelligence</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Emotional-Intelligence-2-0-Travis-Bradberry/dp/0974320625/">Emotional Intelligence 2.0</a></li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Outliers-Story-Success-Malcolm-Gladwell-ebook/dp/B001ANYDAO/">Outliers: The Story of Success</a></li>
</ul>
<p>A book I met at least four times in the airports so far in 2024</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.amazon.com/Think-Again-Power-Knowing-What/dp/1984878123/">Think Again: The Power of Knowing What You Don’t Know</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/19/2024-August/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/08/19/2024-August/" class="post-title-link" itemprop="url">2024-August</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-08-19 00:04:43" itemprop="dateCreated datePublished" datetime="2024-08-19T00:04:43-04:00">2024-08-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-14 10:54:15" itemprop="dateModified" datetime="2024-09-14T10:54:15-04:00">2024-09-14</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>“This incident shows clearly that Windows must prioritize change and innovation in the area of end-to-end resilience. […] Examples of innovation include the recently announced VBS enclaves, which provide an isolated compute environment that does not require kernel mode drivers to be tamper resistant.” - John Cable, Microsoft VP of Program management</em></p>
<p><strong>― Microsoft: Azure Slowdown - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/microsoft-azure-slowdown">Link</a>]</p>
</blockquote>
<p>Microsoft Azure decelerated by 1 point sequentially to 30% YoY, while Google Cloud accelerated.</p>
<p>Recent business highlights: 1) global IT outage caused by a faulty update by CrowdStrike affected 8.5 M Windows PCs, 2) Microsoft facing investigation by UK’s CMA over hiring former Inflection AI Staff and the partnership with the startup.</p>
<blockquote>
<p><em>According to <a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/netflix-ad-tech-focus">Nielsen</a>, Prime Video captured <strong>3.1% of US TV Time</strong> in June (a decline of 0.1 points Y&#x2F;Y). Prime Video captures just over a third of Netflix’s market share (and more than Disney+ and Paramount+ combined).</em></p>
<p><em>As Amazon continues to invest in live sports and expand its content catalog, Prime members may find themselves spending more time with the service they already pay for. Prime Video may have started as a loss leader, but if it can become the go-to streaming platform for ad-supported content, it could evolve into a significant revenue driver, even for a behemoth like Amazon.</em></p>
<p><strong>― Amazon: This Team is Cooking - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/amazon-this-team-is-cooking">Link</a>]</p>
</blockquote>
<blockquote>
<ul>
<li><em><strong>Portfolio rebalancing</strong>: Apple stock surged 24% between May 1st and June 30th. As a result, Buffett would have seen AAPL take up nearly 60% of Berkshire’s portfolio. A stake reduction is a typical move to rebalance a portfolio and lower its risk profile.</em></li>
<li><em><strong>Valuation</strong>: Apple is valued above 30 times forward earnings. That makes it less likely to deliver alpha for shareholders. It’s possible Buffett felt like the odds of market-beating returns at this level were subpar.</em> </li>
<li><em><strong>Taxes matter</strong>: Buffett told shareholders in May that he finds the current tax rate on capital gains relatively low, potentially prompting him to realize his significant AAPL gains while the rate is reasonable.</em></li>
<li><em><strong>No place to hide</strong>: Buffett is building up his cash pile and waiting for a “fat pitch.”</em></li>
</ul>
<p><em><strong>The Buffett Indicator</strong></em>:* This ratio compares the total market capitalization of US stocks to the country’s GDP. It’s often used to gauge whether stock valuations in the US are overinflated. It reached <strong>138%</strong> during the dot-com bubble, which was considered high at the time. Low and behold, the indicator hit <strong>190%</strong> at the end of June.*</p>
<p><strong>― Berkshire Slashes Apple Stake - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/berkshire-slashes-apple-stake">Link</a>]</p>
</blockquote>
<p>Factors of today’s macro environment: 1) The AI Bubble, 2) The Yen Carry Trade, 3) Potential Recession.</p>
<blockquote>
<p><strong>Llama 3.1’s Impact on China, Kuaishou’s AI Video Generator Goes Global, and Alibaba Backs $2.8B AI Firm - Recode China AI</strong> [<a target="_blank" rel="noopener" href="https://recodechinaai.substack.com/p/llama-31s-impact-on-china-kuaishous">Link</a>]</p>
</blockquote>
<p>Highlights key AI news in China: 1) Kuaishou’s global launch of its AI video generator, Kling AI, and Zhipu AI’s introduction of Ying, show China’s progress in AI video generation. 2) Alibaba, Tencent, and state-backed AI funds poured $690 M into the $2.8 B AI firm Baichuan AI.</p>
<blockquote>
<p><strong>State of AI in Venture Capital 2024 - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/932e0055-a2be-47a8-a898-dc455f777009">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>“AI CapEx” is a euphemism for building physical data centers with land, power, steel and industrial capacity. There’s been a lot of investment in data centers and AI chips, but not AGI in sight. You can buy all the shovels you want, but if the mine ain’t making money, we have a problem. If there’s no gold in the mine, the shovels aren’t worth very much. BigTech hyperscalers and VCs might have gotten this all wrong.</em></p>
<p><strong>― OpenAI’s SearchGPT and the Impossible Promises of AI - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/openais-searchgpt-and-the-impossible">Link</a>]</p>
</blockquote>
<p>This article points out that industry is facing immense financial pressures and strategic uncertainties. The concerns are as follows: 1) OpenAI’s operating costs exceed $ 8 B, with a projected loss of $5 B in 2024, 2) annual AI revenue to justify the investment in data centers and chips is unlikely to be achieved by 2025, 3) integrating SearchGPT into ChatGPT is a risky bet because users don’t use ChatGPT frequently enough for it to be a successful search tool, 4) competitive market has pushed many AI startups out of the market, AI innovation cannot compete with market dominance (e.g. Microsoft’s attempts to integrate AI into Bing), 5) Big tech companies have accepted that they are possibly over-investing in AI due to FOMO (fear of missing out), leading to unsustainable financial practices, 6) Nvidia’s revenue is risky since it comes majorly from a few tech giants.</p>
<blockquote>
<p><em>The Morningstar framework: The framework is built on 5 “moat sources”:</em></p>
<ul>
<li><em>Intangible assets (Coca-Cola)</em></li>
<li><em>Switching Costs (Oracle)</em></li>
<li><em>Network Effects (CME Group)</em></li>
<li><em>Cost Advantages (UPS)</em></li>
<li><em>Efficient Scale (Kinder Morgan)</em></li>
</ul>
<p><strong>― 5 Wide Moat Businesses - Invest in Quality</strong> [<a target="_blank" rel="noopener" href="https://www.investinassets.net/p/5-wide-moat-businesses">Link</a>]</p>
</blockquote>
<p>Intangible assest: Coca-Cola, SANOFI, Unilever, Johnson &amp; Johnson.</p>
<p>Switching Costs: Oracle, Intuitive Surgical, ADP.</p>
<p>Network Effect: Mastercard, eBay, CME Group, Facebook.</p>
<p>Cost Advantage: Amazon, Novo Nordisk.</p>
<p>Efficient Scale: UPS, nationalgrid, Carnival</p>
<blockquote>
<p><strong>AI: Are we in another dot-com bubble? - AI Musings by Mu</strong> [<a target="_blank" rel="noopener" href="https://kelvinmu.substack.com/p/ai-are-we-in-another-dot-com-bubble">Link</a>]</p>
</blockquote>
<p>A comprehensive analysis comparing current AI cycle to the internet&#x2F;telecom cycle of the 90s. The author examines the technological, economic, and capital differences between the two eras and concludes that while a bubble may be inevitable in the long run, we are still far from reaching that point.</p>
<p>Key points:</p>
<p>Similarities between AI cycle since Nov 2022 and internet cycle of the 90s: 1) Both cycles have similar ecosystem structures, with companies providing infrastructure, enablement, and applications. 2) Occur amid equity bull markets, driven by favorable economic conditions. 3) Require significant infrastructure investments. 4) Attract significant VC interest, leading to high valuations.</p>
<p>Differences between AI cycle since Nov 2022 and internet cycle of the 90s: 1) AI companies are generating revenue much earlier than dot-com companies did, with more sustainable business models. 2) The current economic environment is less robust than in the 90s, leading to a more cautious investment climate. 3) AI investments are primarily equity-funded by big tech, unlike the debt-financed dot-com boom. 4) Valuations of AI companies, while high, are more grounded in near-term earnings than those during the dot-com era.</p>
<p>Bubble Likelihood: The article argues that while there are risks, the current AI cycle is less likely to be in a bubble compared to the dot-com era. The more cautious investment environment, sustainable business models, and the structured flow of capital contribute to this conclusion.</p>
<p>Lessons from Dot-Com Bubble: 1) Infrastructure buildouts take time. 2) Being a first mover can be a disadvantage, as seen with early internet companies that were later overtaken by more successful competitors. 3) The importance of being critical and not getting swept up in the hype, learning from the past to navigate the present.</p>
<blockquote>
<p><em>To recap the above post, they do the new normal, including:</em></p>
<ul>
<li><em>Human preference data and <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.08673v1">HelpSteer</a> style grading of attributes for regularization.</em></li>
<li><em>High-quality reward models for filtering.</em></li>
<li><em>Replacement of human demonstrations with model completions in some domains.</em></li>
<li><em>Multi-round RLHF — “We iterate data and model qualities jointly to improve them in a unified flywheel.”</em></li>
<li><em>A very large suite of data curation techniques, including prompt re-writing and refining for expansion of costly datasets, filtering math and code answers with outcomes (correctness or execution), filtering with LLMs-as-a-judge, and other new normal stuff.</em></li>
</ul>
<p><strong>― A recipe for frontier model post-training - Nathan Lambert, Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/frontier-model-post-training">Link</a>]</p>
</blockquote>
<p>Recent papers and reports (Llama 3.1, Nemotron 340B, and Apple foundation model) have made it clear that a new default recipe exists for high-quality RLHF. It has a few assumptions:</p>
<ul>
<li>Synthetic data can be of higher quality than humans, especially for demonstrations on challenging tasks.</li>
<li>Reinforcement learning from human feedback (RLHF) can scale far further than instruction tuning.</li>
<li>It takes multiple rounds of training and generation to reach your best model.</li>
<li>Data filtering is the most important part of training.</li>
</ul>
<p>It becomes clear that the post training is highly correlated with the style and robustness gains.</p>
<p>The new normal seems to be converged as follows:</p>
<p><img src="/digital-di/./images/new-post-training-approach.png" alt="post-training"></p>
<blockquote>
<p><strong>OpenAI and Generative AI are at a Crossroads - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/openai-and-generative-ai-are-at-a">Link</a>]</p>
</blockquote>
<p>Views of AI landscape.</p>
<blockquote>
<p><strong>At least five interesting things for your weekend (#45) - Noahpinion</strong> [<a target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/at-least-five-interesting-things-68b">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>GPT-5: Everything You Need to Know - The Algorithmic Bridge</strong> [<a target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/gpt-5-everything-you-need-to-know-10a">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>New LLM Pre-training and Post-training Paradigms - Ahead of AI</strong> [<a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>You don’t have to be a manager - Elena’s Growth Scoop</strong> [<a target="_blank" rel="noopener" href="https://www.elenaverna.com/p/you-dont-have-to-be-a-manager">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Eric Schmidt’s AI prophecy: The next two years will shock you - Exponential View</strong> [<a target="_blank" rel="noopener" href="https://www.exponentialview.co/p/eric-schmidts-ai-prophecy">Link</a>]</p>
</blockquote>
<p>Former Google CEO Eric Schmidt predicts rapid advancements in AI, where large language models and agent-based systems with text-to-action capabilities could converge, causing tremendous economic and technological disruption. </p>
<blockquote>
<p><strong>Meta: Better Sorry Than Safe - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/meta-better-sorry-than-safe">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Judge Amit Mehta handed down the ruling, finding that the tech giant has been using its dominance in the search market to favor its own products and services, making it harder for rivals to gain a foothold.</em></p>
<p><em>The Justice Department had sued Alphabet over its multi-billion dollar deals with smartphone manufacturers and wireless providers to be the default search engine on mobile devices.</em></p>
<p><em>Based on the $87 billion in Services revenue for Apple in 2023, Alphabet accounted for 25% of Apple Services, and over 20% of the Apple’s net profit</em></p>
<p><strong>― Google’s Antitrust Loss - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/googles-antitrust-loss">Link</a>]</p>
</blockquote>
<p>Potential remedies are 1) ending exclusivity deals: prohibit Alphabet from securing exclusive agreements with partners like Apple, 2) behavioral remedies: restrict Alphabet’s conduct e.g. bundling some of its services together, 3) structural remedies: divest some of Alphabet’s businesses e.g. search advertising, YouTube, smartphone business.</p>
<blockquote>
<p><em>A critical component of AMD’s recent strategy is to go beyond advanced chips and offer <strong>software</strong> (for developers to access the capabilities through applications) and now tailored <strong>system solutions</strong> (to optimize the data center for performance).</em></p>
<p><strong>― AMD Acquires ZT Systems - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/amd-acquires-zt-systems">Link</a>]</p>
</blockquote>
<p>In AMD presentation, they mentioned that 1) system design and enablement engineers in ZT systems will enable AMD to design world-class AI infrastructure delivered through an ecosystem of OEM and ODM partners, 2) ZT system’s extensive cloud solutions experience will help accelerate the deployment of AMD-powered AI infrastructure at scale with cloud customers, 3) AMD will deliver optimized solutions to market with our CPU, GPU, networking, and now systems solutions.</p>
<blockquote>
<p>Uber’s continued growth and expanding margins today are encouraging.</p>
<ul>
<li>More users and more trips in mature markets.</li>
<li>Strong advertising performance showing product-market fit.</li>
<li>Multi-product adoption, improving churn, and lowering acquisition costs</li>
</ul>
<p><strong>― Uber’s Big Autonomy Plan - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/ubers-big-autonomy-plan">Link</a>]</p>
</blockquote>
<p>Kind of interested in how Uber’s long-term vision differs from that of Tesla or Waymo.</p>
<p>Business highlights: Autonomous vehicles (AV): the ongoing collaborations with 10 AV companies across all segments fueled the surge of Uber’s AV trip growth. AVs on Uber is a win-win because of Uber’s massive network. </p>
<p>Looking forward: 1) The advertising business reached a revenue run rate of over $1 billion, compared to $650 million a year ago, 2) Uber has made many strategic investments, representing over $6 billion in equity stakes today.</p>
<blockquote>
<p><strong>The Corporate Life Cycle: Managing, Valuation and Investing Implications - Musings on Markets</strong> [<a target="_blank" rel="noopener" href="https://aswathdamodaran.substack.com/p/the-corporate-life-cycle-managing">Link</a>]</p>
</blockquote>
<p>This article is a concise summary of Aswath Damodaran’s <a target="_blank" rel="noopener" href="https://www.amazon.com/Corporate-Lifecycle-Investment-Management-Implications/dp/0593545060?&linkCode=sl1&tag=theratwal-20&linkId=7ebba08f1492c70e6b6388753e4eb683&language=en_US&ref_=as_li_ss_tl">new book</a>. There is also a <a target="_blank" rel="noopener" href="https://pages.stern.nyu.edu/~adamodar//New_Home_Page/webcastCLC.htm">YouTube course series</a>.</p>
<blockquote>
<p><strong>52 Reasons to Fear that Technological Progress Is Reversing - The Honest Broker</strong> [<a target="_blank" rel="noopener" href="https://www.honest-broker.com/p/52-reasons-to-fear-that-technological">Link</a>]</p>
</blockquote>
<p>Very good article summarizing concerning warnings happened recently. Warning signs that all of us have observed. For example, 1) people refuse to upgrade their operating system, probably because the risk started to overweight performance increase, 2) Scientific journals are now filled with thousands of fake AI-generated papers, very concerning, 3) education degree starts to have less value because the tuition now outweights perceived benefits, 4) Google overwhelms search results with affiliate-driven content, often of low quality. Its search results have become dominated by ads, thinly veiled as recommendations, and content designed to maximize affiliate commissions rather than genuinely help users, leading to a degraded user experience, 5) people are addicted to their phones, because tech companies have conducted comprehensive and rigorous research studies, finding way to design and improve products, so that people can stick to them.</p>
<blockquote>
<p>(1) Instead of pursuing truth, new technologies aim to replace it with mimicry and fantasy.</p>
<p>(2) This has empowered shamming, scamming &amp; spamming at unprecedented levels.</p>
<p>(3) Users are not the real customers—so billions of people must suffer to advance the interests of a tiny group of stakeholders.</p>
<p>(4) Real people become inputs in a profit-maximization scheme which requires that they are constantly controlled and manipulated.</p>
<p>(5) In this environment, everything gets viewed as a resource or input and the natural world (including us) is ruthlessly exploited.</p>
<p>(6) The groundwork for this was laid by theorists who replaced truth with power.</p>
<p>(7) In the past, governments controlled huge technologies (nuclear power, spaceships, etc.) so they were somewhat accountable to citizens, but now the most powerful new tech is in private hands, and the public good is no longer even considered.</p>
<p>(8) So much wealth is concentrated in the hands of the winners in these processes, that they literally become more powerful than nation states.</p>
<p>(9) With this shift in power, even the most independent politicians turn into controlled agents working for the technocracy — making a mockery of democracy.</p>
<p>(10) If you oppose this command-and-control tech you can be theoretically (and often literally) erased, suspended, deplatformed, shadow-banned, surveilled, de-banked, digitally faked, etc. —so who will dare?</p>
<p><strong>― 10 Reasons Why Technological Progress Is Now Reversing - Ted Gioia</strong> [<a target="_blank" rel="noopener" href="https://www.honest-broker.com/p/10-reasons-why-technological-progress">Link</a>]</p>
</blockquote>
<p>Good thinking and perspectives. We human are all adapting to a constantly changing life due to the advancement of technology. Ethical boundaries become blur. Truth and false are re-defined. We are farther away from nature and closer to artificiality. We are farther away from truth and closer to hallucination &#x2F; scam. This is inevitable. The point is, how can we maximize the chance of correcting ourselves in the way of development. </p>
<blockquote>
<p><em>“If you want to be a good evaluator of businesses,” said Buffett, “you really ought to figure out a way — without too much personal damage — to run a lousy business for a while. You’ll learn a whole lot more about business by actually struggling with a terrible business for a couple of years than you learn by getting into a very good one where the business itself is so good that you can’t mess it up.”</em></p>
<p><strong>― The Lessons of a Lousy Business - Kingswell</strong> [<a target="_blank" rel="noopener" href="https://www.kingswell.io/p/the-lessons-of-a-lousy-business">Link</a>]</p>
</blockquote>
<p>This is about one of Warren Buffett stories — his investment in Dempster Mill Manufacturing Company. Three lessons: </p>
<ol>
<li><p>Don’t throw good money after bad</p>
<p>Avoid the mistake of continuing to invest in something that is not working, hoping to recover the losses. Warren Buffett learned from his experience to avoid reinvesting in failing operations. Instead of pouring more money into trying to revive the company’s subpar operations, Buffett used the temporary profits from cost-cutting and tax advantages to invest in other, more promising ventures. This approach allowed him to build a successful business empire rather than wasting resources on a losing cause.</p>
</li>
<li><p>Look for .400 hitters</p>
<p>Warren Buffett prioritizes finding exceptional managers—like those who are as rare and skilled as a .400 hitter in baseball—when acquiring companies. By securing top-tier managers, Buffett can delegate the day-to-day operations with confidence, allowing him to focus on what he does best: allocating capital. This approach simplifies his role and ensures that the companies he acquires are in capable hands, which is a crucial aspect of his investment strategy.</p>
</li>
<li><p>Some things are worth more than money</p>
<p>This is the value Warren Buffett places on the impact of his business decisions on people and communities. Despite the financial losses from Berkshire Hathaway’s textile operations, Buffett kept them running for many years because they were a major source of employment for a struggling region. This decision reflects his consideration of the social and human aspects of business, prioritizing the well-being of the community over pure financial gain.</p>
</li>
</ol>
<blockquote>
<p><strong>Pandemic Darlings That Never Bounced Back - Investment Talk</strong> [<a target="_blank" rel="noopener" href="https://www.investmenttalk.co/p/pandemic-darlings-that-never-bounced">Link</a>]</p>
</blockquote>
<p>This article is a reminder that highly speculative situations rarely turn out well in the long run. Many of the speculative stocks that were supposedly going to take advantage of “permanent” societal changes in 2020 and 2021 collapsed and remain far below their highs. </p>
<p>My intuitive explanation is that business that is able to benefit from the sudden covid impact on society is not necessarily stable or invulnerable. It’s probably because the business only works in such abnormal situation where covid was widespread. But the thing is that situation won’t last long and people don’t enjoy it. Business that is sensitive to this societal change is testified by this change to show that normal society sticks to or prefers the business. And you can never underestimate this stickiness or preference, which is like a moat.</p>
<blockquote>
<p><em>We have lots of data, but none of it means much until you attach a story to it about what you think it means and what you think people will do with it next. That seems obvious to me. But ask forecasters if they think the majority of what they do is storytelling and you’ll get blank stares. At best. It never seems like storytelling when you’re basing a forecast in data.</em></p>
<p><em>[History] cannot be interpreted without the aid of imagination and intuition. The sheer quantity of evidence is so overwhelming that selection is inevitable. Where there is selection there is art. Those who read history tend to look for what proves them right and confirms their personal opinions. They defend loyalties. They read with a purpose to affirm or to attack. They resist inconvenient truth since everyone wants to be on the side of the angels.</em></p>
<p><strong>― A Number From Today and A Story About Tomorrow - Morgan Housel @ Collabfund</strong> [<a target="_blank" rel="noopener" href="https://collabfund.com/blog/numbersandstories/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI for Non-Techies: Top Tools for Search, Agent Building, Academic Paper Reviews &amp; Sales Automation - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/ai-for-non-techies-top-tools-for-d90">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>China’s Humanoid Robots, Former Huawei Genius‘ Needle-Threading Robot, and Big Tech Reap AI Rewards - Tony Peng</strong> [<a target="_blank" rel="noopener" href="https://recodechinaai.substack.com/p/chinas-humanoid-robot-former-huawei">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>AI applications will ultimately determine the revenue created across the AI value chain. The primary question in AI is this: “What problems is AI solving? How large are the scale of those problems? What infrastructure needs to be in place to support those applications?”</em></p>
<p><strong>― Ghost in the Machine: The AI Value Chain</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/ghost-in-the-machine-the-ai-value">Link</a>]</p>
</blockquote>
<p>It’s important to think about where value accrues along the AI Value Chain:</p>
<p><img src="/digital-di/./images/al-value-chain.png" alt="ai-value-chain"></p>
<blockquote>
<ul>
<li><em>New Grad or L3</em></li>
<li>Stay hungry<ul>
<li><em>Listen to team meetings to identify areas.</em></li>
<li><em>Ask your team leads where you can help.</em></li>
</ul>
</li>
<li>Self-nominate<ul>
<li><em>Review your team’s backlog and identify “nice to have” items.</em></li>
<li><em>Come forward when someone is looking for assistance.</em></li>
</ul>
</li>
<li>Be curious<ul>
<li><em>Shadow a senior’s coding practices.</em></li>
<li><em>Clarify tasks given to you and understand the context of the larger goals.</em></li>
</ul>
</li>
<li><em>Mid-level or L4</em></li>
<li>Take ownership<ul>
<li><em>“How can others benefit from this work?”.</em></li>
<li><em>Pick up anything dropped on the floor, don’t complain, and take it to the finish line.</em></li>
</ul>
</li>
<li>Assist your teammates</li>
<li>Align with the next level<ul>
<li><em>Find projects to collaborate with key ICs in your organization.</em></li>
<li><em>Become an expert on a specific area for your team.</em></li>
</ul>
</li>
<li><em>Senior or L5</em></li>
<li>Delegate<ul>
<li><em>Create space for others to grow.</em></li>
<li><em>Scale yourself by delegating work and grow your impact.</em></li>
</ul>
</li>
<li>Clear Communication<ul>
<li><em>Invest in mastering concise communication.</em><ul>
<li>❌ “The functionality of the module should be enhanced to provide increased flexibility and adaptability for the end user, with a focus on streamlining the overall workflow process and enhancing the overall user experience.”</li>
<li>✅ “We need to improve the module so it’s easier to use and can handle a wider variety of tasks, making the user’s workflow smoother.”</li>
</ul>
</li>
<li><em>Be intentional with everything you say.</em><ul>
<li>❌ “I think if we decide to make this change, our downstream systems might suffer.”</li>
<li>✅ “This change increases latency by 20%, breaking service X.”</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>― Build Your Credibility As You Grow - Leadership Letters</strong> [<a target="_blank" rel="noopener" href="https://www.leadership-letters.com/p/build-your-credibility-as-you-grow">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Harris makes a big mistake by embracing price controls -  Noahpinion</strong> [<a target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/harris-makes-a-big-mistake-by-embracing">Link</a>]</p>
</blockquote>
<p>The main supporting points: </p>
<ol>
<li>Ineffectiveness of Price Controls: The article argues that price controls on groceries are likely to be either ineffectual or harmful. If implemented, they could lead to shortages as grocery stores operate on razor-thin profit margins. If these stores are forced to sell goods at a loss due to government-mandated price controls, they might reduce supply, leading to empty shelves and potential scarcity, similar to situations seen in the Soviet Union and Venezuela.</li>
<li>Inflation is Already Under Control: The article points out that grocery inflation has already stabilized, with prices having flatlined since early 2023. This suggests that the problem Harris is trying to solve with price controls—rising grocery prices—doesn’t actually exist anymore. Implementing price controls now could be seen as a solution in search of a problem, leading to unnecessary economic distortions.</li>
<li>Legal and Political Risks: Harris’s proposal involves using the Federal Trade Commission (FTC) to enforce price controls, which the article argues is beyond the agency’s current legal authority. This could require new legislation, potentially face legal challenges, and expand the FTC’s powers in ways that could be problematic. The risk is that this could lead to a slippery slope of further government intervention in the economy.</li>
<li>Historical Precedents: Historical examples of price controls, such as in Argentina and the U.S. during the 1970s, show that they often lead to short-term price reductions followed by inflation and shortages once the controls are lifted. The article argues that these historical precedents suggest that the best-case scenario for Harris’s proposal is negligible impact, while the worst-case scenario is significant economic disruption.</li>
<li>Misguided Focus on Grocery Stores: The article highlights that grocery stores are not the main culprits behind price increases, as their profit margins are extremely low. The real issue may lie with other parts of the supply chain, such as food processors, where there is more evidence of monopoly power. Thus, targeting grocery stores with price controls may not address the root causes of price increases.</li>
</ol>
<h3 id="Articles-and-Blogs"><a href="#Articles-and-Blogs" class="headerlink" title="Articles and Blogs"></a>Articles and Blogs</h3><blockquote>
<p><strong>In the Age of A.I., What Makes People Unique? - The New Yorker</strong> [<a target="_blank" rel="noopener" href="https://www.newyorker.com/culture/open-questions/in-the-age-of-ai-what-makes-people-unique">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How To Get Promoted (Without Getting Lucky) - The Developing Dev</strong> [<a target="_blank" rel="noopener" href="https://www.developing.dev/p/how-to-get-promoted-without-getting">Link</a>]</p>
<p><strong>How to Get Rich (without getting lucky) - Naval @ X</strong> [<a target="_blank" rel="noopener" href="https://x.com/naval/status/1002103360646823936">Link</a>]</p>
</blockquote>
<p>Key takeaways: 1) know what you organization considers impactful, 2) learn to sell your ideas, set directions, grow and help others, 3) build your brand by embracing accountability and sharing your results, 4) become a good collaborator and be transparent to your manager about goals and gaps, 5) protect your focus time - “<strong>what you work on is more important than how hard you work</strong>“, do work that you enjoy and has impact.</p>
<blockquote>
<p><strong>Is Consistency Hurting Your Sustainability? - Leadership Letters</strong> [<a target="_blank" rel="noopener" href="https://www.leadership-letters.com/p/is-consistency-hurting-your-sustainability">Link</a>]</p>
</blockquote>
<p>Key takeaways: 1) it’s ok to be inconsistent sometimes, you should update your plan that respects flexibility, balance priorities, or adjust your expectations, 2) Life is not a sprint, taking a pause and pushing goals to the future is not always bad, 3) consistency is about never giving up, 4) don’t set consistency as a goal, find out what is your real goal, so that accepting and developing “bounce-back” plan is possible</p>
<blockquote>
<p><strong>McKinsey’s 2024 annual book recommendations</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/featured-insights/annual-book-recommendations">Link</a>]</p>
</blockquote>
<p>Have selected some books and added them into my read list: 1) God, Human, Animal, Machine: Technology, Metaphor, and the Search for Meaning by Meghan O’Gieblyn, 2) Outlive: The Science &amp; Art of Longevity by Peter Attia, 3) The Journey of Leadership: How CEOs Learn to Lead from the Inside Out by Dana Maor, Hans-Werner Kaas, Kurt Strovink, and Ramesh Srinivasan, 4) Slow Productivity: The Lost Art of Accomplishment Without Burnout by Cal Newport, 5) How Legendary Leaders Speak: 451 Proven Communication Strategies of the World’s Top Leaders  by Peter D. Andrei.</p>
<blockquote>
<p><strong>Paid Advertising 101: A Guide for Startup Founders - Kaya</strong> [<a target="_blank" rel="noopener" href="https://www.usekaya.com/blog/paid-advertising-101">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Building A Generative AI Platform - Chip Huyen</strong> [<a target="_blank" rel="noopener" href="https://huyenchip.com/2024/07/25/genai-platform.html">Link</a>]</p>
</blockquote>
<p>This blog post outlines common themes in building generative AI systems. It covers many of the building blocks a company should consider when deploying its models to production. </p>
<blockquote>
<p><strong>AI’s $600B Question - David Cahn, Sequoia</strong> [<a target="_blank" rel="noopener" href="https://www.sequoiacap.com/article/ais-600b-question/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Calculating GPU memory for serving LLMs - Substratus</strong> [<a target="_blank" rel="noopener" href="https://www.substratus.ai/blog/calculating-gpu-memory-for-llm">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Social media for startup founders: A practical guide to building an online presence - a16zcrypto</strong> [<a target="_blank" rel="noopener" href="https://a16zcrypto.com/posts/article/social-media-for-startups-guide/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Long Context RAG Performance of LLMs - Databricks</strong> [<a target="_blank" rel="noopener" href="https://www.databricks.com/blog/long-context-rag-performance-llms">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>An AI engineer’s tips for writing better AI prompts - coda</strong> [<a target="_blank" rel="noopener" href="https://coda.io/blog/ai/ai-engineer-tips-ai-prompts">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Grok-2 Beta Release - X.AI</strong>  [<a target="_blank" rel="noopener" href="https://x.ai/blog/grok-2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to Prune and Distill Llama-3.1 8B to an NVIDIA Llama-3.1-Minitron 4B Model - NVIDIA Developer</strong> [<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A practitioner’s guide to testing and running large GPU clusters for training generative AI models - together.ai</strong> [<a target="_blank" rel="noopener" href="https://www.together.ai/blog/a-practitioners-guide-to-testing-and-running-large-gpu-clusters-for-training-generative-ai-models">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Competing in search - Benedict Evans</strong> [<a target="_blank" rel="noopener" href="https://www.ben-evans.com/benedictevans/2024/8/19/competing-in-search">Link</a>]</p>
</blockquote>
<p>This article takes a look at the many possible impacts the recent antitrust case against Google may have.</p>
<blockquote>
<p><strong>GitHub CEO Thomas Dohmke says the AI industry needs competition to thrive - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/24221978/github-thomas-dohmke-ai-copilot-microsoft-openai-open-source">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Databricks vs. Snowflake: What their rivalry reveals about AI’s future - Foundation Capital</strong> [<a target="_blank" rel="noopener" href="https://foundationcapital.com/databricks-vs-snowflake-what-their-rivalry-reveals-about-ais-future/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How I Use “AI” - Nichalas Carlini</strong> [<a target="_blank" rel="noopener" href="https://nicholas.carlini.com/writing/2024/how-i-use-ai.html">Link</a>]</p>
</blockquote>
<p>DeepMind research scientist shares practical techniques to augment your work with LLMs.</p>
<blockquote>
<p><strong>FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention - PyTorch</strong> [<a target="_blank" rel="noopener" href="https://pytorch.org/blog/flexattention/">Link</a>]</p>
</blockquote>
<p>Use FlexAttention in PyTorch to achieve 90% of FlashAttention2 Speed.</p>
<blockquote>
<p><strong>Deploy open LLMs with Terraform and Amazon SageMaker - Philschmid</strong> [<a target="_blank" rel="noopener" href="https://www.philschmid.de/terraform-llm-sagemaker">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Sonnet 3.5 for Coding - System Prompt - reddit</strong> [<a target="_blank" rel="noopener" href="https://www.reddit.com/r/ClaudeAI/comments/1dwra38/sonnet_35_for_coding_system_prompt/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Product Recommendations Broke Google And ate the internet in the process. - Intelligencer</strong> [<a target="_blank" rel="noopener" href="https://nymag.com/intelligencer/article/how-product-recommendations-broke-google.html">Link</a>]</p>
</blockquote>
<ul>
<li>Health.com’s Purifier Reviews: The article mentions that Health.com claims to have tested 67 air purifiers but provides no actual test data. This example supports the point that many product recommendations are not based on rigorous testing, undermining their credibility.</li>
<li>HouseFresh’s Critique: HouseFresh published a critical assessment of its competitors, pointing out issues like subpar products being recommended due to brand recognition. This supports the argument that the affiliate marketing model is corrupting the integrity of product recommendations.</li>
<li>Time Stamped and AP Buyline: These brands, operated by Taboola, are presented as examples of how even reputable organizations are now involved in affiliate marketing, blurring the lines between independent journalism and commercial content. This supports the point that the distinction between quality content and affiliate-driven recommendations is becoming increasingly unclear.</li>
<li>SGE (Search Generative Experience): Google’s AI-powered search results, which aggregate and recommend products directly, are criticized for being misleading and overly simplistic. This supports the idea that even Google’s attempts to solve the problem are falling short, further complicating the search landscape.</li>
</ul>
<p>These examples illustrate how the proliferation of affiliate-driven content has compromised the quality of online information, leading to a search experience that is more about driving sales than helping users make informed decisions.</p>
<blockquote>
<p><strong>Avoiding Bad Guys - Humble Dollar</strong> [<a target="_blank" rel="noopener" href="https://humbledollar.com/2024/08/avoiding-bad-guys/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Berkshire Hathaway MBA - The Rational Walk</strong> [<a target="_blank" rel="noopener" href="https://rationalwalk.com/the-berkshire-hathaway-mba/">Link</a>]</p>
</blockquote>
<p>Pathway to a great investor.</p>
<blockquote>
<p><em>Syntopical Reading is the highest form of reading because it involves reading a number of books on the same topic analytically and then placing the books in context in relation to one another and the overall subject. This level of reading has the potential to bring about insights that are not found in any one of the books when considered in isolation.</em></p>
<p><em>As an example relevant to investors, one might want to conduct an analytical reading of Benjamin Graham’s <a target="_blank" rel="noopener" href="http://amzn.to/1WWU4CD">The Intelligent Investor</a> and Philip Fisher’s <a target="_blank" rel="noopener" href="http://amzn.to/1PGbSRY">Common Stocks and Uncommon Profits</a> and then come to grips with the underlying themes expressed in both volumes while drawing conclusions on investing that might not appear in either book in isolation. This approach can, of course, be applied to other forms of literature including biographies. It is quite possible than a thorough analytical reading of Roger Lowenstein’s <a target="_blank" rel="noopener" href="http://amzn.to/1PGcebg">Buffett: The Making of an American Capitalist </a>and Alice Schroeder’s <a target="_blank" rel="noopener" href="http://amzn.to/1PGc9Ez">The Snowball: Warren Buffett and the Business of Life</a> could lead to insights about Warren Buffett that one could not achieve by reading one of these books in isolation.</em></p>
<p><strong>― How to Read a Book: The Classic Guide to Intelligent Reading - The Rational Walk</strong> [<a target="_blank" rel="noopener" href="https://rationalwalk.com/how-to-become-a-better-reader/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Do Not Use LLM or Generative AI For These Use Cases - Christopher Tao on TowardsAI</strong> [<a target="_blank" rel="noopener" href="https://pub.towardsai.net/do-not-use-llm-or-generative-ai-for-these-use-cases-a819ae2d9779">Link</a>]</p>
</blockquote>
<p><img src="/digital-di/./images/genai-usecase.png" alt="genai-usecase"></p>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><strong>Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Kbk9BiPhm7o">Link</a>]</p>
</blockquote>
<p>Eight hours interview..</p>
<blockquote>
<p><strong>Kamala surges, Trump at NABJ, recession fears, Middle East escalation, Ackman postpones IPO - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rj71DPhvpiE">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI and The Next Computing Platforms With Jensen Huang and Mark Zuckerberg - NVIDIA</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=w-cmMcMZoZ4">Link</a>]</p>
</blockquote>
<p>Nvidia CEO Jensen and Zuckerberg discuss the future of AI.</p>
<blockquote>
<p><em>There’s a famous quote from an economist Simon Kuznets who said there’s four kinds of countries in the world there’s developed countries undeveloped countries Japan and Argentina. And I think the reason he said that is that Japan has been in the state since the 90s so they had a massive property and Equity bubble collapse. And they’ve not had to deal with anything that looked like typical economic issues since then and part of it is because the Govern plays a very big hand in the Japanese economy, there’s a lot of price controls there. So I don’t know I’m not sure what it is that we can learn there that you can extrapolate to the rest of the world. - Chamath Palihapitiya</em></p>
<p><em>When you have massive amounts of debt it definitely limits your flexibility. It’s just arithmetic, you are going to pay for it with either economic contraction, higher taxes, or inflation. Those are the three places it goes. - David Sacks &amp; David Friedberg</em></p>
<p><em>Well so it looks like since the start of the year they’ve sold 55% of their Holdings in apple. And if you look at the end of the year, this is what berkshire’s stock Holdings were in their non-majority owned businesses. So businesses that they don’t own the business outright and 50% of their portfolio was in Apple at $174 billion. We obviously saw Apple’s stock price Peak highest level ever just a few days ago, but it has since come down as it was reported that since the start of the year. Now Berkshire sold 55% of this position, so some people are arguing that they’ve got a point of view on the company strategy and comp competitive kind of landscape. Some folks have argued that the valuation multiple has gotten too high trading at nearly 30 times earnings the stock has risen 900% since Berkshire bought the stock in 2016. Bagger nicely done yeah and some people would argue that the percent of the portfolio is too high at over 50%, as you can see here at the start of the year. But you know I’ll kind of provide some of the counterarguments you know Warren Buffett does not do much analysis on corporate strategy when he provides reviews of the stocks that he’s picked he often finds and talks a lot about great managers that generate great returns. And he sticks with them and he sticks with them sometimes for many many decades. The management in this company has not changed the return profile on cash invested and cash returned has only improved since he put money in. They’re generating more cash flow they’re offering more dividends they’re doing more stock BuyBacks and he’s happy to be concentrated over the years he’s made large bets on single companies to the point that sometimes he just outright buys the entire company like he did with. Geico in 1996 he always talks a lot about finding a company that is run by great managers that has a premium product with a nice high margin and a durable moat strong brand value. As I look at kind of what’s really gone on here it feels to me like the difference between Apple and some of the other big Holdings in its portfolio is that many of those other businesses are regulated monopolies. So BNSF Railway is regulated by the Federal Railroad Administration Berkshire energy which owns mid americ is a regulated utility. The prices that they charge consumers are set by the government so they have a market that’s locked in the prices are set they have locked in distribution they have locked in utility value and the same is true in the insurance business. Geico’s rates are approved and set effectively by state Regulators Berkshire has a moat because they’ve got the largest Capital base and they’ve got this machine that just keeps generating cash and the rates are publicly set by government Apple. However is not regulated and it is very clear that apple is facing very deep and severe Financial impact from the regulatory authorities that are overseeing the business so if you look at the Google antitrust we’re going to get into the Google deal in a second. There’s a real regulatory risk there because Google’s paying Apple $20 billion a year to be the default search engine. Apple also has a very deep relationship with China they have a lot of manufacturing being done in China and they sell a lot of product into China. So as Regulators start to take a harder look as they said they’re going to at companies relationships with China that’s a real risk to Apple. Advertising tracking users and then the subscription fees that are charged to Consumers and most importantly we’ve talked a lot about the 30% Vig that Apple takes on their App Store and how Regulators are now stepping in and take a look at this. So because this business is not yet a regulated Monopoly it may be a monopoly in many senses of the world it’s not regulated yet. And that transition could be financially painful for Apple once they get to the other side it starts to look a lot more like a large scale Burkshire type business. So that that’s my kind of summary take on what’s going on with apple.  - David Friedberg</em></p>
<p><em>There’s very little kind of editorialization going on with respect to showing the rankings of the new sources. The ranking of the new sources is typically set by some ranking algorithm. The algorithm is usually around click-throughs views popularity of the sites, how many visitors there are, so there are other metrics that drive the order. So for example if NBC CNN Fox News all have kind of higher rankings than some smaller publication, they’re going to end up Hing the the ranking algorithm, because they have a higher quality score. There’s also measures on how often people click through and come back, the bounceback rate, so if they click through an article and then come back that can actually reduce the ranking versus if they click through and stay on the site. So there’s a lot of factors that go into the ranking algorithm. The thing that probably upsets people is that there isn’t any transparency into this, so there’s no understanding on how these things are ranked, how they’re set, and it’s probably very good guidance and feedback that there should be more transparency and openness. And I’m not necessarily trying to defend anyone’s product or behavior, I’m just saying that there’s a certainly a lack of understanding on why one thing is being shown versus another. I’ll also say Sach there’s probably the case or there might be the case that there’s many more sites potentially putting out pro Harris articles, and there are putting out pro Trump articles which can start to overweight the the algorithm as you know or overweight the rankings that are showing up. So that might also be feeding into this that that the general news media bias is what you’re actually seeing versus a Google bias. - David Friedberg</em></p>
<p><em>I just want to show you one chart because important for you to understand the number of people in journalism. This is from 1971 to 2022 who say the identifying Republican has just absolutely plummeted. I know this and this is what I’m trying to explain to you Sacks, is a incredible opportunity for your party since you know you’re passionate about this is to invest in more journalism, invest in more journalists, because I don’t buy this Independence the fact that they’re claiming they’re independent in journalism. I believe that’s cap I believe they say that the Gap is 33% now between people who say they’re Democrats and people who say they’re Republican in journalism that is a key piece to this problem. And layered on top of it, I agree with you that Google is filled with liberal people, and I agree with you Chamath, that they need to intervene and put at the top of the search results in news. These are the you know this is what we’re indexing, this is the percentage that’s left leaning, this is the percentage that’s right leaning, and there are a lot of organizations that examine and rate Publications on their bias left and right, And that’s something that Google could do that’s very unique and that could move the whole show that you’re saying which is they could showcase that up top. So to my friends at Google who are listening do a better job of just being more transparent, so we don’t have this tension in society. - Jason Calacanis</em></p>
<p><strong>― Yen Carry Trade, Recession odds grow, Buffett cash pile, Google ruled monopoly, Kamala picks Walz - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=LRKDisV_pcI">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Ross Taylor on LLM reasoning, Llama fine-tuning, Galactica, agents - Interconnects AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=KNsnarhMZRo&feature=youtu.be">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Sebastian Raschka on the state of open LLMs, Llama 3.1, and AI education - Interconnects AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=-q79uzz1Wik">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Here you can see that their (Starbucks) net revenue growth was only 1% year-over-year, but their operating margin’s been on the decline, so they have not really been able to boost their operating margin very much in the past 5 years. So while they’ve raised prices, they’ve had a really hard time making more money and that’s because the cost of food and the cost of Labor and the cost of rent, and the capital expenditures needed to upgrade stores has far exceeded the ability for them to grow revenue and compete. And now revenue is flatlining because consumers are getting tapped out with respect to how much they can spend and there’s only so much Innovation you can really do to charge more, get people to come in the store more and drive up revenue. - David Friedberg</em></p>
<p><em>Brian Nickel has an incredible reputation prior to Chipotle. He ran Taco Bell and he ran Taco Bell for several years and made it one of the most profitable Quick Serve Restaurants (QSR) in the world. He did this by focusing on every nickel. He is notorious for being a Cost Cutter, for being an efficiency driver, for being a productivity Hound. He goes into the business and he figures out every step in the supply chain, every step of the operating activities of the employee in the stores. So he was recruited heavily. I don’t know if you guys remember Chipotle’s founder was running Chipotle and at the time there was a lot of investor activism around Chipotle because they were wasting money like no one’s business. The guy had a private Jet, he was flying his management team back and forth between Denver and New York. They were spending money on crazy projects. And the board fired the CEO founder of Chipotle, brought in Nickel. Nickel came in and made Chipotle an incredibly profitable growing business. And the expectation is he’ll come and do the same here that maybe over the years Starbucks’s success has bred laziness. Starbucks’s success has bred fat slowness productivity decline, and that this guy is the right guy to come in and find all the nickels. And Brian Nichol is probably the right guy which is why you’re seeing the stock kind of rally as hard as it has. - David Friedberg</em></p>
<p><em>But the thing about Starbucks is they realized early on that when you can customize a consumer experience, the consumer comes back more frequently. So when you see your name written on that cup, you feel like you’re getting your product, you’re not buying an off-the-shelf product, you’re getting a custom personalized experience. What that led to is people customizing their drinks and what did they find that they liked when they customized their drinks sugary sweet add-ons. And then that became more and more of the standard menu and then that just kept evolving. And that’s just the consumer feedback mechanism working which is to Chamath’s point, led to 60 gram sugar drinks that are now the standard product at Starbucks, not an espresso or a cappuccino which is how they started, and it’s really unfortunate. - David Friedberg</em></p>
<p><em>So arguably I would say that trying to step in and cap prices will reduce competition, and as a result will reduce investment in improving productivity. And we have seen this countless times with every socialist experiment in human history has started with caps on food, and it has resulted in spread lines like you see in the image behind me today as we can see in Soviet Russia. This is a mistake, it is a problem, it is anti-American, it is anti-free Market, it is anti- innovation, it is anti- productivity, and ultimately it’s anti- liberty and I cannot stand it. - David Friedberg</em></p>
<p><em>To support your point, and what Chamath was messaging on our chat, look at Walmart stocks up 7% today, because they offer lower priced solutions to consumers, and Dollar General and Dollar Tree are rallying as well, when the market competes, consumers benefit, and there are companies that will win. And the companies that try to price gouge, and the companies that try to charge too much will lose. Starbucks has been trying to charge too much for sugar water, they have a real problem they are now tackling. Walmart is trying to bring value to consumers, they are winning. That is how free markets work. When the government steps in and says here’s how much margin you can make or here’s how much prices should be, it ruins everything, and the entire incentive structure goes away, and you end up with breadlines. - David Friedberg</em></p>
<p><strong>― Break up Google, Starbucks CEO out, Kamala’s price controls, Boeing disaster, Kursk offensive - All-in Podcasts</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xA5B6quoahY">Link</a>] </p>
</blockquote>
<blockquote>
<p><em>I think the thing that matters more than anything else is to make sure that the people that they are letting in are in love and obsessed with the things that MIT is supposed to be great at. … You should not be going to MIT because you think it’s a check mark. You should be going there because you think that there are professors in organic Chemistry, in physics, in these disciplines that are really important who are experts in their fields that you can learn from and become an expert yourself. And I think the problem with all of this other stuff is once you make it a credential, there are some folks that are only going to MIT because they could get in and because it’s a great credential in their minds and they shouldn’t go there either. So I think the thing is you have to get back to what matters which is there are all of these industries that have not progressed that much. And in order for those Industries to advance you need really talented young people who can learn an apprentice and then take over. And I think MIT is one of these rare places that focuses on this part of the physical world that hasn’t had as much progress. And so I just want to make sure that the people that go there actually want to be there for that reason gender race all that other stuff shouldn’t matter. - Chamath Palihapitiya</em></p>
<p><em>Kamala Harris and Tim Waltz have only ever work for government, Trump and Vance have worked in Private Industry. It’s not just their perspective being colored by the the lack of participation in the private economy, but the lack of employment in the private economy, they’ve never worked for a private business, they’ve never been employees of a private business, they’ve never built a private business. I’m not trying to be disparaging but I do think I’m just trying to underline the point here Chamath which is the voter’s choice is do you want candidates that are not typically government operatives, or do you want candidates that have spent their whole career as government operatives. And that is effectively what the voters are going to be voting for. And they’re going to make a decision they may want to have someone that’s going to lead the biggest government in history, because they’ve spent their whole careers in government. Or they’re going to say you know what the biggest government in history needs to be significantly altered, and we want to bring someone in from the outside that’s worked in Private Industry. And that is the voter’s choice. That’s one way to view the voter’s choice here. - David Friedberg</em></p>
<p><em>I think just because someone has served in Government doesn’t mean that they truly even understand what the problems are, or that they’re even the master of government. I mean you saw this over the past week we talked about the 88,000 jobs that didn’t exist. They asked Gina Rundo the Secretary of Commerce about this and she just said that’s a Trump lie, and they said no actually it’s the Bureau of Labor Statistics report that like is under US Secretary of Commerce. She said I’m not familiar with that, so you have people running the government who don’t even know what their own departments are doing. Now I think it’s just a function of the fact that the government is so big and out of control that no one even understands what it does. I think it’s more important to have someone who at least has some experience in the private sector who truly understands how jobs are created, how wealth is created, what causes inflation, okay. We’ve talked about this before, what causes inflation is the printing of too much money, it’s government spending too much, it is not corporate greed, because corporate greed as a constant, it’s not price gouging. - David Sacks</em></p>
<p><em>And how the free market incentivizes the creation of improved productivity which over time translates into improved prosperity for the society within which that is taking place that is so critical and we saw that happen even in China in the last 30 years when the government allowed entrepreneurship to flourish in certain parts of the country. As a result there were significant productivity gains and they brought a billion people out of poverty - they created a middle class. - David Friedberg</em></p>
<p><strong>― Massive jobs revision, Kamala wealth tax, polls vs prediction markets, end of race-based admissions - All-in Podcasts</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=jSpGiFqL8_E&t=3926s">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Why We Don’t Own Coupang Stock (CPNG) - Chit Chat Stock Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=fxj83i-HY9k">Link</a>]</p>
</blockquote>
<p>Good analysis of CPNG’s business, advantages and disadvantages, future and expectation.</p>
<blockquote>
<p><strong>Track Record and Risk w&#x2F; Guy Spier - We Study Billionaires</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/02nRz018bB8ZO1rxVmdxtN">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong># 361 Estée Lauder - Founders</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/5KM80mo5fMv2JIxzP9Zk5s">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Joe Carlsmith - Otherness and control in the age of AGI - Dwarkesh Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.dwarkeshpatel.com/p/joe-carlsmith">Link</a>]</p>
</blockquote>
<h3 id="Paper-and-Reports"><a href="#Paper-and-Reports" class="headerlink" title="Paper and Reports"></a>Paper and Reports</h3><blockquote>
<p><strong>Gradient Boosting Reinforcement Learning</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.08250v1">Link</a>]</p>
</blockquote>
<p>Gradient-Boosting RL (GBRL) brings the advantages of GradientBoosting Trees (GBT) to reinforcement learning. </p>
<blockquote>
<p><strong>SpreadsheetLLM: Encoding Spreadsheets for Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09025">Link</a>]</p>
</blockquote>
<p>Microsoft releases SpreadsheetLLM, a model designed to optimize LLMs’ powerful understanding on spreadsheets. It’s a great paper that outlines how you can turn a spreadsheet into a representation that is useful to a modern LLM. This can be used for Q&#x2F;A, formatting, and other data operations.</p>
<p>The core innovation in SpreadsheetLLM is the SheetCompressor module, which efficiently compresses and encodes spreadsheets. It includes 1) Structural-anchor-based compression, 2) Inverse index translation, 3) Data-format-aware aggregation.</p>
<blockquote>
<p><strong>OpenAI Revenue</strong> [<a target="_blank" rel="noopener" href="https://futuresearch.ai/openai-revenue-report">Link</a>] </p>
</blockquote>
<blockquote>
<p><strong>The Llama 3 Herd of Models - Meta Research</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">Link</a>]</p>
</blockquote>
<p>This is a 92 pages paper, a comprehensive guide for LLM researchers and engineers.</p>
<blockquote>
<p><strong>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09413v1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>KAN or MLP: A Fairer Comparison</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.16674">Link</a>]</p>
</blockquote>
<p>Controlled study finds MLP generally outperforms KAN across various tasks. MLP outperformed KAN in machine learning (86.16% vs. 85.96%), computer vision (85.88% vs. 77.88%), NLP (80.45% vs. 79.95%), and audio processing (17.74% vs. 15.49%). KAN excelled only in symbolic formula representation (1.2e-3 RMSE vs. 7.4e-3). </p>
<blockquote>
<p><strong>NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.11963">Link</a>]</p>
</blockquote>
<p>The problem of current evaluation methods is that they are inadequate for assessing LLM performance on long context, however reasoning on long texts becomes more and more demanded. So they present a framework called NeedleBench for evaluating the long-context capabilities of LLMs across extensive text lengths. By some experiments, they find that current LLMs are struggling with complex reasoning tasks when it comes to long texts, showing a potential improvement room for LLMs.</p>
<blockquote>
<p><strong>Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.16833">Link</a>]</p>
</blockquote>
<p>This study investigates how large language models handle question-answering tasks under two conditions: when they receive comprehensive context information (long-context) versus when they are given only selected chunks of the necessary information (RAG). It shows that long context surpasses RAG significantly for Gemini-1.5-Pro, GPT-4O and GPT-3.5-Turbo. </p>
<blockquote>
<p><strong>A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.12994v2">Link</a>]</p>
</blockquote>
<p>This paper summarizes 38 prompt engineering techniques for LLM reasoning and lists the types of problems and datasets they have been used with.</p>
<blockquote>
<p><strong>Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.13121">Link</a>]</p>
</blockquote>
<p>This paper explores the capabilities of long-context language models (LCLMs) in handling tasks traditionally dependent on external tools like retrieval systems, RAG (Retrieval-Augmented Generation), and SQL databases. It reveals that LCLMs, such as Gemini 1.5 Pro, GPT-4o, and Claude 3 Opus, can perform competitively with specialized models in tasks like retrieval and RAG. In particular, at the 128k token context length, LCLMs rival the performance of state-of-the-art retrieval systems and even surpass some multi-modal retrieval models. However, LCLMs struggle significantly with more complex tasks requiring multi-hop compositional reasoning, such as SQL-like tasks. The findings also highlight the importance of prompt design, as performance can vary greatly depending on the prompting strategies used.</p>
<blockquote>
<p><strong>Apple Intelligence Foundation Language Models - Apple</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.21075">Link</a>]</p>
</blockquote>
<p>This report describes the architecture, the data used to train the model, the training process, how the models are optimized for inference, and the evaluation results, for the foundation language model developed to power Apple Intelligence features.</p>
<p>Notice that Apple includes the fundamentals of their RL methods, including a different type of soft margin loss for the reward model, regularizing binary preferences with absolute scores, their rejection sampling algorithm (iTeC) that is very similar to Meta’s approach, and their leave-one-out Mirror Descent RL algorithm, MDLOO. </p>
<blockquote>
<p><strong>Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.07666v1">Link</a>]</p>
</blockquote>
<p>This survey provides an in-depth review of model merging techniques, an increasingly popular method in machine learning that doesn’t require raw training data or expensive computation. </p>
<blockquote>
<p><strong>Causal Agent based on Large Language Model</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.06849v1">Link</a>]</p>
</blockquote>
<p>Causal Agent is an agent framework equipped with tools, memory, and reasoning modules to handle causal problems. </p>
<blockquote>
<p><strong>Transformer Explainer</strong> [<a target="_blank" rel="noopener" href="https://poloclub.github.io/transformer-explainer">Link</a>] [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.04619">Paper</a>] [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ECR4oAwocjs&ab_channel=PoloClubofDataScience">video</a>]</p>
</blockquote>
<p>Interactive visualization tool designed for non-experts to learn about Transformers.</p>
<blockquote>
<p><strong>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery - Sakana.AI</strong> [<a target="_blank" rel="noopener" href="https://sakana.ai/ai-scientist/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Transformers in music recommendation - Google Research</strong> [<a target="_blank" rel="noopener" href="https://research.google/blog/transformers-in-music-recommendation/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A Comprehensive Overview of Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.06435">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A Survey on Benchmarks of Multimodal Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.08632v1">Link</a>]</p>
</blockquote>
<p>This paper provides an extensive review of 180 benchmarks used to evaluate Multimodal Large Language Models. </p>
<blockquote>
<p><strong>Qwen2-VL: To See the World More Clearly - QwenLM</strong> [<a href="">Link</a>]</p>
</blockquote>
<p>The model comes in three sizes : 2B and 7B (open-sourced under Apache 2.0 license), and 72B (available via API).</p>
<p>Performance: </p>
<ul>
<li>Qwen2-VL demonstrates state-of-the-art performance on visual understanding benchmarks. The 72B model surpasses GPT-4o and Claude 3.5-Sonnet on most metrics. </li>
<li>The 7B model achieves top performance in document understanding and multilingual text comprehension. Even the 2B model shows strong performance in video-related tasks and document understanding.</li>
</ul>
<p>Key Capabilities:</p>
<ul>
<li>Processing videos over 20 minutes long</li>
<li>Complex reasoning for device operation (e.g., mobile phones, robots)</li>
<li>Multilingual text understanding in images (European languages, Japanese, Korean, Arabic, Vietnamese)</li>
<li>Function calling for integration with external tools</li>
<li>Document understanding and general scenario question-answering</li>
<li>Integrates with Hugging Face Transformers and vLLM. </li>
<li>Supports various tools for quantization, deployment, and fine-tuning, making it accessible for ML engineers and researchers to implement and customize.</li>
</ul>
<p>Two key architectural innovations:</p>
<ul>
<li><strong>Naive Dynamic Resolution</strong> support allows Qwen2-VL to handle arbitrary image resolutions by mapping them to a dynamic number of visual tokens. This ensures consistency between input and image information. </li>
<li><strong>Multimodal Rotary Position Embedding (M-ROPE)</strong> enables concurrent capture of 1D textual, 2D visual, and 3D video positional information.</li>
</ul>
<h3 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h3><blockquote>
<p><strong>Multimodal Report Generation Agent - Llamaindex</strong> [<a target="_blank" rel="noopener" href="https://github.com/run-llama/llama_parse/blob/main/examples/multimodal/multimodal_report_generation_agent.ipynb">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Building a RAG Pipeline over Legal Documents - Llamaindex</strong> [<a target="_blank" rel="noopener" href="https://github.com/run-llama/llama_parse/blob/main/examples/multimodal/legal_rag.ipynb">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to generate images with FLUX: the most photorealistic text-to-image model available</strong> </p>
</blockquote>
<p>Simple Method: Use <a target="_blank" rel="noopener" href="https://y1mnw3w8.r.us-east-1.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FocUXNN/1/010001914bdfb8dc-cb490fbf-a7e7-43ba-9b23-fb5a8234308c-000000/hK6AWLCJMvupI6H-Ehmvy0zZviY=387">Replicate</a> or <a target="_blank" rel="noopener" href="https://y1mnw3w8.r.us-east-1.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FCZQwnF/1/010001914bdfb8dc-cb490fbf-a7e7-43ba-9b23-fb5a8234308c-000000/LDL-GsnSKSeqVKB-0eCr188joMo=387">FAL</a> for inference via your browser.</p>
<p>HuggingFace Method</p>
<ol>
<li>Clone this <a target="_blank" rel="noopener" href="https://y1mnw3w8.r.us-east-1.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FkHG68u/1/010001914bdfb8dc-cb490fbf-a7e7-43ba-9b23-fb5a8234308c-000000/-h6_XgCvSpyzigNlXK91B8Y45I8=387">Google Colab notebook</a>.</li>
<li>Change the Runtime to A100 GPU: FLUX.1 requires 32GB of GPU RAM to run, so ensure you select the A100 GPU runtime.</li>
<li>Run the notebook.</li>
<li>Change the prompt, currently set to: “A modern, minimalist house with large windows and a flat roof.”</li>
</ol>
<blockquote>
<p><strong>GraphRAG Implementation with LlamaIndex</strong> [<a target="_blank" rel="noopener" href="https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v1.ipynb">Link</a>]</p>
</blockquote>
<p>LlamaIndex releases notebook implementation of Microsoft’s GraphRAG.</p>
<blockquote>
<p><strong>Step-By-Step Tutorial: How to Fine-tune Llama 3 (8B) with Unsloth + Google Colab &amp; deploy it to Ollama - reddit</strong> [<a target="_blank" rel="noopener" href="https://www.reddit.com/r/LocalLLaMA/comments/1e416fo/stepbystep_tutorial_how_to_finetune_llama_3_8b/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Notebooks: Using Mistral Nemo with 60% less memory - Nvidia</strong> [<a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing">Notebook1</a>] [<a target="_blank" rel="noopener" href="https://www.kaggle.com/code/danielhanchen/kaggle-mistral-nemo-12b-unsloth-notebook">Notebook2</a>]</p>
</blockquote>
<p>Nvidia has released two free notebooks for Mistral NeMo 12b, enabling 2x faster finetuning with 60% less memory. Mistral’s latest free LLM is the largest multilingual open-source model that fits in a free Colab GPU. </p>
<blockquote>
<p><strong>Prompt Engineering Interactive Tutorial - Anthropics</strong> [<a target="_blank" rel="noopener" href="https://github.com/anthropics/courses/tree/master/prompt_engineering_interactive_tutorial/Anthropic%201P">Link</a>]</p>
</blockquote>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Google has an illegal monopoly on search, judge rules. Here’s what’s next - CNN</strong> [<a target="_blank" rel="noopener" href="https://amp-cnn-com.cdn.ampproject.org/c/s/amp.cnn.com/cnn/2024/08/05/business/google-loses-antitrust-lawsuit-doj">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Berkshire Hathaway sells off large share of Apple and increases cash holdings - The Guardian</strong> [<a target="_blank" rel="noopener" href="https://www.theguardian.com/business/article/2024/aug/03/berkshire-hathaway-warren-buffett-sells-off-apple-increases-cash-holdings">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Having accurate, reliable benchmarks for AI models matters, and not just for the bragging rights of the firms making them. Benchmarks “define and drive progress”, telling model-makers where they stand and incentivising them to improve, says Percy Liang of the Institute for Human-Centred Artificial Intelligence at Stanford University. Benchmarks chart the field’s overall progress and show how AI systems compare with humans at specific tasks. They can also help users decide which model to use for a particular job and identify promising new entrants in the space, says Clémentine Fourrier, a specialist in evaluating LLMs at Hugging Face, a startup that provides tools for AI developers.</em></p>
<p><strong>― GPT, Claude, Llama? How to tell which AI model is best - The Economist</strong> [<a target="_blank" rel="noopener" href="https://www.economist.com/science-and-technology/2024/07/31/gpt-claude-llama-how-to-tell-which-ai-model-is-best">Link</a>]</p>
</blockquote>
<p>Current benchmark MMLU (massive multi-task language understanding) has a few problems: 1) too easy for today’s models leading to the problem of ‘saturation’. New alternatives are developed such as MMLU-Pro, GPQA, MUSR, etc, 2) training data comes from internet which is a source of questions and answers for MMLU, resulting in a problem called “contamination”, 3) answers in MMLU tests are sometimes wrong or correct answers are more than one, 4) small changes in the way questions are posed to models can significantly affect their scores.</p>
<p>There are some trustworthy automated testing systems other than ChatBotArena leaderboard: HELM (holistic evaluation of language models) built by Dr Liang’s team at Stanford, and EleutherAI Harness uses by Dr Fourrier’s teams at Hugging Face for open source models.</p>
<p>As model gain new skills, new benchmarks are being developed to assess them. For example, GAIA tests model on real world problem solving, NoCha provides novel challenge, etc. However, new benchmarks are expensive to develop because they require human experts to create a detailed set of questions and answers. Dr Liang is working on project AutoBencher, Anthropic started funding the creation of benchmarks with a focus of AI safety.</p>
<blockquote>
<p><strong>GPT-4o mini: advancing cost-efficient intelligence - OpenAI News</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">Link</a>]</p>
</blockquote>
<p>GPT-4o is small and intelligent. It’s probably distilled from current or unreleased version of OpenAI’s models, similar to what Claude did with Claude Haiku and Google with Gemini Flash.</p>
<blockquote>
<p><strong>Made by Google 2024: Pixel 9, Gemini, a new foldable and other things to expect from the event - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/08/06/made-by-google-2024-pixel-9-gemini-a-new-foldable-and-other-things-to-expect-from-the-event/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>MIT releases comprehensive database of AI risks - VentureBeat</strong> [<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/mit-releases-comprehensive-database-of-ai-risks/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Apple will let other digital wallets into Apple Pay, and even be the default - ars technica</strong> [<a target="_blank" rel="noopener" href="https://arstechnica.com/gadgets/2024/08/apple-will-let-other-digital-wallets-into-apple-pay-and-even-be-the-default/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Apple Aiming to Launch Tabletop Robotic Home Device as Soon as 2026 With Pricing Around $1,000</strong> [<a target="_blank" rel="noopener" href="https://www.macrumors.com/2024/08/14/apple-tabletop-robotic-home-device-2026/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Sakana AI’s ‘AI Scientist’ conducts research autonomously, challenging scientific norms - VentureBeat</strong> [<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/sakana-ai-scientist-conducts-research-autonomously-challenging-scientific-norms/">Link</a>]</p>
</blockquote>
<p>Sakana AI unveils world’s first fully automatic ‘AI-Scientist’ generating complete research papers.</p>
<blockquote>
<p><strong>Scaling Laws, Economics and the AI “Game of Emperors.” - Gavin Baker</strong> [<a target="_blank" rel="noopener" href="https://x.com/gavinsbaker/status/1828862999836102800?s=12&utm_source=tldrnewsletter">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/11/The-Wisdom-of-the-Bullfrog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/08/11/The-Wisdom-of-the-Bullfrog/" class="post-title-link" itemprop="url">The Wisdom of the Bullfrog</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-08-11 09:34:39 / Modified: 12:31:05" itemprop="dateCreated datePublished" datetime="2024-08-11T09:34:39-04:00">2024-08-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>The book “The Wisdom of the Bullfrog” written by Admiral William H. McRaven is recommended by my mentor Dylan. It contains 18 sayings or mottos used in the military, which inspire Admiral William and others throughout his 4 decades Navy SEAL career.</p>
<p>Some favorite quotes from the author:</p>
<h3 id="Chapter-Three-When-in-Command-Command"><a href="#Chapter-Three-When-in-Command-Command" class="headerlink" title="Chapter Three - When in Command, Command"></a>Chapter Three - When in Command, Command</h3><blockquote>
<p>As a leader you must always appear to be in command, even on those days when you struggle with the pressures of the job. You must be confident. You must be decisive. You must smile. You must laugh. You must engage with your employees and be thankful for their work. You must have the look of a person in charge. You must instill in your men and women a sense of pride that their leader can handle any problem.</p>
<p>As a leader you can’t have a bad day. You must never look beaten, no matter the circumstance. If you sulk, if you hang your head, if you whine or complain about the leaders above you or the followers below you, then you will lose the respect of your men and women, and the attitude of despair will spread like wildfire.</p>
<p>Being a leader is an awesome responsibility. There are days when it can be frightening to know that the fate of the organization rests on your shoulders. But you must also realize that you were chosen to be the leader because you have proven yourself along the way. You have demonstrated that you know the business. You have shown that you can handle the pressures and be decisive. You have exhibited all the qualities necessary to lead. And even if none of the above holds true, now that you are the leader, you are in command. So, take the damn helm and command!</p>
</blockquote>
<h3 id="Chapter-Five-The-Only-Easy-Day-Was-Yesterday"><a href="#Chapter-Five-The-Only-Easy-Day-Was-Yesterday" class="headerlink" title="Chapter Five - The Only Easy Day Was Yesterday"></a>Chapter Five - The Only Easy Day Was Yesterday</h3><blockquote>
<p>The day you no longer believe you have something to prove, the day you no longer believe you must give it your all, the day you think you are entitled to special treatment, the day you think all your hard days are behind you, is the day you are no longer the right leader for the job.</p>
<p>Leadership requires energy. It requires stamina. It requires resilience. It requires everything you have and then some. The men and women that work for you will feed off your energy. If you look unprepared to deal with the challenges of the day, they will see this. If you look beaten down because today was harder than yesterday, they will feel this. If you are not prepared to give it your all, they will know this. And if you think this is just about leaders in combat, you’re mistaken. This is about every great leader who was given a difficult task and asked to inspire, motivate, and manage the people under their charge.</p>
</blockquote>
<h3 id="Chapter-Six-Run-to-the-Sound-of-the-Guns"><a href="#Chapter-Six-Run-to-the-Sound-of-the-Guns" class="headerlink" title="Chapter Six - Run to the Sound of the Guns"></a>Chapter Six - Run to the Sound of the Guns</h3><blockquote>
<p>Good leaders understand that organizations are going to have challenges. That’s why you were hired to lead. Embrace the challenge. Accept the fact that you must attack each problem with vigor and that sometimes only you, the leader, can solve the most vexing of institutional crises. Never shy away. Never retreat from a difficult problem.</p>
</blockquote>
<h3 id="Chapter-Eight-Who-Dares-Wins"><a href="#Chapter-Eight-Who-Dares-Wins" class="headerlink" title="Chapter Eight - Who Dares Wins"></a>Chapter Eight - Who Dares Wins</h3><blockquote>
<p>It is better to err on the side of daring than the side of caution.<br>     —Alvin Toffler, American writer and futurist</p>
</blockquote>
<h3 id="Chapter-Ten-No-Plan-Survives-First-Contact-with-the-Enemy"><a href="#Chapter-Ten-No-Plan-Survives-First-Contact-with-the-Enemy" class="headerlink" title="Chapter Ten - No Plan Survives First Contact with the Enemy"></a>Chapter Ten - No Plan Survives First Contact with the Enemy</h3><blockquote>
<p>No plan of operations reaches with any certainty beyond the first encounter of the enemy’s main force.<br>In other words, always have a Plan B. A contingency plan. A backup plan. Because once you encounter the enemy, no plan survives first contact.</p>
</blockquote>
<h3 id="Chapter-Fourteen-Expect-What-You-Inspect"><a href="#Chapter-Fourteen-Expect-What-You-Inspect" class="headerlink" title="Chapter Fourteen - Expect What You Inspect"></a>Chapter Fourteen - Expect What You Inspect</h3><blockquote>
<p>Truth is confirmed by inspection and delay; falsehood by haste and uncertainty.<br>     —Tacitus, Roman historian</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/07/Essentialism-The-Disciplined-Pursuit-of-Less/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/08/07/Essentialism-The-Disciplined-Pursuit-of-Less/" class="post-title-link" itemprop="url">Essentialism, The Disciplined Pursuit of Less</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-08-07 19:33:13" itemprop="dateCreated datePublished" datetime="2024-08-07T19:33:13-04:00">2024-08-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-08-19 01:18:30" itemprop="dateModified" datetime="2024-08-19T01:18:30-04:00">2024-08-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Essentialism written by Greg Mckeown is a book centered me to essentialism from my minimalism mindset and lifestyle. Dan recommended it to me in our first coffee chat :)</p>
<p>What Ela Bhatt said reminds me how I became a minimalism - </p>
<blockquote>
<p>Out of all virtues simplicity is my most favorite virtue. So much so that I tend to believe that simplicity can solve most of the problems, personal as well as the world problems. If the life approach is simple one need not lie so frequently, nor quarrel nor steal, nor envy, anger, abuse, kill. Everyone will have enough and plenty so need not hoard, speculate, gamble, hate. When character is beautiful, you are beautiful. That is the beauty of simplicity.</p>
</blockquote>
<h3 id="What-is-the-Core-Mindset-of-an-Essentialist"><a href="#What-is-the-Core-Mindset-of-an-Essentialist" class="headerlink" title="What is the Core Mindset of an Essentialist?"></a>What is the Core Mindset of an Essentialist?</h3><blockquote>
<p>The way of the Essentialist means living by design, not by default. Instead of making choices reactively, the Essentialist deliberately distinguishes the vital few from the trivial many, eliminates the nonessentials, and then removes obstacles so the essential things have clear, smooth passage. In other words, Essentialism is a disciplined, systematic approach for determining where our highest point of contribution lies, then making execution of those things almost effortless.</p>
</blockquote>
<blockquote>
<p>It is a discipline you apply each and every time you are faced with a decision about whether to say yes or whether to politely decline. It’s a method for making the tough trade-off between lots of good things and a few really great things. It’s about learning how to do less but better so you can achieve the highest possible return on every precious moment of your life.</p>
</blockquote>
<blockquote>
<p>A Nonessentialist approaches every trade-off by asking, “How can I do both?” Essentialists ask the tougher but ultimately more liberating question, “Which problem do I want?” An Essentialist makes trade-offs deliberately. She acts for herself rather than waiting to be acted upon. As economist Thomas Sowell wrote: “There are no solutions. There are only trade-offs.”</p>
</blockquote>
<p>It’s not only about mental discipline.</p>
<h3 id="Explore-Discerning-The-Trivial-Many-from-the-Vital-Few"><a href="#Explore-Discerning-The-Trivial-Many-from-the-Vital-Few" class="headerlink" title="Explore: Discerning The Trivial Many from the Vital Few"></a>Explore: Discerning The Trivial Many from the Vital Few</h3><p>Essentialisms systematically and deliberately explore and evaluate a broad set of options at first to ensure that they pick the right one later. This exploration requires time and space and this can be seen as trivial and unnecessary by nonessentialists. </p>
<p>We need to look for the lead rather than being distracted by minor details. we need to pay attention to those not explicitly stated rather than everything. We not only capture the dots, but also connect them to see the trends.</p>
<blockquote>
<p>He (Frank O’Brien) wrote: “I think it’s critical to set aside time to take a breath, look around, and think. You need that level of clarity in order to innovate and grow.” Furthermore, he uses the meeting as a litmus test to alert him if employees are spending too much time on the nonessential: “If somebody can’t make the meeting because of too much going on, that tells me either we’re doing something inefficiently or we need to hire more people.” If his people are too busy to think, then they’re too busy, period.</p>
</blockquote>
<blockquote>
<p>Being a journalist of your own life will force you to stop hyper-focusing on all the minor details and see the bigger picture. You can apply the skills of a journalist no matter what field you are in-you can even apply them to your personal life. By training yourself to look for “the lead,” you will suddenly find yourself able to see what you have missed. You’ll be able to do more than simply see the dots of each day: you’ll also connect them to see the trends. Instead of just reacting to the facts, you’ll be able to focus on the larger issues that really matter.</p>
</blockquote>
<p>We need to play to relieve stress and expand minds in ways that allow us to generate new ideas. We also need enough sleep hours to allow new neural connections to be made. </p>
<blockquote>
<p>Play expands our minds in ways that allow us to explore: to germinate new ideas or see old ideas in a new light. It makes us more inquisitive, more attuned to novelty, more engaged. </p>
</blockquote>
<blockquote>
<p>The best asset we have for making a contribution to the world is ourselves. If we underinvest in ourselves, and by that I mean our minds, our bodies, and our spirits, we damage the very tool we need to make our highest contribution. One of the most common ways people-especially ambitious, successful people-damage this asset is through a lack of sleep.</p>
</blockquote>
<blockquote>
<p>Sleep Is the New Status Symbol for Successful Entrepreneurs. </p>
</blockquote>
<h3 id="Eliminate-Cutting-Out-the-Trivial-Many"><a href="#Eliminate-Cutting-Out-the-Trivial-Many" class="headerlink" title="Eliminate: Cutting Out the Trivial Many"></a>Eliminate: Cutting Out the Trivial Many</h3><p>Clarity is the key.</p>
<blockquote>
<p>When there is a serious lack of clarity about what the team stands for and what their goals and roles are, people experience confusion, stress, and frustration. When there is a high level of clarity, on the other hand, people thrive.<br>When there is a lack of clarity, people waste time and energy on the trivial many. When they have sufficient levels of clarity, they are capable of greater breakthroughs and innovations- greater than people even realize they ought to have- in those areas that are truly vital. </p>
</blockquote>
<blockquote>
<p>Creating an essential intent is hard. It takes courage, insight, and foresight to see which activities and efforts will add up to your single highest point of contribution. It takes asking tough questions, making real trade-offs, and exercising serious discipline to cut out the competing priorities that distract us from our true intention. Yet it is worth the effort because only with real clarity of purpose can people, teams, and organizations fully mobilize and achieve something truly excellent.</p>
</blockquote>
<p>We need to make our choices about where to focus our energy and time purposefully and deliberately. This is necessary because “If you don’t prioritize your life, someone else will”. And this is not easy because sometime we are going against social expectation and we are under social pressure. We need courage and grace to navigate some hard moments.</p>
<blockquote>
<p>The only way out of this trap is to learn to say no firmly, resolutely, and yet gracefully. Because once we do, we find, not only that our fears of disappointing or angering others were exaggerated, but that people actually respect us more. Since becoming an Essentialist I have found it almost universally true that people respect and admire those with the courage of conviction to say no.</p>
</blockquote>
<blockquote>
<p>How do we learn to say no gracefully?</p>
<ol>
<li><p>Separate the decision from the relationship</p>
</li>
<li><p>Saying “No” gracefully doesn’t have to mean using the word No</p>
</li>
<li><p>Focus on the trade-off</p>
</li>
<li><p>Remind yourself that everyone is selling something</p>
</li>
</ol>
<p>  I am simply saying everyone is selling something-an idea, a viewpoint, an opinion-in exchange for your time. Simply being aware of what is being sold allows us to be more deliberate in deciding whether we want to buy it.</p>
<ol start="5">
<li>Make your peace with the fact that saying “No” often requires trading popularity for respect</li>
</ol>
<p>  When the initial annoyance or disappointment or anger wears off, the respect kicks in. When we push back effectively, it shows people that our time is highly valuable. It distinguishes the professional from the amateur.</p>
</blockquote>
<p>Becoming an Essentialism requires us to eliminate things that are really good in order to save time and space for something better.</p>
<blockquote>
<p>The Latin root of the word decision-cis or cid-literally means “to cut” or “to kill.” Since ultimately, having fewer options actually makes a decision “easier on the eye and the brain,” we must summon the discipline to get rid of options or activities that may be good, or even really good, but that get in the way. Yes, making the choice to eliminate something good can be painful. But eventually, every cut produces joy-maybe not in the moment but afterwards, when we realize that every. additional moment we have gained can be spent on something better. That may be one reason why Stephen King has written, “To write is human, to edit is divine.”</p>
</blockquote>
<blockquote>
<p>Condensing doesn’t mean doing more at once, it simply means less waste. It means lowering the ratio of words to ideas, square feet to usefulness, or effort to results. Thus to apply the principle of condensing to our lives we need to shift the ratio of activity to meaning. We need to eliminate multiple meaningless activities and replace them with one very meaningful activity.</p>
</blockquote>
<blockquote>
<p>Becoming an Essentialist means making cutting, condensing, and correcting a natural part of our daily routine-making editing a natural cadence in our lives.</p>
</blockquote>
<p>Setting boundaries is not having limits of life nor evidence of weakness. It’s a way of avoiding being distracted by something that is essential to others rather than that is essential to ourselves. We need to articulate our boundaries and set them up in advance.</p>
<blockquote>
<p>After all, if you don’t set boundaries-there won’t be any. Or even worse, there will be boundaries, but they’ll be set by default-or by another person-instead of by design.</p>
</blockquote>
<blockquote>
<p>Essentialists, on the other hand, see boundaries as empowering. They recognize that boundaries protect their time from being hijacked and often free them from the burden of having to say no to things that further others’ objectives instead of their own. They know that clear boundaries allow them to proactively eliminate the demands and encumbrances from others that distract them from the true essentials.</p>
</blockquote>
<blockquote>
<p>Whoever it is that’s trying to siphon off your time and energies for their own purpose, the only solution is to put up fences. And not at the moment the request is made, you need to put up your fences well in advance, clearly demarcating what’s off limits so you can head off time wasters and boundary pushers at the pass.</p>
</blockquote>
<blockquote>
<p>The simple reality is, if you can’t articulate these to yourself and others, it may be unrealistic to expect other people to respect them or even figure them out.</p>
</blockquote>
<h3 id="Execution-Removing-Obstacles-and-Making-Execution-Effortless"><a href="#Execution-Removing-Obstacles-and-Making-Execution-Effortless" class="headerlink" title="Execution: Removing Obstacles and Making Execution Effortless"></a>Execution: Removing Obstacles and Making Execution Effortless</h3><p>Time and space are required as a buffer to reduce friction and ensure success.</p>
<blockquote>
<p>The way of the Essentialist is different. The Essentialist looks ahead. She plans. She prepares for different contingencies. She expects the unexpected. She creates a buffer to prepare for the unforeseen, thus giving herself some wiggle room when things come up, as they inevitably do.</p>
</blockquote>
<blockquote>
<p>Essentialists accept the reality that we can never fully anticipate or prepare for every scenario or eventuality; the future is simply too unpredictable. Instead, they build in buffers to reduce the friction caused by the unexpected.</p>
</blockquote>
<p>Essentialists produce more by removing more instead of doing more.</p>
<blockquote>
<p>Essentialists don’t default to Band-Aid solutions. Instead of looking for the most obvious or immediate obstacles, they look for the ones slowing down progress. They ask, “What is getting in the way of achieving what is essential?” While the Nonessentialist is busy applying more and more pressure and piling on more and more solutions, the Essentialist simply makes a one-time investment in removing obstacles. This approach goes beyond just solving problems; it’s a method of reducing your efforts to maximize your results.</p>
</blockquote>
<p>Essentialists make progress by making small and concrete wins. It’s harder to make achievement when you set big, lofty, and impossible goals.</p>
<blockquote>
<p>The way of the Nonessentialist is to go big on everything: to try to do it all, have it all, fit it all in. The Nonessentialist operates under the false logic that the more he strives, the more he will achieve, but the reality is, the more we reach for the stars, the harder it is to get ourselves off the ground.</p>
<p>The way of the Essentialist is different. Instead of trying to accomplish it all and all at once, and flaring out, the Essentialist starts small and celebrates progress. Instead of going for the big, flashy wins that don’t really matter, the Essentialist pursues small and simple wins in areas that are essential.</p>
</blockquote>
<blockquote>
<p>A popular idea in Silicon Valley is “Done is better than perfect.” The sentiment is not that we should produce rubbish. The idea, as I read it, is not to waste time on nonessentials and just to get the thing done. In entrepreneurial circles the idea is expressed as creating a “minimal viable product.” The idea is, “What is the simplest possible product that will be useful and valuable to the intended customer?”</p>
</blockquote>
<p>Personalizing patterns of action (i.e. routine) allows us to pay more attention to matters that count rather than to other’s expectations.</p>
<blockquote>
<p>The way of the Nonessentialist is to think the essentials only get done when they are forced. That execution is a matter of raw effort alone. You labor to make it happen. You push through.</p>
<p>The way of the Essentialist is different. The Essentialist designs a routine that makes achieving what you have identified as essential the default position. Yes, in some instances an Essentialist still has to work hard, but with the right routine in place each effort yields exponentially greater results.”</p>
</blockquote>
<p>Be present - Focus on what is important now. Don’t pretend that you can multifocus. </p>
<blockquote>
<p>As he tells his players: “There is a difference between losing and being beaten. Being beaten means they are better than you. They are faster, stronger, and more talented.” To Larry, losing means something else. It means you lost focus. It means you didn’t concentrate on what was essential. It is all based on a simple but powerful idea: to operate at your highest level of contribution requires that you deliberately tune in to what is important in the here and now.</p>
</blockquote>
<blockquote>
<p>The ancient Greeks had two words for time. The first was chronos. The second was kairos. The Greek god Chronos was imagined as an elderly, gray-haired man, and his name connotes the literal ticking clock, the chronological time, the kind we measure (and race about trying to use efficiently). Kairos is different. While it is difficult to translate precisely, it refers to time that is opportune, right, different. Chronos is quantitative; kairos is qualitative. The latter is experienced only when we are fully in the moment-when we exist in the now.</p>
</blockquote>
<blockquote>
<p>Nonessentialists tend to be so preoccupied with past successes and failures, as well as future challenges and opportunities, that they miss the present moment. They become distracted. Unfocused. They aren’t really there.<br>The way of the Essentialist is to tune into the present. To experience life in kairos, not just chronos. To focus on the things that are truly important-not yesterday or tomorrow, but right now.</p>
</blockquote>
<blockquote>
<p>We can easily do two things at the same time. What we can’t do is concentrate on two things at the same time. When I talk about being present, I’m not talking about doing only one thing at a time. I’m talking about being focused on one thing at a time. Multitasking itself is not the enemy of Essentialism; pretending we can “multifocus” is.</p>
</blockquote>
<h3 id="Related-to-Leadership"><a href="#Related-to-Leadership" class="headerlink" title="Related to Leadership"></a>Related to Leadership</h3><p>Again, clarity is the key. </p>
<blockquote>
<p>When there was a high level of clarity of purpose, the teams and the people on it overwhelmingly thrived. When there was a serious lack of clarity about what the team stood for and what their goals and roles were, people experienced confusion, stress, frustration, and ultimately failure. As one senior vice president succinctly summarized it when she looked at the results gathered from her extended team: “Clarity equals success.”</p>
</blockquote>
<blockquote>
<p>The Nonessentialist disempowers people by allowing ambiguity over who is doing what. Often this is justified in the name of wanting to be a flexible or agile team. But what is actually created is a counterfeit agility. When people don’t know what they are really responsible for and how they will be judged on their performance, when decisions either are or appear to be capricious, and when roles are ill-defined, it isn’t long before people either give up or, worse, become obsessed with trying to look busy and therefore important instead of actually getting any real work done.</p>
</blockquote>
<blockquote>
<p>The Nonessentialist leader communicates in code, and as a result people aren’t sure what anything really means. Nonessentialist communication usually is either too general to be actionable or changes so quickly that people are always caught off guard. Essentialist leaders, on the other hand, communicate the right things to the right people at the right time. Essentialist leaders speak succinctly, opting for restraint in their communication to keep the team focused. When they do speak, they are crystal clear. They eschew meaningless jargon, and their message is so consistent it seems almost boring to their ears. In this way, teams are able to pick up the essential through all the trivial noise.</p>
</blockquote>
<p>Apply “less but better” in hiring people. </p>
<blockquote>
<p>And the cost of hiring too many wrong people (and one wrong hire often leads to multiple wrong hires because the wrong person will tend to attract more wrong people) is what Guy Kawasaki called a “Bozo explosion”—a term he uses to describe what happens when a formerly great team or company descends into mediocrity.</p>
</blockquote>
<blockquote>
<p>An Essentialist, on the other hand, is ridiculously selective on talent. She has the discipline to hold out for the perfect hire-no matter how many résumés she has to read, or interviews she has to conduct, or talent searches she has to make-and doesn’t hesitate to remove people who hold the team back. The result is a team full of all-star performers whose collective efforts add up to more than the sum of their parts.</p>
</blockquote>
<h3 id="Some-interesting-observations-or-research-results-mentioned"><a href="#Some-interesting-observations-or-research-results-mentioned" class="headerlink" title="Some interesting observations or research results mentioned"></a>Some interesting observations or research results mentioned</h3><p>This is how after you become a “go to” person and gain a lot of opportunities, you started to diffuse your efforts and be distracted by a lot of options.</p>
<blockquote>
<ol>
<li>The pursuit of success can be a catalyst for failure. Put another way, success can distract us from focusing on the essential things that produce success in the first place.</li>
<li>We are unprepared in part because, for the first time (in human history), the preponderance of choice has overwhelmed our ability to manage it. We have lost our ability to filter what is important and what isn’t. Psychologists call this “decision fatigue”: the more choices we are forced to make, the more the quality of our decisions deteriorates.</li>
</ol>
</blockquote>
<p>If you are an overachiever thinking you can do anything, how about taking the challenge of saying no to an opportunity and taking a nap.</p>
<blockquote>
<ol start="3">
<li>Stuart Brown, the founder of the National Institute for Play, has studied what are called the play histories of some six thousand individuals and has concluded that play has the power to significantly improve everything from personal health to relationships to education to organizations’ ability to innovate.<br>  “Play,” he says, “leads to brain plasticity, adaptability, and creativ-ity.” As he succinctly puts it, “Nothing fires up the brain like play.”</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>In a Harvard Business Review article called “Sleep Deficit: The Performance Killer,” Charles A. Czeisler, the Baldino Professor of Sleep Medicine at Harvard Medical School, has explained how sleep deprivation undermines high performance. He likens sleep deficit to drinking too much alcohol, explaining that pulling an all-nighter i.e., going twenty-four hours without sleep) or having a week of sleeping just four or five hours a night actually “induces an impairment equivalent to a blood alcohol level of 0.1%. Think about this: we would never say, ‘This person is a great worker! He’s drunk all the time!’ yet we continue to celebrate people who sacrifice sleep for work.”</li>
<li>The researchers explained that while we sleep our brains are hard at work encoding and restructuring information. Therefore, when we wake up, our brains may have made new neural connections, thereby opening up a broader range of solutions to problems, literally overnight.</li>
</ol>
</blockquote>
<p>Clarity is critical.</p>
<blockquote>
<ol start="6">
<li>In my work, I have noticed two common patterns that typically emerge when teams lack clarity of purpose.</li>
</ol>
<p>  a. Playing politics</p>
<p>  In the first pattern, the team becomes overly focused on winning the attention of the manager. The problem is, when people don’t know what the end game is, they are unclear about how to win, and as a result they make up their own game and their own rules as they vie for the manager’s favor. Instead of focusing their time and energies on making a high level of contribution, they put all their effort into games like attempting to look better than their peers, demonstrating their self-importance, and echoing their manager’s every idea or sentiment. These kinds of activities are not only nonessential but damaging and counterproductive.</p>
<p>  b. It’s all good (which is bad)</p>
<p>  In the second pattern, teams without purpose become leaderless. With no clear direction, people pursue the things that advance their own short-term interests, with little awareness of how their activities contribute to (or in some cases, derail) the long-term mission of the team as a whole.</p>
</blockquote>
<p>‘Uncommit’ is a way to minimize loss and win big.</p>
<blockquote>
<ol start="7">
<li>Sunk-cost bias is the tendency to continue to invest time, money, or energy into something we know is a losing proposition simply because we have already incurred, or sunk, a cost that cannot be re-couped. But of course this can easily become a vicious cycle: the more we invest, the more determined we become to see it through and see our investment pay off. The more we invest in something, the harder it is to let go.</li>
</ol>
</blockquote>
<p>The power of small wins.</p>
<blockquote>
<ol start="8">
<li>Research has shown that of all forms of human motivation the most effective one is progress. Why? Because a small, concrete win creates momentum and affirms our faith in our further success. In his 1968 Harvard Business Review article entitled “One More Time: How Do You Motivate Employees?” among the most popular Harvard Business Review articles of all time, Frederick Herzberg reveals research showing that the two primary internal motivators for people are achievement and recognition for achievement.</li>
</ol>
</blockquote>
<blockquote>
<ol start="9">
<li>Indeed, today Zimbardo is attempting a grand social experiment along those lines called the “Heroie Imagination Project.” The logic is to increase the odds of people operating with courage by teaching them the principles of heroism. By encouraging and rewarding heroic acts, Zimbardo believes, we can consciously and deliberately create a system where heroic aets eventually become natural and effortless.</li>
</ol>
</blockquote>
<p>Be present and focus on one thing.</p>
<blockquote>
<ol start="10">
<li>Thich Nhat Hanh, the Vietnamese Zen Buddhist monk who has been called the “world’s calmest man,” has spent a lifetime exploring how to live in kairos, albeit by a different name. He has taught it as mindfulness or maintaining “beginner’s mind.” He has written: “Mindfulness helps you go home to the present. And every time you go there and recognize a condition of happiness that you have, happiness comes.”</li>
</ol>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/27/Biased-and-Debiased-Machine-Learning-in-Causal-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/27/Biased-and-Debiased-Machine-Learning-in-Causal-Inference/" class="post-title-link" itemprop="url">Biased and Debiased Machine Learning in Causal Inference</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-27 21:53:36" itemprop="dateCreated datePublished" datetime="2024-07-27T21:53:36-04:00">2024-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-28 12:52:30" itemprop="dateModified" datetime="2024-07-28T12:52:30-04:00">2024-07-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>The application of machine learning methods in estimating treatment effects is a burgeoning area in causal inference. The regression function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span> and the propensity score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">e</span></span></span></span> used to estimate the average treatment effects can be estimated using machine learning methods like random forests. However, the naive applications of machine learning methods to estimate treatment effects lead to biased estimates due to regularization bias. The proof examines the asymptotic behavior of the estimator.</p>
<h2 id="Proof-Process"><a href="#Proof-Process" class="headerlink" title="Proof Process"></a>Proof Process</h2><ol>
<li><p><strong>Define the Model and Estimator</strong>:</p>
<ul>
<li>Assume a partially linear regression model where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> is the outcome, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> is the treatment indicator, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> represents covariates.</li>
<li>The regression function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and the propensity score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> are modeled non-parametrically using machine learning methods.</li>
</ul>
</li>
<li><p><strong>Assumptions</strong>:</p>
<ul>
<li>Treatment assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> is unconfounded given covariates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>.</li>
<li>Residuals (errors) satisfy usual assumptions (e.g., mean zero, finite variance).</li>
</ul>
</li>
<li><p><strong>Estimator Definition</strong>:</p>
<ul>
<li>Split the data into two groups.</li>
<li>Estimate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> using the second group with a machine learning method.</li>
<li>Regress <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y−\hat{g}(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> in the first group to obtain the estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> for the treatment effect.</li>
</ul>
</li>
<li><p><strong>Rewrite the Estimator</strong>:</p>
<ul>
<li><p>Express the estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> in a form that separates the effect of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and the residuals: </p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>treated</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>control</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\theta} = \frac{1}{N_1} \sum_{i \in \text{treated}} \left[ Y_i - \hat{g}(X_i) \right] - \frac{1}{N_0} \sum_{i \in \text{control}} \left[ Y_i - \hat{g}(X_i) \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">treated</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">control</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span></li>
</ul>
</li>
<li><p><strong>Decompose into Asymptotic Terms</strong>:</p>
<ul>
<li><p>Decompose <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> into terms that reveal the contributions of the estimation error from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{g}(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and the residuals:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mi>θ</mi><mo>+</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>treated</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>ϵ</mi><mi>i</mi></msub><mo>−</mo><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>control</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>ϵ</mi><mi>i</mi></msub><mo>−</mo><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\theta} = \theta + \frac{1}{N_1} \sum_{i \in \text{treated}} \left[ \epsilon_i - (\hat{g}(X_i) - g(X_i)) \right] - \frac{1}{N_0} \sum_{i \in \text{control}} \left[ \epsilon_i - (\hat{g}(X_i) - g(X_i)) \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">treated</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">control</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span></li>
</ul>
</li>
<li><p><strong>Analyze Asymptotic Distribution</strong>:</p>
<ul>
<li><strong>First Term</strong>: Under usual regularity conditions, the term involving <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\epsilon_i </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (residuals) converges in distribution to a normal distribution.</li>
<li><strong>Second Term</strong>: The term involving <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{g}(X_i) - g(X_i) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> represents the bias due to regularization in the machine learning method. This term does not have mean zero and can diverge to infinity.</li>
</ul>
</li>
<li><p><strong>Conclusion on Bias</strong>:</p>
<ul>
<li>The second term introduces bias because the machine learning method’s regularization bias does not vanish asymptotically.</li>
<li>This results in the estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> being asymptotically biased, even if the first term converges to a normal distribution.</li>
</ul>
</li>
</ol>
<h3 id="Detailed-Example"><a href="#Detailed-Example" class="headerlink" title="Detailed Example"></a>Detailed Example</h3><ol>
<li><p><strong>Model Setup</strong>:</p>
<ul>
<li>Let <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>Z</mi><mi>θ</mi><mo>+</mo><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">Y=Zθ+g(X)+ϵ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Zθ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span></li>
<li>Estimate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> using a machine learning method (e.g., random forest).</li>
</ul>
</li>
<li><p><strong>Estimator</strong>:</p>
<ul>
<li><p>Split data into two parts.</p>
</li>
<li><p>Use part one to estimate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{g}(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>.</p>
</li>
<li><p>Use part two to calculate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span>: </p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msub><mi>Z</mi><mi>i</mi></msub><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{\theta} = \frac{1}{N_1} \sum_{i=1}^{N_1} (Y_i - \hat{g}(X_i)) Z_i - \frac{1}{N_0} \sum_{i=1}^{N_0} (Y_i - \hat{g}(X_i)) (1 - Z_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
<li><p><strong>Asymptotic Analysis</strong>:</p>
<ul>
<li><p>Rewrite the estimator to separate terms: </p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mi>θ</mi><mo>+</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><msub><mi>ϵ</mi><mi>i</mi></msub><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><msub><mi>ϵ</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\theta} = \theta + \left( \frac{1}{N_1} \sum_{i=1}^{N_1} \epsilon_i - \frac{1}{N_0} \sum_{i=1}^{N_0} \epsilon_i \right) - \left( \frac{1}{N_1} \sum_{i=1}^{N_1} (\hat{g}(X_i) - g(X_i)) - \frac{1}{N_0} \sum_{i=1}^{N_0} (\hat{g}(X_i) - g(X_i)) \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></li>
</ul>
</li>
<li><p><strong>Identify Bias Term</strong>:</p>
<ul>
<li>The second term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{N_1} \sum_{i=1}^{N_1} (\hat{g}(X_i) - g(X_i)) - \frac{1}{N_0} \sum_{i=1}^{N_0} (\hat{g}(X_i) - g(X_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span> represents the bias due to regularization in the machine learning method.</li>
</ul>
</li>
<li><p><strong>Conclusion</strong>:</p>
<ul>
<li>The bias term does not converge to zero, leading to an asymptotically biased estimator.</li>
<li>This illustrates why naive application of machine learning methods without addressing regularization bias can lead to incorrect estimates of treatment effects.</li>
</ul>
</li>
</ol>
<h2 id="Steps-to-Obtain-a-Debiased-Estimator"><a href="#Steps-to-Obtain-a-Debiased-Estimator" class="headerlink" title="Steps to Obtain a Debiased Estimator"></a>Steps to Obtain a Debiased Estimator</h2><p>To obtain a debiased estimator using machine learning methods, we follow a systematic approach that addresses the regularization bias inherent in machine learning models. Here is a detailed process:</p>
<h4 id="1-Setup-the-Problem"><a href="#1-Setup-the-Problem" class="headerlink" title="1. Setup the Problem"></a>1. <strong>Setup the Problem</strong></h4><p>Define the outcome <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>, treatment indicator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>, and covariates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. The objective is to estimate the average treatment effect (ATE).</p>
<h4 id="2-Split-the-Data"><a href="#2-Split-the-Data" class="headerlink" title="2. Split the Data"></a>2. <strong>Split the Data</strong></h4><p>Divide the dataset into two parts to avoid overfitting and ensure valid inference:</p>
<ul>
<li><strong>Part 1</strong>: Used to estimate the propensity score.</li>
<li><strong>Part 2</strong>: Used to estimate the regression function.</li>
</ul>
<h4 id="3-Estimate-the-Propensity-Score"><a href="#3-Estimate-the-Propensity-Score" class="headerlink" title="3. Estimate the Propensity Score"></a>3. <strong>Estimate the Propensity Score</strong></h4><p>Using <strong>Part 1</strong> of the data, estimate the propensity score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(X) = P(Z = 1 | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>. This can be done using a machine learning model such as logistic regression, random forests, or other methods.</p>
<h4 id="4-Estimate-the-Regression-Function"><a href="#4-Estimate-the-Regression-Function" class="headerlink" title="4. Estimate the Regression Function"></a>4. <strong>Estimate the Regression Function</strong></h4><p>Using <strong>Part 2</strong> of the data, estimate the regression function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">g(X) = E[Y | X]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">]</span></span></span></span> using a machine learning model such as random forests, gradient boosting machines, or any other suitable method.</p>
<h4 id="5-Calculate-Residuals"><a href="#5-Calculate-Residuals" class="headerlink" title="5. Calculate Residuals"></a>5. <strong>Calculate Residuals</strong></h4><p>For the treated and control groups in <strong>Part 2</strong> of the data, calculate the residuals:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>U</mi><mo>^</mo></mover><mi>i</mi></msub><mo>=</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{U}_i = Y_i - \hat{g}(X_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0968em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>

<h4 id="6-Debiasing-Step"><a href="#6-Debiasing-Step" class="headerlink" title="6. Debiasing Step"></a>6. <strong>Debiasing Step</strong></h4><p>Estimate the treatment effect using the residuals and propensity scores. Calculate the debiased estimate by adjusting for the propensity score:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mover accent="true"><mi>e</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mover accent="true"><mi>e</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow><mo>+</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{\theta} = \frac{1}{N} \sum_{i=1}^N \left( \frac{Z_i (Y_i - \hat{g}(X_i))}{\hat{e}(X_i)} - \frac{(1 - Z_i) (Y_i - \hat{g}(X_i))}{1 - \hat{e}(X_i)} \right) + \frac{1}{N} \sum_{i=1}^N \hat{g}(X_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight">e</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">))</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight">e</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">))</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>

<h4 id="7-Variance-Estimation"><a href="#7-Variance-Estimation" class="headerlink" title="7. Variance Estimation"></a>7. <strong>Variance Estimation</strong></h4><p>Estimate the variance of the debiased estimator to construct confidence intervals. This step involves calculating the standard error of the debiased estimate.</p>
<h4 id="8-Construct-Confidence-Intervals"><a href="#8-Construct-Confidence-Intervals" class="headerlink" title="8. Construct Confidence Intervals"></a>8. <strong>Construct Confidence Intervals</strong></h4><p>Using the standard error, construct confidence intervals for the treatment effect estimate.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/27/Lecture-Note-Overview-of-Modern-Approach-of-Causal-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/27/Lecture-Note-Overview-of-Modern-Approach-of-Causal-Inference/" class="post-title-link" itemprop="url">Lecture Note - Overview of Modern Approach of Causal Inference</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-27 18:22:52" itemprop="dateCreated datePublished" datetime="2024-07-27T18:22:52-04:00">2024-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-28 12:54:42" itemprop="dateModified" datetime="2024-07-28T12:54:42-04:00">2024-07-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>This is one of my notes of the online Causal Inference Course in Columbia University, taught by Michael E. Sobel who is a professor in the Department of Statistics. It would be good to have this overview of causal inference regarding the framework in mind before getting into statistical and theoretical details especially for beginners. A clear approach framework is very important that it’s not only because rigorous experiment and analysis methods could be developed with this well-defined framework, but also because it can guide you to deal with challenging situations in a correct way, while being clear about the limitations and assumptions at the same time. This is why it became a Science.</p>
<h1 id="Modern-Approach-for-Causal-Inference"><a href="#Modern-Approach-for-Causal-Inference" class="headerlink" title="Modern Approach for Causal Inference"></a>Modern Approach for Causal Inference</h1><p>The modern dominant approach for causal inference, significantly influenced by Donald Rubin’s contributions, primarily revolves around the following key ideas:</p>
<ol>
<li><p>Potential Outcomes Framework:</p>
<ul>
<li><strong>Potential Outcomes Notation</strong>: Introduced by Neyman and further developed by Rubin, this framework involves conceptualizing the outcomes that would occur both with and without the treatment for each unit. Each unit has a potential outcome under treatment and a potential outcome under control, but only one of these outcomes is observed for each unit.</li>
<li><strong>Average Treatment Effects</strong>: The focus is on estimating the average causal effect of a treatment across a population. This involves comparing the average outcomes of treated and untreated groups, taking into account the potential outcomes framework.</li>
</ul>
</li>
<li><p>Randomization and Its Analogs:</p>
<ul>
<li><strong>Role of Randomization</strong>: In experimental studies, random assignment of treatments is crucial for ensuring that the treatment groups are comparable, allowing for unbiased estimation of causal effects.</li>
<li><strong>Randomization-like Conditions in Observational Studies</strong>: Rubin extended the framework to observational studies by arguing that causal inferences can be made if these studies fulfill conditions similar to randomization. This involves controlling for confounding variables that influence both the treatment and the outcome, often through methods like matching, regression adjustment, or instrumental variables.</li>
</ul>
</li>
<li><p>Counterfactual Reasoning:</p>
<ul>
<li><strong>Counterfactual Conditionals</strong>: Causal relationships must satisfy counterfactual conditions. This means that for a cause to be deemed responsible for an effect, it should be demonstrable that if the cause had not occurred, the effect would not have occurred. This is formalized through the potential outcomes framework.</li>
</ul>
</li>
</ol>
<h2 id="Key-Features-of-Rubin’s-Approach"><a href="#Key-Features-of-Rubin’s-Approach" class="headerlink" title="Key Features of Rubin’s Approach:"></a>Key Features of Rubin’s Approach:</h2><ul>
<li><strong>Application to Both Experimental and Observational Studies</strong>: Rubin’s framework is versatile and can be applied to both types of studies, providing a unified approach to causal inference.</li>
<li><strong>Focus on Estimating Causal Effects</strong>: The primary goal is to estimate the causal effect of treatments or interventions, rather than simply identifying associations.</li>
<li><strong>Use of Statistical Methods</strong>: The approach leverages statistical methods to control for confounding variables and to estimate causal effects, emphasizing the importance of rigorous statistical analysis.</li>
</ul>
<h2 id="Two-Key-Criteria-of-Modern-Causal-Inference"><a href="#Two-Key-Criteria-of-Modern-Causal-Inference" class="headerlink" title="Two Key Criteria of Modern Causal Inference"></a>Two Key Criteria of Modern Causal Inference</h2><p>The modern dominant approach to causal inference primarily builds on two key criteria:</p>
<ol>
<li><p>Causation at the Singular Level:</p>
<ul>
<li>This criterion allows for the possibility that causation can be specific to individual subjects or units, acknowledging effect heterogeneity. It means that a cause may produce an effect in one individual but not necessarily in another, depending on various conditions.</li>
</ul>
</li>
<li><p>Satisfaction of Counterfactual Conditionals:</p>
<ul>
<li>A causal relationship must sustain a counterfactual conditional. This means that for a cause to be deemed responsible for an effect, it should be demonstrable that if the cause had not occurred, the effect would not have occurred. This criterion is essential for defining and reasoning about causal relationships in both experimental and observational studies.</li>
</ul>
</li>
</ol>
<h2 id="Impact-on-Empirical-Research"><a href="#Impact-on-Empirical-Research" class="headerlink" title="Impact on Empirical Research:"></a>Impact on Empirical Research:</h2><p>Rubin’s contributions have led to more careful and precise inferences about causal effects in various disciplines, particularly in the social sciences. Researchers now more rigorously design studies and analyze data to ensure that their conclusions about causality are well-founded within this robust statistical framework.</p>
<h2 id="Challenges-in-Randomized-Studies"><a href="#Challenges-in-Randomized-Studies" class="headerlink" title="Challenges in Randomized Studies:"></a>Challenges in Randomized Studies:</h2><ol>
<li><p>Non-compliance with Treatment Assignments:</p>
<ul>
<li><strong>Example</strong>: In a study by the University of Michigan in the 1990s, unemployed persons were assigned to receive or not receive assistance in job searching. A significant percentage of those assigned to the treatment group did not actually take the treatment, complicating the comparison between groups and potentially overestimating the treatment’s effectiveness.</li>
</ul>
</li>
<li><p>Intermediate Variables:</p>
<ul>
<li><strong>Example</strong>: An educational researcher wants to know the effect of encouragement to study on test scores. While the researcher can estimate the effect of encouragement, estimating the direct effect of study time is more complicated because it involves intermediate variables (encouragement affecting study time, which in turn affects test scores).</li>
</ul>
</li>
<li><p>Breakdown of Random Assignment:</p>
<ul>
<li><strong>Example</strong>: If a subject’s treatment adherence is influenced by their perception of treatment benefits, comparing only those who comply can lead to biased estimates.</li>
</ul>
</li>
</ol>
<h2 id="Challenges-in-Observational-Studies"><a href="#Challenges-in-Observational-Studies" class="headerlink" title="Challenges in Observational Studies:"></a>Challenges in Observational Studies:</h2><ol>
<li><p>Identifying and Measuring All Covariates:</p>
<ul>
<li><strong>Example</strong>: When studying the effect of education on earnings, researchers must account for various covariates that affect both education levels and earnings. Failure to identify or measure all relevant covariates can lead to biased estimates.</li>
</ul>
</li>
<li><p>Estimating Average Treatment Effects:</p>
<ul>
<li><strong>Example</strong>: In observational studies, various methods like matching, weighting, and regression are used to estimate treatment effects. Each method has its own set of practical issues and assumptions that need to be carefully managed.</li>
</ul>
</li>
<li><p>Longitudinal Observational Studies:</p>
<ul>
<li><strong>Example</strong>: When treatments administered in different periods depend on previous treatments and outcomes, analysis becomes more complicated.</li>
</ul>
</li>
<li><p>Interference:</p>
<ul>
<li><strong>Example</strong>: In a housing experiment conducted by the U.S. government, participants assigned to move from housing projects to suburbs knew each other. If the treatment assignment of one participant influenced the decision or outcome of another, traditional analysis methods might not be adequate.</li>
</ul>
</li>
</ol>
<p>These examples illustrate that both randomized and observational studies require careful consideration of various factors to ensure accurate and reliable causal inferences.</p>
<h1 id="Potential-Outcomes-Unit-and-Average-Effect"><a href="#Potential-Outcomes-Unit-and-Average-Effect" class="headerlink" title="Potential Outcomes, Unit, and Average Effect"></a>Potential Outcomes, Unit, and Average Effect</h1><h2 id="Potential-Outcomes-Framework"><a href="#Potential-Outcomes-Framework" class="headerlink" title="Potential Outcomes Framework"></a>Potential Outcomes Framework</h2><ol>
<li>Potential Outcomes:<ul>
<li>Each unit (e.g., individual) has two potential outcomes: one if treated and one if not treated. However, only one outcome can be observed for each unit.</li>
<li>This leads to the “fundamental problem of causal inference,” where we cannot observe both potential outcomes for a single unit.</li>
</ul>
</li>
<li>Notation and Unit Effects:<ul>
<li>For a unit <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>, denote the outcome as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y_i (1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> if treated and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y_i (0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0</span><span class="mclose">)</span></span></span></span> if not treated.</li>
<li>The unit effect is defined as the difference <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y_i (1)−Y_i (0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0</span><span class="mclose">)</span></span></span></span>.</li>
<li>The observed outcome Yi is determined by the treatment assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">Z_i=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> if the unit is treated and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">Z_i=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> if not.</li>
</ul>
</li>
<li>Randomized vs. Observational Studies:<ul>
<li>In randomized experiments, treatment assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is random.</li>
<li>In observational studies, subjects choose their treatment, introducing potential biases.</li>
</ul>
</li>
</ol>
<h2 id="Average-Treatment-Effects"><a href="#Average-Treatment-Effects" class="headerlink" title="Average Treatment Effects"></a>Average Treatment Effects</h2><ol>
<li>Sample Average Treatment Effect (SATE):<ul>
<li>The average of the unit effects for the sample.</li>
</ul>
</li>
<li>Finite Population Average Treatment Effect (FATE):<ul>
<li>The average treatment effect for a finite population from which the sample is drawn.</li>
</ul>
</li>
<li>Average Treatment Effect (ATE):<ul>
<li>The average treatment effect in an infinite or large population. This is treated as an expectation of the potential outcomes.</li>
</ul>
</li>
<li>Estimands of Interest:<ul>
<li>Various estimands depend on the marginal distributions of potential outcomes, such as ATE and Average Treatment Effect on the Treated (ATT).</li>
</ul>
</li>
<li>Challenges and Assumptions:<ul>
<li>Estimating these effects requires assumptions like the Stable Unit Treatment Value Assumption (SUTVA), which ensures that the potential outcomes are well-defined and not affected by other units’ treatments.</li>
</ul>
</li>
</ol>
<h2 id="Practical-Implications"><a href="#Practical-Implications" class="headerlink" title="Practical Implications"></a>Practical Implications</h2><ol>
<li>Decision-Making:<ul>
<li>Knowledge of average treatment effects aids decision-making in contexts like medical treatments and policy implementations.</li>
</ul>
</li>
<li>Ignorability Conditions:<ul>
<li>Under certain conditions, known as ignorability or unconfoundedness, it is possible to use observed data to estimate causal effects reliably.</li>
</ul>
</li>
<li>Extensions and Assumptions:<ul>
<li>The framework extends to multiple treatments and continuous treatments, though additional assumptions may be required.</li>
<li>SUTVA assumes no alternative representations of treatment and no interference between units, which may need adjustments in certain studies.</li>
</ul>
</li>
</ol>
<h1 id="Conditions-Allow-Average-Effects-be-Unbiasedly-Consistently-Estimated"><a href="#Conditions-Allow-Average-Effects-be-Unbiasedly-Consistently-Estimated" class="headerlink" title="Conditions Allow Average Effects be Unbiasedly&#x2F; Consistently Estimated"></a>Conditions Allow Average Effects be Unbiasedly&#x2F; Consistently Estimated</h1><h2 id="Key-Concepts"><a href="#Key-Concepts" class="headerlink" title="Key Concepts"></a>Key Concepts</h2><ol>
<li>Average Treatment Effect (ATE) Estimation:<ul>
<li><strong>Random Sampling</strong>: Drawing random samples of treated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) and untreated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) units to estimate their respective means.</li>
<li><strong>Sample Means</strong>: The means of treated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\bar{y}_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) and untreated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\bar{y}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) samples serve as unbiased and consistent estimators of the population means.</li>
</ul>
</li>
<li>Unconfoundedness:<ul>
<li><strong>Definition</strong>: Treatment assignment z is independent of potential outcomes (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li>
<li><strong>Intuition</strong>: In randomized experiments, treatment assignment is blind to potential outcomes, ensuring unconfoundedness. In observational studies, treatment assignment might depend on factors related to potential outcomes, potentially confounding the estimates.</li>
</ul>
</li>
</ol>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><ol>
<li>Randomized Experiment vs. Observational Study:<ul>
<li><strong>Randomized Experiment</strong>: Treatment assignment is random (e.g., coin flip), ensuring <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> is independent of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li>
<li><strong>Observational Study</strong>: Treatment assignment may depend on patient characteristics, potentially leading to biased estimates.</li>
</ul>
</li>
<li>Age and Treatment Example:<ul>
<li><strong>Scenario</strong>: Older patients might forego treatment believing it’s less beneficial, while younger patients might opt for treatment believing it’s more beneficial.</li>
<li><strong>Consequence</strong>: Naive comparison between treated and untreated groups might overestimate the treatment effect due to confounding by age.</li>
</ul>
</li>
</ol>
<h2 id="Ignorability-Condition"><a href="#Ignorability-Condition" class="headerlink" title="Ignorability Condition"></a>Ignorability Condition</h2><ol>
<li>Condition: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are independent of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> given covariates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> (e.g., age).<ul>
<li><strong>Stratified Analysis</strong>: In both randomized experiments and observational studies, stratifying on covariates like age can help achieve conditional unconfoundedness.</li>
</ul>
</li>
<li>Adjusting for Covariates:<ul>
<li><strong>Randomized Experiment</strong>: Can stratify on covariates either before or after the experiment.</li>
<li><strong>Observational Study</strong>: Treat it as a stratified randomized experiment by conditioning on covariates related to treatment status and potential outcomes.</li>
</ul>
</li>
</ol>
<h2 id="Practical-Implications-1"><a href="#Practical-Implications-1" class="headerlink" title="Practical Implications"></a>Practical Implications</h2><ol>
<li>Comparison of Groups:<ul>
<li>In a stratified randomized experiment, compare treated and control groups within each stratum (e.g., age group) to estimate ATE.</li>
<li>In observational studies, stratify on covariates to reduce bias and estimate ATE as if it were a stratified randomized experiment.</li>
</ul>
</li>
<li>Challenges in Observational Studies:<ul>
<li><strong>Unknown Assignment Mechanism</strong>: Unlike randomized experiments, the assignment mechanism in observational studies is not controlled, making it harder to ensure unconfoundedness.</li>
<li><strong>Measurement of Confounders</strong>: It’s crucial to measure and account for all relevant confounders, though it may not always be possible.</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/20/2024-July/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/20/2024-July/" class="post-title-link" itemprop="url">2024 July</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-20 00:22:38" itemprop="dateCreated datePublished" datetime="2024-07-20T00:22:38-04:00">2024-07-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-01 17:16:41" itemprop="dateModified" datetime="2024-09-01T17:16:41-04:00">2024-09-01</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><strong>Playing defense: How to control the narrative if your work is being questioned - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/playing-defense-how-to-control-narrative">Link</a>]</p>
</blockquote>
<p>It’s normal that people will misunderstand and disagree with you. what we need to do is to 1) learn to explain your ideas better and 2) stay calm and share your thought process in the most objective way possible.</p>
<p>Defending your thinking means to share logic, evidence and rationale that explains why you believe your conclusion is the right one. It’s not to try to protect your ego by refusing to acknowledge a good argument, and being delusional about the strength of your claim. Being able to play defense is important because it’s about your credibility. If you do it well you are building more trust, otherwise you will be diminishing trust.</p>
<p>Some suggestions mentioned in this article:</p>
<ul>
<li>﻿﻿Have a rationale of every small decision you made.</li>
<li>﻿﻿Try to anticipate questions.</li>
<li>﻿﻿Embrace “show, not tell”</li>
<li>﻿﻿React as positively as possible. e.g.<br> “Ah! I’m so glad you asked”.</li>
<li>﻿﻿Consider the question behind the question.</li>
<li>﻿﻿Be happy that the person voiced their concern.</li>
<li>﻿﻿Beware of insecure vibes.</li>
</ul>
<p>If you overcompensate, you’ll come across as defensive. This decreases your credibility too. You’ll need to use your judgment and read the situation. An open, curious, and almost playful attitude shows you’re not afraid of hard questions.</p>
<p>Many people underestimate the daily moments where your credibility can either be reinforced or eroded. This might sound dramatic, but it’s quite banal: Every interaction folks have with you gets added to their subconscious cumulative repository of data points about you.</p>
<blockquote>
<p><em>Insecure vibes are subconscious clues and signals that you might be giving off when you’re feeling anxious, nervous, or uncertain. Get rid of insecure vibes—and your writing, meetings, presentations, negotiations, and pitches will become stronger.</em></p>
<p><strong>― “Insecure vibes” are a self-fulfilling prophecy - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/insecure-vibes-are-a-self-fulfilling">Link</a>]</p>
</blockquote>
<p>In the following situations, insecure vibes happen: </p>
<ul>
<li><p>When other person touched on your sore spot and you feel threatened</p>
</li>
<li><p>You assume the person will say no before you even start</p>
<p>This can make you talk fast - showing you enter the conversation already playing defense. You don’t give the person a chance to say yes because you’ve already said no to yourself.</p>
</li>
<li><p>You insist on email or slack when you know a phone call is better</p>
<p>Explaining your point in writing is a sign of lacking confidence and avoiding confrontation.</p>
</li>
<li><p>You over-explain because you expect the other person to be skeptical</p>
<p>You bring up counterpoints to arguments no one has mentioned. Not a good time to do so. It looks like you intentionally bring up something new to surprise others rather than having a reasonable justification of your point.</p>
</li>
</ul>
<p>To avoid being doubtful if you actually feel confident:</p>
<ul>
<li>Don’t preface your idea with too many caveats. Speak in complete sentences. Remove “ands” and “buts” that create never-ending sentences, which can sound less authoritative. </li>
<li>Notice if you start to ramble. Try to prepare the first few lines of what you want to say to kick off a meeting, so you start strong. </li>
<li>Practice your actual script so you get comfortable saying those words.</li>
</ul>
<p>To get rid of insecure vibes, ask yourself</p>
<ul>
<li>Could this be interpreted as sounding defensive?</li>
<li>Am I overcompensating or overexplaining?</li>
<li>How would I respond on my best day?</li>
<li>Would I say this if I felt secure?</li>
</ul>
<blockquote>
<p><strong>Strategy, not self-expression: How to decide what to say when giving feedback - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/strategy-not-self-expression">Link</a>]</p>
</blockquote>
<p>Ask yourself “Is this strategy or self expression?” before giving feedback.</p>
<ul>
<li>Do not self-express your feeling or complain. Do not say anything that does not motivate them to change. Instead, say things that get you closer to changing the person’s behavior.</li>
</ul>
<p>How to focus on strategy rather than self-expression:</p>
<ul>
<li><p>Mentally forgive this person</p>
</li>
<li><p>Identify what is most likely to motivate them to change, </p>
</li>
<li><p>Say only 10% that will actually change behavior, thinking about:</p>
<ul>
<li>How does this make them even more effective?</li>
<li>How will this allow them to work even better with the people around them?</li>
<li>How does this get them closer to their goals?</li>
<li>How is this a skill they can apply now and in all future roles?</li>
</ul>
</li>
<li><p>Don’t trigger the defensiveness in the first place</p>
<p>The minute your recipient gets defensive, it becomes a lot harder to undo the defensiveness and get them to accept what you’re saying. </p>
</li>
<li><p>Let the other person talk, e.g.  “I’d love to hear what you think. What parts are resonating most with you?”</p>
<p>The other benefit of letting the other person talk is <em>cognitive dissonance</em>: if they say out loud what they are committed to doing differently, they are reinforcing the idea in their own mind. </p>
</li>
<li><p>Keep your eyes on the person’s behavior change</p>
</li>
<li><p>Always be framing</p>
<p>“Strategy, not self-expression” applies to many more situations too.</p>
</li>
</ul>
<blockquote>
<ol>
<li><em>The more controversial the idea, the higher the burden of proof.</em></li>
<li><em>Update your assumptions about how you add value.</em></li>
<li><em>Share where your hunch is coming from—because it’s coming from somewhere.</em></li>
<li><em>Describe why the problem matters, so people understand why you’re speaking up.</em></li>
<li><em>Don’t rely on your credentials. Your idea should make sense on its own.</em></li>
<li><em>Use language that accurately reflects your level of certainty.</em></li>
</ol>
<p><strong>― How to share your point of view (even if you’re afraid of being wrong) - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/high-performers-share-their-point-of-view">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Every week, we make business cases at work. I’m defining a business case as any recommendation to pursue a business opportunity or solve a problem. A business case can be a 5-page document, 5 sentences in Slack, or a 5-minute phone call. The larger the project, the more you may need to make a comprehensive business case. But the underlying premise is the same: If you don’t explain why a problem matters, your colleagues won’t have the necessary information to decide how to support you.</em></p>
<p><strong>― The #1 question every business case should answer - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/the-1-question-every-business-case">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Skilled immigration is a national security priority - Noahpinion</strong> [<a target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/skilled-immigration-is-a-national">Link</a>]</p>
</blockquote>
<p>Skilled immigration should be supported while illegal immigration should be avoided. Also, avoid US education system to become corrupt system for immigration.</p>
<blockquote>
<p><strong>The low road, the high road, and the way the wind blows - Silver Bulletin</strong> [<a target="_blank" rel="noopener" href="https://www.natesilver.net/p/the-low-road-the-high-road-and-the">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Paramount Merges With Skydance - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/paramount-merges-with-skydance">Link</a>]</p>
</blockquote>
<p>PARA agreed to merge with Skydance. The new CEO is Skydance Media CEO David Ellison whose father Larry Ellison is the founder of Oracle. </p>
<p>Old paramount businesses: 1) filmed entertainment (Paramount Pictures and Nickelodeon movie), 2) TV media (Paramount’s broadcast) and cable television networks, like CBS and MTV, 3) Direct to consumer streaming services like Paramount+ and Pluto TV. Its current problems: 1) flat revenue, 2) streaming services are losing, 3) high long-term debt but low cash.</p>
<p>New Paramount Plan: 1) unify marquee rights, 2) reorganize finance, 3) transition into a tech-media hybrid.</p>
<p>For the #3, the vision is to better position Paramount on the front end (DTC apps) and the back end (cloud infrastructure, cloud-based production, and AI tools). Specifically, they are going to 1) rebuild DTC into a differentiated platform, 2) build studio-in-the-cloud, 3) leverage Gen AI.</p>
<blockquote>
<p><strong>Fintech Shake-Up - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/fintech-shake-up">Link</a>]</p>
</blockquote>
<p>Apple Pay unveiled a new peer-to-peer (P2P) feature called “Tap to Cash”, which is a natural evolution of the existing “Tap to Pay”.   This is not the only case where big tech offers features that directly compete with financial institutions: Google Wallet, Amazon’s lending program for sellers, etc, competing with PayPal’s Venmo, Block’s Cash App, etc. Big tech’s move not only intensifies competition within P2P payment, but also raises questions about the future of the payment industry.</p>
<p>Highlights:</p>
<ol>
<li>Visa and Mastercard both face mobile wallet threats to card-based business model.</li>
<li>American Express renowned for its premium card offerings, targeting high spending high credit quality customers, continuing to attract millennials and Gen Z customers. The recent strategic acquisitions are Tock (a reservation platform for high end restaurant and events) and Rooam (a mobile payment and ordering platform for restaurants and venues). However, it’s sensitive to economic downturns and facing competitions for other premium card issuers and digital payment platforms. </li>
<li>Fiserv’s merchant solutions and financial solutions look positive, it’s actively investing in digital transformation, and it recently acquired BentoBox (a digital marketing and commerce platform for restaurants).</li>
<li>Adyen serves large enterprise clients with its unified commerce platform</li>
<li>PayPal lowered its FY 2024 guidance. It’s facing a decline in active accounts. To solve this, it focuses on strategic partnerships such as collaboration with Apple. It’s facing competitive pressure from Big Tech payment solutions like Apple Pay and Google Pay. It’s currently undergoing significant restructuring such as layoffs and leadership change. And it’s initiating AI-powered personalized ads platform and strengthening relationships with SME customers.</li>
<li>Block’s growth is driven by its momentum of Cash App ecosystem, square ecosystem, and significant investment in Bitcoin. However, it’s facing challenges of regulatory scrutiny on cryptocurrency activities and compliance practices, competition from established competitors and fintech startups, needs of balancing growth and profitability given FY 2024 guidance.</li>
</ol>
<p>What to watch for the shift in payment landscape:</p>
<ul>
<li>Facing legal battle from Big Tech, can Visa and Mastercard find innovation or new solutions to maintain their revenue streams from swipe fee?</li>
<li>Will Digital Wallet dominant payment industry? Will traditional cards remain or be replace?</li>
<li>New possibilities of payments have been developed such as Buy Now and Pay Later (BNPL). Will innovations gain mainstream adoption in payment industry?</li>
<li>Can the challenges of cryptocurrencies be overcome? Will cryptocurrencies be mainstream adoption?</li>
<li>As consumers are demanding seamless, secure, cheaper, and personalized payment experiences, companies that can provide such services will become successful in the future.</li>
</ul>
<blockquote>
<p><strong>Nike: Losing Its Swoosh? - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/nike-losing-its-swoosh">Link</a>]</p>
</blockquote>
<p>Nike’s facing challenges of 1) shifting consumer preferences to newer brands (On and Hoka), 2) softer traffic and lower sales of classic footwear franchises in direct-to-consumer channel, 3) macroeconomic headwinds.</p>
<p>Nike Q4 2024 Highlights: 1) Nike is reducing supply of classic footwear franchises to create space for newness and innovation, 2) focusing on performance and innovation, 3) Jordan Brand is still growing YoY.</p>
<p>Other observation: Nike brand value declined by 4% YoY, while Adidas and Lululemon gain brand values.</p>
<blockquote>
<p><strong>Broadcom: AI Surge - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/broadcom-ai-surge">Link</a>]</p>
</blockquote>
<p>Broadcom now operates across two primary segments: 1) semiconductor solutions (chips for networking, server storage, broadband, wireless communication, and industrial applications), and 2) infrastructure software (a explosive leap with the acquisition of VMware). </p>
<p>Highlights: VMware acquisition brings significant revenue to Broadcom; AI as a great growth driver; jumbo acquisition resulted in gigantic net debt; strong cash generation; 10-for-1 stock split on July 15. </p>
<p>Future: Next-generation products include Tomahawk and Jericho; supply chain disruption and inflation resulted from macroeconomic environment; regulatory scrutiny into VMware acquisition.</p>
<blockquote>
<p><strong>Starbucks: A Brewing Crisis - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/starbucks-a-brewing-crisis">Link</a>] [<a target="_blank" rel="noopener" href="https://www.linkedin.com/feed/update/urn:li:activity:7193044402255110144/">LinkedIn</a>]</p>
</blockquote>
<p>Three main issues: </p>
<ol>
<li>the boycott impact: losing 1.5M loyal customers, as a result of the fact that in October 2023, Starbucks became embroiled in a controversy related to the ongoing violence in the Middle East, </li>
<li>significant loss in traffic from non-Rewards members due to additional reasons such as awareness of daily drink price, gourmet coffee boom, health-conscious consumers, changing work habits, and competitors with coffee offerings in lower prices. Solutions on this are new initiatives such as physical and digital enhancements like updated POS system, siren system speedup, and opening mobile orders beyond its loyalty programs.</li>
<li>Price war in Chinese coffee market e.g. Luckin Coffee.</li>
</ol>
<blockquote>
<p><strong>7 Mindsets That Are Slowing Down Your Career Growth - The Caring Techie Newsletter</strong> [<a target="_blank" rel="noopener" href="https://www.thecaringtechie.com/p/7-mindsets-that-are-slowing-down">Link</a>]</p>
</blockquote>
<ol>
<li>Solo Contributor Mindset -&gt; Prioritize get thing done with others</li>
<li>That’s not my job -&gt; willing to do things outside of my scope</li>
<li>My work will speak for itself -&gt; do the work and say that I did the work</li>
<li>If I do what I’m told, I will get promoted -&gt; I need to sit in the driver’s seat of my career growth</li>
<li>If I’m not getting any feedback, it means I’m doing good -&gt; I need to actively seek feedback</li>
<li>I’m not ready for the next level -&gt; I might be ready for a promotion despite my doubts</li>
<li>Picking the devil you know -&gt; next promotion might come from joining another company</li>
</ol>
<blockquote>
<p><strong>Mark Zuckerberg and Peter Thiel - Internal Tech Emails</strong> [<a target="_blank" rel="noopener" href="https://www.techemails.com/p/mark-zuckerberg-peter-thiel-millennials">Link</a>]</p>
</blockquote>
<p>Peter Thiel and Mark Zuckerberg on Facebook, Millennials, and predictions for 2030.</p>
<blockquote>
<p><em>Google owes its stable position as much to Generative AI’s slow progress as its own innovations. While OpenAI, Anthropic, Meta, and others have built more powerful AI models into their chatbots, people haven’t substituted those bots for traditional search. As of February, Bing still had less than 4% of search market share worldwide compared to Google’s 91%. ChatGPT, for context, debuted nearly two years ago.</em> </p>
<p><em>This week, when OpenAI introduced its own search engine, called SearchGPT, it didn’t exactly strike fear in the halls of Mountain View.</em></p>
<p><strong>― Surprisingly, Google Is Thriving In The GenAI Era - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/surprisingly-google-is-thriving-in">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Netflix: Ad Tech Focus - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/netflix-ad-tech-focus">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Tesla: Robotaxi Delay - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/tesla-robotaxi-delay">Link</a>]</p>
</blockquote>
<p>Analysis:</p>
<ul>
<li>Tesla’s revenue comes from three main sources 1) automative (78% revenue), 2) services and other (12% revenue), 3) energy generation and storage (10% revenue). </li>
<li>Production and Deliveries are the two main metrics.</li>
<li>Tesla’s margins have historically been ahead of other car manufacturers thanks to three critical leverages: 1) Economies of scale (though gigafactories), 2) Direct-to-consumer (online and via its showrooms), 3) Low marketing costs (Tesla barely spends on advertising).</li>
</ul>
<p>Highlights:</p>
<ul>
<li>Tesla missed earnings expectations for the fourth consecutive quarter.</li>
<li>Elon Musk pushed the Robotaxi announcement from August 8 to October 10.</li>
<li>Profits fell for the second straight quarter, driven by slower demand, competition, and price cuts. Price cut remain a double-edged sword.</li>
<li>Operating margin declined by 3% YoY and was at its lowest in years. Negative impacts are from 1) price cuts, 2) delivery decline, 3) AI projects, 4) restructuring costs. Positive impacts are from 1) lower cost per vehicle, production ramp of 4680 cells, higher regulatory credits, and non-auto segments.</li>
<li>Energy generation and storage doubled.</li>
</ul>
<p>Future:</p>
<ul>
<li>Humanoid Robots (Optimus): Tesla will begin producing humanoid robots for internal use next year and plans to sell to other companies in 2026.</li>
<li>Market Share and BYD: Tesla outsold BYD in Q2 2024, but the gap between the two companies was only 18K deliveries. Tesla had a 50% market share in BEV sales in the US, with 164K deliveries in Q2. As expected, the market share of BEVs has consistently declined, reflecting the continued adoption of all-electric cars.</li>
</ul>
<blockquote>
<p><em>More than 1.5 million developers are now using Gemini across our developer tools.</em></p>
<p><em>Waymo’s served more than 2 million trips to-date and driven more than 20 million fully autonomous miles on public roads. Waymo’s now delivering well over 50,000 weekly paid public rides, primarily in San Francisco and Phoenix</em>.</p>
<p><em>Our AI-driven profit optimization tools have been expanded to performance max and standard shopping campaigns. Advertisers use profit optimization and smart bidding see a 15% uplift in profit on average compared to revenue-only bidding.</em></p>
<p><em>Soon we’ll actually start testing Search and Shopping ads in AI overviews for users in the US, and they will have the opportunity to actually appear within the overview in a section clearly labeled as sponsored.</em></p>
<p><strong>― Google: AI Spending Spree - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/google-ai-spending-spree">Link</a>]</p>
</blockquote>
<p>Highlights of Q2 FY24: 1) Revenue growth slowed down, 2) search advertising showed no slowdown, 3) YouTube Ads growth slower than Q1, 4) subscriptions decelerated from Q1 due to YouTubeTV increased its price in Q2 FY23, 5) cloud accelerated, 6) margin improved YoY but are about to compress due to AI investments etc, 7) Capex were up and expected to continue being up, 8) Alphabet committed $5 B to the ongoing operations of Waymo, 9) The company returned $18.2 B to shareholders, including $15.7 B in buybacks, showing their confidence in stock value.</p>
<p>Highlights of Cookies, Cloud, and YouTube: 1) planned to phase out third-party cookies from Chrome to address privacy concerns regarding tracking but reversed its decide to let users choose their tracking preferences, 2) AI boost continues to accelerate cloud revenue growth especially in GCP and Workspace, 3) YouTube gains market share, 9.9% in Jun, up from 9.2% in prior year.</p>
<p>Future: 1) Project Astra, 2) SearchGPT competition: Search is critical for Alphabet because it contributes 57% revenue. SearchGPT could shake up the market but challenges are ensuring accuracy and avoiding hallucination. OpenAI doesn’t have either user engagement or ad performance which are required by a successful search business.  </p>
<blockquote>
<p><em>American Express had that network because of its legacy traveler’s check business so it was able to leverage that network to create and establish its credit card business. Without such a network, it’s impossible to operate a closed loop system.</em></p>
<p><strong>― I Am Buying American: American Express - Capitalist Letters</strong> [<a target="_blank" rel="noopener" href="https://www.capitalist-letters.com/p/i-am-buying-american-american-express">Link</a>]</p>
</blockquote>
<p>Why American Express is superior than Visa and Mastercard? It’s business model.</p>
<p>Visa is a typical payment processor. It connects the merchant to the issuer bank. It’s an open loop. American Express, on the other hand, is a closed loop system which makes it a money printing machine. It uses two strategies: 1) set stricter standards to issue cards, 2) provides travel privileges to attract frequent travelers who have higher net worth. </p>
<p>Why good investment: 1) Giant moat due to closed loop system, 2) inflation proof: customer base are those with stronger purchasing power, 3) it’s expanding internationally and among younger people: in 2023, 60% of new consumer accounts were Gen-Z and Millennial, international businesses billed for card services grew 14% YoY last quarter, accounting for 35% overall growth.</p>
<blockquote>
<p><strong>How Github grows and makes money - Productify by Bandan</strong> [<a target="_blank" rel="noopener" href="https://productify.substack.com/p/how-github-grows-and-makes-money">Link</a>]</p>
</blockquote>
<p>Github’s culture values: 1) ﻿﻿﻿Customer-obsessed, 2) ﻿﻿﻿Ship to learn 3) ﻿﻿﻿Growth mindset, 4) ﻿﻿﻿Own the outcome, 5) ﻿﻿﻿Better together, 6) ﻿﻿﻿Diverse and inclusive.</p>
<p>How does Github make money: 1) ﻿﻿﻿Al powered tools - Github CoPilot, 2) ﻿﻿﻿Subscription Plans, 3) ﻿﻿﻿Enterprise solutions, 4) ﻿﻿﻿Marketplace and additional services - Github Marketplace, Github Actions, Github Packages.</p>
<p>Revenue Breakdown: Major contributors are Github CoPilot and Enterprise solutions, Steady contributors are subscription plans, growing segments are marketplace and additional services.</p>
<p>Github’s product and engineering culture: 1) ﻿﻿﻿Open source, 2) ﻿﻿﻿Remote first prioneers - pull requests, 3) ﻿﻿﻿Octocat obsession, 4) ﻿﻿﻿Continuous learning and growth, 5) ﻿﻿﻿Al integration - Github Copilot, 6) ﻿﻿﻿Hackathons and innovation time, 7) ﻿﻿﻿Inclusive design.</p>
<p>Key Takeaways from Github’s growth strategy: 1) Unwavering developer-centric focus and positioning, 2) Building relevant products for its user problems, 3) strong cultural values and community engagement</p>
<blockquote>
<p><strong>No Rules Rules - The secret sauce of Netflix - Tech Books</strong> [<a target="_blank" rel="noopener" href="https://techbooks.substack.com/p/no-rules-rules">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to win at Enterprise AI - A playbook - Platforms, AI, and the Economics of BigTech</strong> [<a target="_blank" rel="noopener" href="https://platforms.substack.com/p/how-to-win-at-enterprise-ai-a-playbook">Link</a>]</p>
</blockquote>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><strong>Hot Swap growing, donors revolt, President Kamala? SCOTUS breakdown: Immunity, Chevron, Censorship - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=kOeARghNIaY&t=1893s&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p>they’re probably two of the key things that I  would look at to determine are we looking at a a true luxury business and then you can go into all um uh kinds of detail um but I think they would be the two ones I’d look at um in terms of the experience from the customer point of view I think it’s also important  to remember that there needs to be a social (06:37) element um to the product or service for it to be a luxury in in the in a commercial sense and in a sort of financial um you know investor sense um and so the idea there is if you look at many Artisans or makers of high quality bespoke Goods um you know that they may very well be high quality product but there’s no social Dimension right so there’s no element of showing off if you will to use a slightly sort of negative connotation and so therefore I think in a in in this for the purposes of our discussion The Artisans and the and the (07:14) sort of small independent bespoke makers would not be considered luxury businesses right um so there would probably be two or three things I would look at clay to figure out if I’m looking at a true luxury business um and then finally the the fact that these businesses and the market overall tends to be driven more by the offering than  the demand side so in some sense these companies create you know their own Market they create their own Demand by offering things to the consumer that the consumer may not realize they they need or desire or even um or or dream of right so there there’s a number of unique characteristics to these businesses which I think you know make them very interesting to study sometimes it’s difficult to determine if you’re looking at a true luxury business or not and sometimes Within These large groups take an lbmh for instance you know some of their offering for some of their brands take Cosmetics or perfumes some of that offering I probably wouldn’t classify as a luxury business right but there are still part (08:16) of um the group and and they generate some revenues at group level um and then you have some parts of the business say say the LV or Dior Brands where it’s and especially leather goods and apparel where it’s much easier to say that this is a this operates as a true luxury business so you know you can attempt to draw these distinctions but I think sometimes the lines are blurred。 </p>
<p><strong>The Luxury Strategy | Why LVMH &amp; Hermès have Outperformed the Market w&#x2F; Christian Billinger (TIP643)</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rbmDgRRwkJ4&ab_channel=WeStudyBillionaires">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Simple Diffusion Language Models (15min video)</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=WjAUX23vgfg">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>You cannot spend this kind of money and show no incremental revenue potential. So while this is incredible for NVIDIA, the chicken is coming home to roast, because if you do not start seeing revenue flow to the bottom line of these companies that are spending 26 B dollars a quarter, the market cap of NVIDIA is not what the market cap of NVIDIA should be, and all of these other companies are going toe get punished for spending this kind of money. Where are all these new fangled things that we are supposed to see that justifies a hundred billion dollar of chip spend a year, two hundreds billion dollars of energy spend, a hundred billion dollars of all this other stuff, we are now spending 750 billion dollars. This is on the order of a national transfer payment, and we’ve seen nothing to show for it except that you can mimic somebody’s voice. It doesn’t all hang together yet. - Chamath Palihapitiya</em></p>
<p><em>There’s gaps in the quality of the products that can be created to not have hallucination. Those gaps are too large right now for them to be used reliably in production settings unless you have a very defined scope. If you have a defined scope though, the implementation costs are not nearly what needs the level of spend to support. So there is just a big mismatch. Second is that we have a huge problem with NVIDIA, which is you can’t spend this kind of money to have tech lock-in to one hardware vendor, and that makes no sense. And what you are seeing now is that Amazon Google Microsoft AMD Intel, a plethora of startups Grok, everybody trying to make now different hardware solution. The problem though is that we have this massive lock-in right now, because the code is littered with all these NVIDIA specific ways of implementing access to GPUs, that’s not sustainable. So we are in an existential thrash and I think the only way that we are going to get around this is to do a little bit of a reset. And I think that’s going to touch a lot of startups that have already taken down way too much money at really insane valuations. I think we are in a bit of a reckoning right now it’s going to be complicated couple of quarters to at a minimum and probably a complicated year to sort out who’s actually real. - Chamath Palihapitiya</em></p>
<p><em>There is ton of capital that was raised during the covid bubble era, and the ZIRP (Zero Interest Rate Policy) era, that needed a place to go. And a lot of traditional business model, traditional in the technology sense - SAS and a lot of biotech stuff, it became uninvestable. Then there is a lot of money in the public markets that was sitting on the sidelines, that was sitting in treasuries and so on. So every dollar is looking for growth and there is a lot of dollars still sitting around out there from the ZIRP era and the coming into this kind of post ZIRP era, looking for a place to growth. And there is very little growth as we talked about with the S&amp;P 479 not being very performative with respect to growth and revenue and having great outlook for the next five years. So then when there is a glimmer of upside there is a glimmer of opportunity, even if it’s just painting a picture of a growth story, all the capital drives into it. And we’ve all heard stories about these series a startups in AI, getting bit up to a 100M valuation. I’ve seen a couple of these where people have pitch me things on like protein modeling AI startups, and it’s literally like two guys from meta and openai that left and started this company, and they raised 30 on a 12 per year or something, and it’s just two guys building a model. That’s because that capital needs to find a place where it can tell itself a growth story. So I think we are still dealing with the capital hangover from ZIRP. And the fact there is an area to invest for real growth that has allowed the AI bubble to grow as quickly as it has. - David Friedberg</em></p>
<p><em>Now as Chamath points out we are kind of rationalizing that back and I do think that there is going to be a reset. Now I’ll also say that the Goldman report which I read and some of the other analyses that have been done. I think there was some commentary or some analysis that hey it costs me six times as much as having an analyst do this work. The energy cost of the AI is still so high, the actual performance of the model is not good. What that fails to write it’s right and wrong. It’s right in the sense that yes it’ s more expensive today and ROI is not there today. It’s wrong in that it ignores the performative model improvements that we’re seeing in nearly any metric over the past couple of months. Every few months as we know we see new models, new improvements, new architectures, new ways to leveraging the chips to actually drive a lover token cost, to drive lower energy cost per answer, lower energy cost per run. Every metric that matters is improving, so if you fast forward another 24 or 36 months, I do think that there is a great reason to be optimistic that there is going to be extraordinary ROI based on the infrastructure that’s being built. It’s a question of are you going to get payback before the next cycle of infrastructure needs to be made and everything comes back in. We saw this during the dotcom boom where a lot of people built out data centers and by the time they were able to actually able to make money on those data centers, it was like hey all the new Telco equipment, all the new servers needs to be put in, and everything got written off. So there is a big capex kind of question mark here, but I do think that the fundamental economics of AI will be proven over the next couple of quarters. - David Friedberg</em></p>
<p><em>I’m much more bullish than you guys about this investment that’s being made. Remember that when the internet got started in the 90s, it was via dialup. I mean you literally had to have a modem and you would dial up the internet and it was incredibly slow. Photo sharing didn’t even work, so social networking wasn’t possible. And basically what happened next was that the Telecom company spent a ton of money building out broadband and people started upgrading to broadband. Then we had the Doom crash everyone thought that telecom companies had wasted billions of dollars investing in all this Broadband infrastructure. And it turned out that no they were right to do that, it just took a while for that to get used and this is a pretty common pattern with technological revolutions is that you can have a bubble in the short term but then it gets justified in the mid to long term. The build out of the railroads in the United States another example of this we had huge railroad bubbles but it turned out that that investment was all worthwhile. - David Sacks</em></p>
<p><strong>― Biden chaos, Soft landing secured? AI sentiment turns bearish, French elections - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=w30WLkNU47g&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Project 2025: The Radical Conservative Plan to Reshape America Under Trump | WSJ</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=y16SZhZJHkI&ab_channel=TheWallStreetJournal">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Trump assassination attempt, Secret Service failure, Inside the RNC, VC liquidity problem - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=3z73JXD3pYU&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Trump’s VP pick JD Vance SPEAKS at 2024 RNC (FULL SPEECH) - NBC Chicago</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1if1ufZY6nI&ab_channel=NBCChicago">Link</a>] </p>
</blockquote>
<blockquote>
<p><em>You have to put one foot in front of the other every day, and you have to focus on tangible progress. And where that fails is when most people and I do it a lot and I’ve tried to get better as I’ve gotten older, is when I get comparative and I compare myself to the other person, the other company, the other funding round, there’s so many reasons for you to feel like you’re less than something else. And the reality is that has nothing to do with you, you’re not in control of that, but it’s so hard. And then if I don’t take that medicine, I become insecure, and then I make mistakes that are entirely avoidable. So it’s just tangible progress the things that I can control. That’s probably the most useful piece of advice that I try to remind myself of every day. - Chamath Palihapitiya</em></p>
<p><strong>― The Besties Take Napa | All-In Special  - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xk4G-ImoSvw&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>Sharing good insights about AI, David’s amazing story with Poker, some great career advice. And happy birthday to David Friedberg!</p>
<blockquote>
<p><em>We talked a little bit about it with Jonathan height. There’s some great studies that have shown in the past that the change in income is a better predictor of happiness than absolute income. Eventually everything normalizes so I think UBI makes no sense for three reasons. The first is this normalization of spending level. So once you’ve kind of had this increase, you have a moment of happiness, and then you actually start spending differently or spending more. And effectively every human has one innate trait desire. And desire is what drives humanity. It’s what drives progress. It’s what pushes us forward because no matter what our absolute condition, it’s our relative condition that matters relative to others or relative to ourselves in the past or perspectively in the future. And so we always want to improve our condition. So a UBI based system basically gives a flat income so the only way for it to really work is if you increase the income automatically by say 10% a year. So in a UBI world, no amount of money will actually make someone satisfied or meet their minimum thresholds because those minimum thresholds will simply shift. And you know the second issue is just the net economic effect if we gave 350 million Americans 1000 bucks a month, that’s $350 billion a month, that’s $4 trillion a year. Our prospective budget for next year is 7.3 trillion at the federal level, so you know that’s already more than 50% of the total projected federal budget next year finding the mechanism for funding this at scale is not what this study actually looked at. Because if you look at it the net effect would be inflationary. And that’s the third major reason is that ultimately this would have an inflationary effect anytime. We’ve stimulated the economy with outside money. With government-driven money, we see many bubbles emerge and we see an inflationary effect. So look at covid, there were all these little bubbles that popped up in the financial markets, we had NFTs, we had crypto, we had all these sort of new places that money found its way to and then we had an aggregate inflationary effect food prices are still up 30 40% since covid. And so I think that the study provides an interesting insight into the micro effect the psychological effects, the social effect, but macro effects are what is so like simply arithmetically obvious, which is inflation and an inability to actually fund us at scale. And fundamentally people want to work so they’ll take that money, and then they’ll go find ways to work and generate more money, and you have this inflationary effect so I think UBI does not make sense. - David Friedberg</em></p>
<p><em>That’s not UBI right and what you’re describing I think exist and there are incentives and programs and opportunities out there people can sign up with Roth IRAs they can contribute some percentage of their paycheck to a 401k. If they have a job that has a 401k setup for them there’s a lot of systems and mechanisms out there and you get tax breaks for doing that. So there’s mechanisms and incentives out there to do that sort of thing the concept with UBI is can you pay people a flat amount of money so that they don’t have to work, and then they end up being able to explore and do other things with their life as the robots and AI does everything for them. And I’ve just always been of the belief that I don’t think that there’s this natural border that we hit beyond which humans don’t work. I think that AI based tools and automation tools are the same as they’ve always been. When we developed a tractor people didn’t stop farming. They could get much more leverage using the tractor and farm more. And new jobs and new Industries emerged. And I expect that the same thing will happen with this next evolution of technology and human progress. Humans will find ways to create new things to push themselves forward to drive things forward. And for the natural market-based incentives that fundamentally are rooted in this internal system of Desire will create new opportunities that we’re not really thinking about so I don’t believe in this idea of UBI in some utopian world where everyone’s happy not working and letting machines do everything for them I think that the fundamental sense of a human is to find purpose, and to realize that purpose to drive themselves forward and progress themselves. And I think that that’s always going to be the case. - David Friedberg</em></p>
<p><strong>― Mag 7 sell-off, Wiz rejects Google, UBI, Kamala in, China’s nuclear buildout, Sacks responds to PG - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UQBPUAgVuJA&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Microsoft Volume II - Acquired Podcast</strong>  [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/2VlQlPDJQSheDFDqgOv8N0">Link</a>]</p>
</blockquote>
<h3 id="Blogs-and-Articles"><a href="#Blogs-and-Articles" class="headerlink" title="Blogs and Articles"></a>Blogs and Articles</h3><blockquote>
<p><strong>A year later, what Threads could learn from other social networks - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/04/a-year-later-what-threads-could-learn-from-other-social-networks/">Link</a>] </p>
</blockquote>
<p>Though Threads has reached 175 million monthly active users in its first year and has made some progress such as integrating fediverse, there are a lot of things need to be improved by learning from other social medias. </p>
<ol>
<li><p>Custom Feeds: Learning from Bluesky: Threads should implement advanced custom feed features to allow users to easily follow specific topics and events without relying solely on tags.</p>
</li>
<li><p>Third-Party Apps: Learning from Mastodon and Bluesky: Meta should consider opening up Threads to third-party developers to create diverse client applications, allowing for a broader range of user experiences and features.</p>
</li>
<li><p>Algorithm Improvement: Improving “For You” Feed: Threads needs to refine its algorithm to ensure that users receive more relevant and personalized content, avoiding random or irrelevant posts that can detract from user experience.</p>
</li>
<li><p>Handling News and Political Content: Learning from X and Mastodon: Threads should develop mechanisms to handle news and political content more effectively, balancing visibility without suppressing important information, and potentially integrating features like context-providing notes or bylines.</p>
</li>
<li><p>Local Content Engagement: Learning from Instagram and Twitter: Threads should enhance its focus on local content by developing partnerships and features that cater to regional interests and events, like live scores for popular sports in specific regions.</p>
</li>
<li><p>Separation from Instagram: Developing Independent Profiles: Threads should work on allowing users to create and manage profiles independent of Instagram accounts, offering more flexibility and autonomy in account management.</p>
</li>
</ol>
<blockquote>
<p><em>If “product-market-fit” means that you’ve found the right kind of product that the market wants…  “Position-market-fit” means that you’ve found the right combination of product&#x2F;brand&#x2F;marketing&#x2F;pricing&#x2F;go-to-market&#x2F;sales&#x2F;etc in a given domain.</em></p>
<p><strong>― Product-market fit is not enough anymore. You need position-market fit - Aakash Gupta on X</strong> [<a target="_blank" rel="noopener" href="https://threadreaderapp.com/thread/1808850674118959457.html">Link</a>]</p>
</blockquote>
<p>Product-market fit is about having the right product for the market, while position-market fit is about effectively positioning that product within the market to stand out and meet specific customer expectations.</p>
<blockquote>
<p><strong>A discussion of discussions on AI bias - Dan Luu</strong> [<a target="_blank" rel="noopener" href="https://danluu.com/ai-bias/#:~:text=Rather%2C%20%22AI%20bias%22%20is,due%20to%20the%20circumstances%20of">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to build a valuable tech company - Jason Shen on X</strong> [<a target="_blank" rel="noopener" href="https://threadreaderapp.com/thread/1806357605343691053.html?utm_source=tldrproduct">Link</a>]</p>
</blockquote>
<p>Jensen’s Mindmap about his secrets to building the mos tvaluable tech company in the world</p>
<p><img src="/digital-di/./images/jensen-mindmap.jpeg" alt="jensen-mindmap"></p>
<blockquote>
<p><em>As a general rule, don’t let your company start doing the next thing until you’ve dominated the first thing. No great company I know of started doing multiple things at once—they start with a lot of conviction about one thing, and see it all the way through. You can do far fewer things than you think. A very, very common cause of startup death is doing too many of the wrong things. Prioritization is critical and hard.</em></p>
<p><em>While great founders don’t do many big projects, they do whatever they do very intensely. They get things done very quickly. They are decisive, which is hard when you’re running a startup—you will get a lot of conflicting advice, both because there are multiple ways to do things and because there’s a lot of bad advice out there. Great founders listen to all of the advice and then quickly make their own decisions.</em></p>
<p><em>Please note that this doesn’t mean doing everything intensely—that’s impossible. You have to pick the right things. As Paul Buchheit says, find ways to get 90% of the value with 10% of the effort. The market doesn’t care how hard you work—it only cares if you do the right things.</em> </p>
<p><em>Fire quickly. Everyone knows this in principle and no one does it. But I feel I should say it anyway. Also, fire people who are toxic to the culture no matter how good they are at what they do. Culture is defined by who you hire, fire, and promote.</em></p>
<p><strong>― Startup Playbook by Sam Altman - Sam Altman</strong> [<a target="_blank" rel="noopener" href="https://playbook.samaltman.com/">Link</a>]</p>
</blockquote>
<p>A brief summary of Sam’s long article by <a target="_blank" rel="noopener" href="https://twitter.com/nurijanian/status/1807462862509723901">George from prodmgmt.world</a> on X.</p>
<p><img src="/digital-di/./images/startup-playbook-by-sam.jpeg" alt="startup-playbook"></p>
<blockquote>
<p>The primary battleground was data and Al governance.</p>
<p>Snowflake fired the first shot by open-sourcing Polaris, its catalog for Apache Iceberg, a popular open-source table format that’s compatible any compute engine. Databricks countered by announcing its acquisition of Tabular, a managed solution for Iceberg created by the project’s founders, right in the middle of Snowflake’s conference. The tollowing week, at their own summit, Databricks further upped the ante by open-sourcing its Unity catalog in front of a live audience.</p>
<p>Data has gravity, so It’s far more efficient to bring applications and services to data rather than vice versa.</p>
<p>Both Databricks and Snowflake are now vying to build the ultimate enterprise AI platform: one capable of serving as the foundation for this “small-but-mighty” vision of AI. Their shared goal is to become the single source of truth for all of an organization’s data and use this position to power intelligent applications across every business function.</p>
<p>Databricks emerged from the open-source Apache Spark project and initially focused on serving the needs of data scientists and ML engineers. Its big data processing capabilities made it a natural fit for AI and data science workloads. Snowflake, by contrast, built its early success around a SQL-centric architecture and tight integration with BI tools, catering to data analysts and traditional IT departments with a closed, “it just works” solution.</p>
<p><strong>― Databricks vs. Snowflake: What their rivalry reveals about AI’s future - Foundation Capital</strong> [<a target="_blank" rel="noopener" href="https://foundationcapital.com/databricks-vs-snowflake-what-their-rivalry-reveals-about-ais-future/">Link</a>] </p>
</blockquote>
<p>Databricks and Snowflake are fighting for the future of enterprise Al. This article discussed four key concepts that shed light on the competitive dynamics: data gravity, the convergence of analytics and Al, the strategic importance of open source, and the rise of compound Al systems.</p>
<blockquote>
<p><strong>How to Interview and Hire ML&#x2F; AI Engineers - eugeneyan</strong> [<a target="_blank" rel="noopener" href="https://eugeneyan.com/writing/how-to-interview/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Meta CTO Andrew Bosworth on the Metaverse, VR&#x2F;AR, AI, Billion-Dollar Expenditures, and Investment Timelines - MatthewBall.co</strong> [<a target="_blank" rel="noopener" href="https://www.matthewball.co/all/bozinterview2024">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Spotify is no longer just a streaming app, it’s a social network - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/10/spotify-is-no-longer-just-a-streaming-app-its-a-social-network/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Gen AI: too much spend, too little benefit? - Goldman Sachs</strong> [<a target="_blank" rel="noopener" href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Crypto x Al report</strong> [<a target="_blank" rel="noopener" href="https://x.com/dunleavy89/status/1811072580817695058">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI’s shift to efficiency</strong> [<a target="_blank" rel="noopener" href="https://www.canaan.com/latest/ai-s-shift-to-efficiency">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>What is AI? - Everyone thinks they know but no one can agree. And that’s a problem - MIT Technology Review</strong> [<a target="_blank" rel="noopener" href="https://www.technologyreview.com/2024/07/10/1094475/what-is-artificial-intelligence-ai-definitive-guide">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Folly of Certainty - Howard Marks</strong> [<a target="_blank" rel="noopener" href="https://www.oaktreecapital.com/insights/memo/the-folly-of-certainty">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>On July 19, 2024 at 04:09 UTC, as part of ongoing operations, CrowdStrike released a sensor configuration update to Windows systems. Sensor configuration updates are an ongoing part of the protection mechanisms of the Falcon platform. This configuration update triggered a logic error resulting in a system crash and blue screen (BSOD) on impacted systems. The sensor configuration update that caused the system crash was remediated on Friday, July 19, 2024 05:27 UTC. This issue is not the result of or related to a cyberattack.</em></p>
<p><strong>― Technical Details: Falcon Content Update for Windows Hosts</strong> [<a target="_blank" rel="noopener" href="https://www.crowdstrike.com/blog/falcon-update-for-windows-hosts-technical-details/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>In any massive failure there are a host of smaller errors that compound; in this case, CrowdStrike created a faulty file, failed to test it properly, and deployed it to its entire customer base in one shot, instead of rolling it out in batches. Doing something different at each one of these steps would have prevented the widespread failures that are still roiling the world</em></p>
<p><em>The real issue, though, is more fundamental: erroneous configuration files in userspace crash a program, but they don’t crash the computer; CrowdStrike, though, doesn’t run in userspace: it runs in kernel space, which means its bugs crash the entire computer — 8 million of them, <a target="_blank" rel="noopener" href="https://blogs.microsoft.com/blog/2024/07/20/helping-our-customers-through-the-crowdstrike-outage/">according to Microsoft</a>. Apple and Linux were not impacted, for a very obvious reason: both have long since locked out 3rd-party software from kernel space.</em></p>
<p><strong>― Crashes and Competition - Ben Thompson on Stratechery</strong> [<a target="_blank" rel="noopener" href="https://stratechery.com/2024/crashes-and-competition/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Munger Series - Learning from Benjamin Franklin - Investment Master Class</strong>  [<a target="_blank" rel="noopener" href="https://mastersinvest.com/newblog/2024/5/9/the-munger-series-learning-from-benjamin-franklin">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Benjamin Graham Survived World Panic on Wall Street (#17) - Beyond Ben Graham</strong> [<a target="_blank" rel="noopener" href="https://beyondbengraham.com/how-benjamin-graham-survived-world-panic-on-wall-street-17/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing Llama 3.1: Our most capable models to date - Meta AI Blog</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/meta-llama-3-1/">Link</a>]</p>
</blockquote>
<p>Meta is releasing Llama 3.1 405B, the first frontier-level open-source AI model. Along with Llama 3.1 70B and 8B models, they offer superior cost &#x2F; performance and are open for Fien-tuning and distilling. And they are collaborating with companies such as Amazon, Databricks, NVIDIA, Grow, etc, to support developers in fine-tuning and distilling models.</p>
<blockquote>
<p><strong>Open Source AI Is the Path Forward - Meta News</strong> [<a target="_blank" rel="noopener" href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/">Link</a>]</p>
</blockquote>
<p>In this letter, Zuckerberg emphasizes Meta’s commitment to open source AI. Similar to Unix and Linux, Zuckerberg believes AI development will eventually go to open source. Open source AI has several benefits: 1) it benefits developers in customization, control and security, cost efficiency, and long-term standards, 2) it benefits Meta in avoiding being locked into competitor’s ecosystems, allowing for freedom in innovation and product development, enhancing its competitiveness, and building a community of partnerships and developers, 3) it benefits the world in providing wide spread access to AI benefits, ensuring safety and security, and avoiding monopoly in AI power.</p>
<blockquote>
<p><strong>GPT-4o mini: advancing cost-efficient intelligence - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">Link</a>]</p>
</blockquote>
<h3 id="Paper-and-Reports"><a href="#Paper-and-Reports" class="headerlink" title="Paper and Reports"></a>Paper and Reports</h3><blockquote>
<p><strong>Meta 3D Gen - Meta AI</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/meta-3d-gen/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI Agents That Matter</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01502">Link</a>]</p>
</blockquote>
<p>This study suggests the importance of optimizing both cost and accuracy in benchmarking and evaluation of AI agents. Since the issues of inadequate hold-out sets, absence of standardized evaluation practices, etc, the authors also suggests a principled framework that emphasizes the development of agents effective especially in practical scenarios rather than on benchmarks.</p>
<blockquote>
<p><strong>Scaling Synthetic Data Creation with 1,000,000,000 Personas</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.20094">Link</a>]</p>
</blockquote>
<p>This team generated 1B personas based on web info and stored them into a Persona Hub. They introduced a synthetic data generation method called ‘persona-driven data synthesis’. These personas can be potentially used to 1) generate personalized content, 2) support LLM prompting, 3) enhance product research, 4) create NPCs in games. The compression perspective is more interesting and helpful for understanding the approach: Persona Hub can be seen as the compressed form of the world knowledge into distributed carriers. And the public web text can be seen as the decompressed content created by these personas with their knowledge and experiences.</p>
<blockquote>
<p><strong>TextGrad: AutoGrad for Text</strong> [<a target="_blank" rel="noopener" href="https://hai.stanford.edu/news/textgrad-autograd-text">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>RouteLLM: An Open-Source Framework for Cost-Effective LLM Routing</strong> [<a target="_blank" rel="noopener" href="https://lmsys.org/blog/2024-07-01-routellm/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A Survey on Mixture of Experts</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.06204">Link</a>]</p>
</blockquote>
<p>This is a comprehensive survey on LLM MoE technique. MoE stands out for enabling model scaling with minimal additional computation. This survey as a systematic MoE literature review, covers MoE’s structure, taxonomy, core designs, open-source resources, applications, and future research directions.</p>
<blockquote>
<p><strong>An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers v2</strong> [<a target="_blank" rel="noopener" href="https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Magic Insert: Style-Aware Drag-and-Drop - Google</strong> [<a target="_blank" rel="noopener" href="https://magicinsert.github.io/">Link</a>] </p>
</blockquote>
<blockquote>
<p><strong>PaliGemma: A versatile 3B VLM for transfer</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/html/2407.07726v1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</strong> [<a target="_blank" rel="noopener" href="https://tridao.me/blog/2024/flash3/">Link</a>]</p>
</blockquote>
<p>FlashAttention-3: achieves a 1.5-2x speedup and reaching up to 740 TFLOPS on FP16 and nearly 1.2 PFLOPS on FP8. This increases GPU utilization to 75% of the theoretical maximum on H100 GPUs, up from 35%.</p>
<p>FlashAttention-3 introduces three main techniques to boost performance:</p>
<ol>
<li>Overlapping computation and data movement</li>
<li>Interleaving matrix multiplications (matmul)</li>
<li>Softmax operations, and using low-precision FP8</li>
</ol>
<blockquote>
<p><strong>Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.07775">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures</strong> [<a target="_blank" rel="noopener" href="https://www.arxiv.org/abs/2407.09468">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Accuracy is Not All You Need</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09141">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI achieves silver-medal standard solving International Mathematical Olympiad problems - Google Research</strong> [<a target="_blank" rel="noopener" href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">Link</a>]</p>
</blockquote>
<p>This is one of the most surprising breakthrough in this AI and LLM year. AlphaProof got a silver medal in IMO. It’s a neurosymbolic system -  a combination of Google’s Gemini LLM and DeepMind’s Alpha Zero, so it uses LLM to generate plausible solutions and uses self-play style to search for the right one. It opens a research direction of AI use cases, which has been discussed about by many AI frontier experts and companies, which is “scientific discovery”. Mastering math can be the first step of expanding frontier of our knowledge. OpenAI’s Strawberry project seems to have the same ambitions.</p>
<blockquote>
<p><strong>Gen AI: Too Much Spend, Too Little Benefit? - Goldman Sachs Research Newsletter</strong>  [<a target="_blank" rel="noopener" href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf">Link</a>]</p>
</blockquote>
<p>As money’s flooded into GenAI projects, people started to question whether or when the investment would net a return. Though the bubble may or may not be bursting, a healthy discussion like this is worth a read.</p>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Prices fell in June for the first time since the start of the pandemic - CNN</strong> [<a target="_blank" rel="noopener" href="https://amp.cnn.com/cnn/2024/07/11/economy/us-cpi-consumer-inflation-june">Link</a>]</p>
</blockquote>
<p>CPI dropped 0.1% from May. Odds of Fed cutting the rate are increasing. Effect of high inflation is expected to be long lasting.</p>
<blockquote>
<p><strong>Here’s how far the Dow has fallen behind the S&amp;P 500 so far in 2024 - Morningstar</strong> [<a target="_blank" rel="noopener" href="https://www.morningstar.com/news/marketwatch/20240709188/heres-how-far-the-dow-has-fallen-behind-the-sp-500-so-far-in-2024">Link</a>]</p>
<p><strong>Tech Giants Face Tough Task to Sustain Second Half Stock Rally - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-09/tech-giants-face-tough-task-to-sustain-second-half-stock-rally">Link</a>]</p>
</blockquote>
<p>Magnificent 7 stocks have accounted for majority of the S&amp;P 500 growth this year. If this projection of AI optimism fails to materialize, it could trigger a massive decline of the index.</p>
<blockquote>
<p><strong>Apple Poised to Get OpenAI Board Observer Role as Part of AI Pact - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-02/apple-to-get-openai-board-observer-role-as-part-of-ai-agreement">Link</a>]</p>
<p><strong>Microsoft, Apple Drop OpenAI Board Plans as Scrutiny Grows - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-10/microsoft-quits-openai-board-after-antitrust-scrutiny-grows">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>This is Big Tech’s playbook for swallowing the AI industry - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/7/1/24190060/amazon-adept-ai-acquisition-playbook-microsoft-inflection">Link</a>]</p>
<p><strong>Amazon Hires Top Executives From AI Startup Adept for AGI Team - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-06-28/amazon-hires-top-executives-from-ai-startup-adept-for-agi-team">Link</a>]</p>
</blockquote>
<p>Big Tech companies are finding new ways to integrate AI startups into their operations without triggering antitrust scrutiny -  ‘reverse acquihire’, an approach where actual acquisitions are masked by employment and licensing agreements. This is highlighted by Microsoft hiring inflection’s team and licensing of its AI tech, and Amazon hiring roughly 2&#x2F;3 of Adept’s personnel and securing a deal to license its AI tech.</p>
<blockquote>
<p><strong>What happened to the artificial-intelligence revolution? - The Economics</strong> [<a target="_blank" rel="noopener" href="https://www.economist.com/finance-and-economics/2024/07/02/what-happened-to-the-artificial-intelligence-revolution">Link</a>]</p>
</blockquote>
<p>Silicon Valley companies are investing heavily in AI while the revenue from AI products is still far from the projected figures.</p>
<blockquote>
<p><strong>Humanoid robots powered by AI turn heads at the World Artificial Intelligence Conference - AP News</strong> [<a target="_blank" rel="noopener" href="https://apnews.com/video/artificial-intelligence-electric-vehicles-shanghai-china-robotics-1dfcfd6e5c6142a48c3df1dd43616353">Link</a>]</p>
<p><strong>Record 300,000 visitors attend World AI Conference</strong> [<a target="_blank" rel="noopener" href="https://www.shine.cn/news/metro/2407064491/">Link</a>]</p>
</blockquote>
<p>The World AI Conference and High-level Meeting on Global AI Governance (WAIC) 2024 closed in Shanghai on Saturday, covering investment plans, cooperation projects, city-level organizations, and development plans for AI. Robotic tech such as humanoid models is capturing the attention of attendees.</p>
<blockquote>
<p><strong>Fame, Feud and Fortune: Inside Billionaire Alexandr Wang’s Relentless Rise in Silicon Valley - The Information</strong> [<a target="_blank" rel="noopener" href="https://www.theinformation.com/articles/fame-feud-and-fortune-inside-billionaire-alexandr-wangs-relentless-rise-in-silicon-valley">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Robinhood snaps up Pluto to add AI tools to its investing app - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/01/robinhood-snaps-up-pluto-to-add-ai-tools-to-its-investing-app">Link</a>]</p>
</blockquote>
<p>The AI tool Pluto will allow Robinhood to add tools for quicker identification of trends and investment opportunities, help guide users with their investment strategies, and offer real-time portfolio optimization.</p>
<blockquote>
<p><em>“The algorithm is looking at traditional economic indicators that you would normally look at. But then inside of our proprietary algorithm, we’re ingesting the behavioral data and transaction data of 240 million Americans, which nobody else has,” said David Steinberg, co-founder, chairman and CEO of Zeta Global.</em></p>
<p><em>The eight verticals the economic index uses include automotive activity, dining and entertainment, financial services such as credit line expansion, health care, retail sales, technology and travel.</em></p>
<p><strong>― A new index is using AI tools to measure U.S. economic growth in a broader way - CNBC</strong> [<a target="_blank" rel="noopener" href="https://www.cnbc.com/2024/07/01/a-new-index-is-using-ai-tools-to-measure-us-economic-growth-in-a-broader-way.html">Link</a>]</p>
</blockquote>
<p>The Zeta Economic Index uses Gen AI to analyze “trillions of behavioral signals” to score growth of US economy.</p>
<blockquote>
<p><strong>OpenAI Hires Zapier Revenue Chief to Lead Sales Strategy - The Information</strong> [<a target="_blank" rel="noopener" href="https://www.theinformation.com/briefings/openai-hires-zapier-revenue-chief-to-lead-sales-strategy?utm_source=www.matthewberman.com&utm_medium=referral&utm_campaign=amazon-s-100b-bet-openai-s-legal-woes-and-robots-deployed-in-retail">Link</a>]</p>
</blockquote>
<p>OpenAI has recently hired new CFO and CPO to enhance its focus on both consumer and enterprise products. It appointed Giancarlo Lionetti (former CRO at Zapier, worked at Atlassian, Confluent, and Dropbox) to lead its sales strategy in OpenAI’s sales team.</p>
<blockquote>
<p><strong>Tesla’s Share of U.S. Electric Car Market Falls Below 50% - The New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/07/09/business/tesla-electric-vehicles-market-share.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Tesla’s Upcoming Model Y, Project Juniper, Spotted with Front Bumper Camera; Coming in 2025</strong> [<a target="_blank" rel="noopener" href="https://www.notateslaapp.com/news/2119/teslas-upcoming-model-y-project-juniper-spotted-with-front-bumper-camera-coming-in-2025">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Persona’s founders are certain the world can use another humanoid robot - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/06/26/personas-founders-are-certain-the-world-can-use-another-humanoid-robot/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Thermonuclear Blasts and New Species: Inside Elon Musk’s Plan to Colonize Mars - The New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/07/11/technology/elon-musk-spacex-mars.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>OpenAl says there are 5 ‘levels’ for AI to reach human intelligence - it’s already almost at level 2</strong> [<a target="_blank" rel="noopener" href="https://qz.com/openai-five-level-system-human-intelligence-ai-1851588122">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>The reason we decided to do the 100k H100 and next major system internally was that our fundamental competitiveness depends on being faster than any other AI company. This is the only way to catch up. Oracle is a great company and there is another company that shows promise also involved in that OpenAI GB200 cluster, but, when our fate depends on being the fastest by far, we must have our own hands on the steering wheel, rather than be a backseat driver. - Elon Musk @ X</em></p>
<p><strong>― xAI Appears to Confirm Ended Talks With Oracle Over Expanded AI Chips Agreement - WSJ</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/xai-appears-to-confirm-ended-talks-with-oracle-over-expanded-ai-chips-agreement-e06ade8b">Link</a>] [<a target="_blank" rel="noopener" href="https://x.com/xDaily/status/1810723880937607564">X</a>]</p>
</blockquote>
<p>Elon’s business strategy - being completely vertical integrated, on many of his companies (Tesla, SpaceX, etc) are working very well over the years. </p>
<blockquote>
<p><strong>Venture capital firm A16z stashing GPUs, including Nvidia’s, to win AI deals: report - Seeking Alpha</strong> [<a target="_blank" rel="noopener" href="https://www.msn.com/en-us/money/savingandinvesting/venture-capital-firm-a16z-stashing-gpus-including-nvidia-s-to-win-ai-deals-report/ar-BB1pGCNR">Link</a>]</p>
</blockquote>
<p>A16z has purchased thousands of GPUs including Nvidia’s H100, in an effort to win deals for AI startups. They store those H100s and give them to companies they invest in. It’s hard for startups to get vast amounts of computing power. So this practice can make them more competitive in these VC deals.</p>
<blockquote>
<p><strong>OpenAI and Los Alamos National Laboratory announce bioscience research partnership - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together/">Link</a>]</p>
</blockquote>
<p>OpenAI and LANL are working together on evaluating how frontier models like GPT-4o can assist humans in physical lab setting through multimodal capabilities to support bioscience research.</p>
<blockquote>
<p><em>In response to the fourth question in the <a target="_blank" rel="noopener" href="https://www.nintendo.co.jp/ir/pdf/2024/qa2406.pdf">investor call transcript</a>, Furukawa said the following (obtained via machine translation and edited for clarity):</em></p>
<p><em>“In the game industry, AI-like technology has long been used to control enemy character movements, so I believe that game development and AI technology have always been closely related.</em></p>
<p><em>Generative AI, which has been a hot topic recently, can be more creative [in its use], but I also recognize that it has issues with intellectual property rights.</em></p>
<p><em>Our company has [had] the know-how to create optimal gaming experiences for our customers for decades.</em></p>
<p><em>While we are flexible in responding to technological developments, we would like to continue to deliver value that is unique to us and cannot be created simply by technology alone.”</em></p>
<p><strong>― Nintendo becomes the biggest company in the games industry - and maybe the world - to say ‘no, thank you’ to using generative AI - PC Gamer</strong> [<a target="_blank" rel="noopener" href="https://www.pcgamer.com/gaming-industry/nintendo-becomes-the-biggest-company-in-the-games-industryand-maybe-the-worldto-say-no-thank-you-to-using-generative-ai/">Link</a>]</p>
</blockquote>
<p>Most gaming companies would like to incorporate AI in some sense but Nintendo as the biggest company in the game industry said no thank you to Gen AI. This sounds counter to what other game companying are aiming for, but it’s also reasonable because Nintendo has built incredible IP and they just want to be classic and they want everything to be their own.</p>
<p>However, many people have imagined the future of video game would be powered by AI with contents dynamically created for players in real time. </p>
<blockquote>
<p><strong>Watch a robot navigate the Google DeepMind offices using Gemini - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/11/watch-a-robot-navigate-the-google-deepmind-offices-using-gemini">Link</a>]</p>
</blockquote>
<p>Google DeepMind Robotics developed a robot navigation system powered by Gemini 1.5 Pro. It responds to human language commands, navigates the office environment. It uses “Multimodal Instruction Navigation with demonstration Tours (MINT)” to familiarize itself with the office and hierarchical Vision-Language-Action (VLA) for understanding and reasoning. The ability of recalling environment is boosted by 1M token context length of Gemini 1.5 Pro</p>
<blockquote>
<p><strong>OpenAI Scale Ranks Progress Toward ‘Human-Level’ Problem Solving - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-11/openai-sets-levels-to-track-progress-toward-superintelligent-ai">Link</a>]</p>
</blockquote>
<p>OpenAI tiers range from the kind of AI that can interact in conversational language with people (lvl 1) to AI that can do the work of an organization (lvl 5). The OpenAI executives believes that they are at stage one and reaching towards the second tier. The third tier on the way to AGI would be ‘Agents’ - AI systems which can spend several days taking actions on a user’s behalf. Tier 4 would be the kind of AI that can come up with innovations. And the tier 5 would be called ‘organization’.</p>
<blockquote>
<p><strong>Samsung’s Jam-Packed Galaxy Unpacked: Galaxy Ring, Z Fold 6 and All the New Products Announced</strong> [<a target="_blank" rel="noopener" href="https://www.cnet.com/tech/mobile/samsungs-jam-packed-galaxy-unpacked-galaxy-ring-z-fold-6-and-all-the-new-products-announced/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Among the 35 companies approved to test by the California DMV, seven are wholly or partly China-based. Five of them drove on California roads last year: <a target="_blank" rel="noopener" href="https://archive.ph/o/rMutc/https://fortune.com/company/weride/">WeRide</a>, Apollo, AutoX, Pony.ai, and DiDi Research America. Some Chinese companies are approved to test in Arizona and Texas as well.</em> </p>
<p><strong>― Chinese self-driving cars have quietly traveled 1.8 million miles on U.S. roads, collecting detailed data with cameras and lasers - Fortune</strong> [<a target="_blank" rel="noopener" href="https://fortune.com/2024/07/08/chinese-self-driving-cars-us-roads-data-collection-surveillance-national-security-concerns-investigation/">Link</a>]</p>
</blockquote>
<p>Since 2017, self-driving cars owned by Chinese companies have traverse 1.8M miles of California alone. They captured video of their surroundings and map the state’s roads to within 2 cm of precision. These information have been transferred to data centers and been used to train their self-driving systems.</p>
<blockquote>
<p><strong>Evaluate prompts in the developer console - Anthropic News</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/evaluate-prompts">Link</a>]</p>
</blockquote>
<p>Anthropic releases some new features every week. Now they allow users to generate, test, and evaluate prompts in the Anthropic Console.</p>
<blockquote>
<p><strong>Fine-tune Claude 3 Haiku in Amazon Bedrock - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/fine-tune-claude-3-haiku">Link</a>]</p>
</blockquote>
<p>Customers can now fine-tune Claude 3 Haiku in Amazon Bedrock to customize model for vertical business usage.</p>
<blockquote>
<p><strong>Shooting at Trump Rally Comes at Volatile Time in American History - The New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/07/14/us/politics/trump-assassination-attempt-wounded.html">Link</a>]</p>
</blockquote>
<p>This is crazy but legendary.</p>
<blockquote>
<p><strong>Insurers Pocketed $50 Billion From Medicare for Diseases No Doctor Treated - The Wall Street Journal</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/health/healthcare/medicare-health-insurance-diagnosis-payments-b4d99a5d?st=2vdas0fpyug0ui5">Link</a>]</p>
</blockquote>
<p>UnitedHealth Group committed a $50 billion fraud over the three years of 2019, 2020, and 2021. Though treating doctors say “no treatment or minimal treatment necessary for this diagnosis”, UnitedHealth overrides the docstors’ judgment, generates its own diagnosis code, bills medicare with this new code. </p>
<blockquote>
<p><em>Thousands of Windows machines are experiencing a Blue Screen of Death (BSOD) issue at boot today, impacting banks, airlines, TV broadcasters, supermarkets, and many more businesses worldwide. A faulty update from cybersecurity provider CrowdStrike is knocking affected PCs and servers offline, forcing them into a recovery boot loop so machines can’t start properly. The issue is not being caused by Microsoft but by third-party CrowdStrike software that’s widely used by many businesses worldwide for managing the security of Windows PCs and servers.</em></p>
<p><strong>― Major Windows BSOD issue hits banks, airlines, and TV broadcasters - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/7/19/24201717/windows-bsod-crowdstrike-outage-issue">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>That from Christopher Thornberg who heads a California-based consulting firm called Beacon Economics. He says moving a main office like this out of state would likely mean anywhere from dozens of lost jobs to a couple hundred, not thousands of jobs lost.</em></p>
<p><em>Governor Newsom’s press office took to X after Musk made the announcement comparing California to Texas saying, “The last time Elon Musk moved an HQ, Tesla ended up expanding in California, even relocating their Global Engineering and AI headquarters to California because of diverse, world leading talent.”</em></p>
<p><strong>― What Elon Musk’s Texas relocation plan for SpaceX, X HQs could mean for CA - ABC7 News</strong> [<a target="_blank" rel="noopener" href="https://abc7news.com/post/what-elon-musks-plan-move-spacex-headquarters-texas-could-mean-california">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>SearchGPT Prototype - OpenAI News</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/searchgpt-prototype/">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/digital-di/page/2/">2</a><a class="page-number" href="/digital-di/page/3/">3</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/digital-di/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/digital-di/js/comments.js"></script><script src="/digital-di/js/utils.js"></script><script src="/digital-di/js/motion.js"></script><script src="/digital-di/js/schemes/muse.js"></script><script src="/digital-di/js/next-boot.js"></script>

  






  





</body>
</html>
