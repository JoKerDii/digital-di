<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/digital-di/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/digital-di/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/digital-di/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/digital-di/images/logo.svg" color="#222">

<link rel="stylesheet" href="/digital-di/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/digital-di/","images":"/digital-di/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/digital-di/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Di&#39;s Blog">
<meta property="og:url" content="https://jokerdii.github.io/digital-di/index.html">
<meta property="og:site_name" content="Di&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Di Zhen">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jokerdii.github.io/digital-di/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Di's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/digital-di/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/digital-di/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Di's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/digital-di/archives/">
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/19/2024-August/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/08/19/2024-August/" class="post-title-link" itemprop="url">2024-August</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-08-19 00:04:43 / Modified: 01:22:33" itemprop="dateCreated datePublished" datetime="2024-08-19T00:04:43-04:00">2024-08-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>“This incident shows clearly that Windows must prioritize change and innovation in the area of end-to-end resilience. […] Examples of innovation include the recently announced VBS enclaves, which provide an isolated compute environment that does not require kernel mode drivers to be tamper resistant.” - John Cable, Microsoft VP of Program management</em></p>
<p><strong>― Microsoft: Azure Slowdown - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/microsoft-azure-slowdown">Link</a>]</p>
</blockquote>
<p>Microsoft Azure decelerated by 1 point sequentially to 30% YoY, while Google Cloud accelerated.</p>
<p>Recent business highlights: 1) global IT outage caused by a faulty update by CrowdStrike affected 8.5 M Windows PCs, 2) Microsoft facing investigation by UK’s CMA over hiring former Inflection AI Staff and the partnership with the startup.</p>
<blockquote>
<p><em>According to <a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/netflix-ad-tech-focus">Nielsen</a>, Prime Video captured <strong>3.1% of US TV Time</strong> in June (a decline of 0.1 points Y&#x2F;Y). Prime Video captures just over a third of Netflix’s market share (and more than Disney+ and Paramount+ combined).</em></p>
<p><em>As Amazon continues to invest in live sports and expand its content catalog, Prime members may find themselves spending more time with the service they already pay for. Prime Video may have started as a loss leader, but if it can become the go-to streaming platform for ad-supported content, it could evolve into a significant revenue driver, even for a behemoth like Amazon.</em></p>
<p><strong>― Amazon: This Team is Cooking - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/amazon-this-team-is-cooking">Link</a>]</p>
</blockquote>
<blockquote>
<ul>
<li><em><strong>Portfolio rebalancing</strong>: Apple stock surged 24% between May 1st and June 30th. As a result, Buffett would have seen AAPL take up nearly 60% of Berkshire’s portfolio. A stake reduction is a typical move to rebalance a portfolio and lower its risk profile.</em></li>
<li><em><strong>Valuation</strong>: Apple is valued above 30 times forward earnings. That makes it less likely to deliver alpha for shareholders. It’s possible Buffett felt like the odds of market-beating returns at this level were subpar.</em> </li>
<li><em><strong>Taxes matter</strong>: Buffett told shareholders in May that he finds the current tax rate on capital gains relatively low, potentially prompting him to realize his significant AAPL gains while the rate is reasonable.</em></li>
<li><em><strong>No place to hide</strong>: Buffett is building up his cash pile and waiting for a “fat pitch.”</em></li>
</ul>
<p><em><strong>The Buffett Indicator</strong></em>:* This ratio compares the total market capitalization of US stocks to the country’s GDP. It’s often used to gauge whether stock valuations in the US are overinflated. It reached <strong>138%</strong> during the dot-com bubble, which was considered high at the time. Low and behold, the indicator hit <strong>190%</strong> at the end of June.*</p>
<p><strong>― Berkshire Slashes Apple Stake - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/berkshire-slashes-apple-stake">Link</a>]</p>
</blockquote>
<p>Factors of today’s macro environment: 1) The AI Bubble, 2) The Yen Carry Trade, 3) Potential Recession.</p>
<blockquote>
<p><strong>Llama 3.1’s Impact on China, Kuaishou’s AI Video Generator Goes Global, and Alibaba Backs $2.8B AI Firm - Recode China AI</strong> [<a target="_blank" rel="noopener" href="https://recodechinaai.substack.com/p/llama-31s-impact-on-china-kuaishous">Link</a>]</p>
</blockquote>
<p>Highlights key AI news in China: 1) Kuaishou’s global launch of its AI video generator, Kling AI, and Zhipu AI’s introduction of Ying, show China’s progress in AI video generation. 2) Alibaba, Tencent, and state-backed AI funds poured $690 M into the $2.8 B AI firm Baichuan AI.</p>
<blockquote>
<p><strong>State of AI in Venture Capital 2024 - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/932e0055-a2be-47a8-a898-dc455f777009">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>“AI CapEx” is a euphemism for building physical data centers with land, power, steel and industrial capacity. There’s been a lot of investment in data centers and AI chips, but not AGI in sight. You can buy all the shovels you want, but if the mine ain’t making money, we have a problem. If there’s no gold in the mine, the shovels aren’t worth very much. BigTech hyperscalers and VCs might have gotten this all wrong.</em></p>
<p><strong>― OpenAI’s SearchGPT and the Impossible Promises of AI - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/openais-searchgpt-and-the-impossible">Link</a>]</p>
</blockquote>
<p>This article points out that industry is facing immense financial pressures and strategic uncertainties. The concerns are as follows: 1) OpenAI’s operating costs exceed $ 8 B, with a projected loss of $5 B in 2024, 2) annual AI revenue to justify the investment in data centers and chips is unlikely to be achieved by 2025, 3) integrating SearchGPT into ChatGPT is a risky bet because users don’t use ChatGPT frequently enough for it to be a successful search tool, 4) competitive market has pushed many AI startups out of the market, AI innovation cannot compete with market dominance (e.g. Microsoft’s attempts to integrate AI into Bing), 5) Big tech companies have accepted that they are possibly over-investing in AI due to FOMO (fear of missing out), leading to unsustainable financial practices, 6) Nvidia’s revenue is risky since it comes majorly from a few tech giants.</p>
<blockquote>
<p><em>The Morningstar framework: The framework is built on 5 “moat sources”:</em></p>
<ul>
<li><em>Intangible assets (Coca-Cola)</em></li>
<li><em>Switching Costs (Oracle)</em></li>
<li><em>Network Effects (CME Group)</em></li>
<li><em>Cost Advantages (UPS)</em></li>
<li><em>Efficient Scale (Kinder Morgan)</em></li>
</ul>
<p><strong>― 5 Wide Moat Businesses - Invest in Quality</strong> [<a target="_blank" rel="noopener" href="https://www.investinassets.net/p/5-wide-moat-businesses">Link</a>]</p>
</blockquote>
<p>Intangible assest: Coca-Cola, SANOFI, Unilever, Johnson &amp; Johnson.</p>
<p>Switching Costs: Oracle, Intuitive Surgical, ADP.</p>
<p>Network Effect: Mastercard, eBay, CME Group, Facebook.</p>
<p>Cost Advantage: Amazon, Novo Nordisk.</p>
<p>Efficient Scale: UPS, nationalgrid, Carnival</p>
<blockquote>
<p><strong>AI: Are we in another dot-com bubble? - AI Musings by Mu</strong> [<a target="_blank" rel="noopener" href="https://kelvinmu.substack.com/p/ai-are-we-in-another-dot-com-bubble">Link</a>]</p>
</blockquote>
<p>A comprehensive analysis comparing current AI cycle to the internet&#x2F;telecom cycle of the 90s. The author examines the technological, economic, and capital differences between the two eras and concludes that while a bubble may be inevitable in the long run, we are still far from reaching that point.</p>
<p>Key points:</p>
<p>Similarities between AI cycle since Nov 2022 and internet cycle of the 90s: 1) Both cycles have similar ecosystem structures, with companies providing infrastructure, enablement, and applications. 2) Occur amid equity bull markets, driven by favorable economic conditions. 3) Require significant infrastructure investments. 4) Attract significant VC interest, leading to high valuations.</p>
<p>Differences between AI cycle since Nov 2022 and internet cycle of the 90s: 1) AI companies are generating revenue much earlier than dot-com companies did, with more sustainable business models. 2) The current economic environment is less robust than in the 90s, leading to a more cautious investment climate. 3) AI investments are primarily equity-funded by big tech, unlike the debt-financed dot-com boom. 4) Valuations of AI companies, while high, are more grounded in near-term earnings than those during the dot-com era.</p>
<p>Bubble Likelihood: The article argues that while there are risks, the current AI cycle is less likely to be in a bubble compared to the dot-com era. The more cautious investment environment, sustainable business models, and the structured flow of capital contribute to this conclusion.</p>
<p>Lessons from Dot-Com Bubble: 1) Infrastructure buildouts take time. 2) Being a first mover can be a disadvantage, as seen with early internet companies that were later overtaken by more successful competitors. 3) The importance of being critical and not getting swept up in the hype, learning from the past to navigate the present.</p>
<blockquote>
<p><em>To recap the above post, they do the new normal, including:</em></p>
<ul>
<li><em>Human preference data and <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.08673v1">HelpSteer</a> style grading of attributes for regularization.</em></li>
<li><em>High-quality reward models for filtering.</em></li>
<li><em>Replacement of human demonstrations with model completions in some domains.</em></li>
<li><em>Multi-round RLHF — “We iterate data and model qualities jointly to improve them in a unified flywheel.”</em></li>
<li><em>A very large suite of data curation techniques, including prompt re-writing and refining for expansion of costly datasets, filtering math and code answers with outcomes (correctness or execution), filtering with LLMs-as-a-judge, and other new normal stuff.</em></li>
</ul>
<p><strong>― A recipe for frontier model post-training - Nathan Lambert, Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/frontier-model-post-training">Link</a>]</p>
</blockquote>
<p>Recent papers and reports (Llama 3.1, Nemotron 340B, and Apple foundation model) have made it clear that a new default recipe exists for high-quality RLHF. It has a few assumptions:</p>
<ul>
<li>Synthetic data can be of higher quality than humans, especially for demonstrations on challenging tasks.</li>
<li>Reinforcement learning from human feedback (RLHF) can scale far further than instruction tuning.</li>
<li>It takes multiple rounds of training and generation to reach your best model.</li>
<li>Data filtering is the most important part of training.</li>
</ul>
<p>It becomes clear that the post training is highly correlated with the style and robustness gains.</p>
<p>The new normal seems to be converged as follows:</p>
<p><img src="/digital-di/./images/new-post-training-approach.png" alt="post-training"></p>
<blockquote>
<p><strong>OpenAI and Generative AI are at a Crossroads - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/openai-and-generative-ai-are-at-a">Link</a>]</p>
</blockquote>
<p>Views of AI landscape.</p>
<blockquote>
<p><strong>At least five interesting things for your weekend (#45) - Noahpinion</strong> [<a target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/at-least-five-interesting-things-68b">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>GPT-5: Everything You Need to Know - The Algorithmic Bridge</strong> [<a target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/gpt-5-everything-you-need-to-know-10a">Link</a>]</p>
</blockquote>
<h3 id="Articles-and-Blogs"><a href="#Articles-and-Blogs" class="headerlink" title="Articles and Blogs"></a>Articles and Blogs</h3><blockquote>
<p><strong>In the Age of A.I., What Makes People Unique? - The New Yorker</strong> [<a target="_blank" rel="noopener" href="https://www.newyorker.com/culture/open-questions/in-the-age-of-ai-what-makes-people-unique">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How To Get Promoted (Without Getting Lucky) - The Developing Dev</strong> [<a target="_blank" rel="noopener" href="https://www.developing.dev/p/how-to-get-promoted-without-getting">Link</a>]</p>
<p><strong>How to Get Rich (without getting lucky) - Naval @ X</strong> [<a target="_blank" rel="noopener" href="https://x.com/naval/status/1002103360646823936">Link</a>]</p>
</blockquote>
<p>Key takeaways: 1) know what you organization considers impactful, 2) learn to sell your ideas, set directions, grow and help others, 3) build your brand by embracing accountability and sharing your results, 4) become a good collaborator and be transparent to your manager about goals and gaps, 5) protect your focus time - “<strong>what you work on is more important than how hard you work</strong>“, do work that you enjoy and has impact.</p>
<blockquote>
<p><strong>Is Consistency Hurting Your Sustainability? - Leadership Letters</strong> [<a target="_blank" rel="noopener" href="https://www.leadership-letters.com/p/is-consistency-hurting-your-sustainability">Link</a>]</p>
</blockquote>
<p>Key takeaways: 1) it’s ok to be inconsistent sometimes, you should update your plan that respects flexibility, balance priorities, or adjust your expectations, 2) Life is not a sprint, taking a pause and pushing goals to the future is not always bad, 3) consistency is about never giving up, 4) don’t set consistency as a goal, find out what is your real goal, so that accepting and developing “bounce-back” plan is possible</p>
<blockquote>
<p><strong>McKinsey’s 2024 annual book recommendations</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/featured-insights/annual-book-recommendations">Link</a>]</p>
</blockquote>
<p>Have selected some books and added them into my read list: 1) God, Human, Animal, Machine: Technology, Metaphor, and the Search for Meaning by Meghan O’Gieblyn, 2) Outlive: The Science &amp; Art of Longevity by Peter Attia, 3) The Journey of Leadership: How CEOs Learn to Lead from the Inside Out by Dana Maor, Hans-Werner Kaas, Kurt Strovink, and Ramesh Srinivasan, 4) Slow Productivity: The Lost Art of Accomplishment Without Burnout by Cal Newport, 5) How Legendary Leaders Speak: 451 Proven Communication Strategies of the World’s Top Leaders  by Peter D. Andrei.</p>
<blockquote>
<p><strong>Paid Advertising 101: A Guide for Startup Founders - Kaya</strong> [<a target="_blank" rel="noopener" href="https://www.usekaya.com/blog/paid-advertising-101">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Building A Generative AI Platform - Chip Huyen</strong> [<a target="_blank" rel="noopener" href="https://huyenchip.com/2024/07/25/genai-platform.html">Link</a>]</p>
</blockquote>
<p>This blog post outlines common themes in building generative AI systems. It covers many of the building blocks a company should consider when deploying its models to production. </p>
<blockquote>
<p><strong>AI’s $600B Question - David Cahn, Sequoia</strong> [<a target="_blank" rel="noopener" href="https://www.sequoiacap.com/article/ais-600b-question/">Link</a>]</p>
</blockquote>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><strong>Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Kbk9BiPhm7o">Link</a>]</p>
</blockquote>
<p>Eight hours interview..</p>
<blockquote>
<p><strong>Kamala surges, Trump at NABJ, recession fears, Middle East escalation, Ackman postpones IPO - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rj71DPhvpiE">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI and The Next Computing Platforms With Jensen Huang and Mark Zuckerberg - NVIDIA</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=w-cmMcMZoZ4">Link</a>]</p>
</blockquote>
<p>Nvidia CEO Jensen and Zuckerberg discuss the future of AI.</p>
<blockquote>
<p><em>There’s a famous quote from an economist Simon Kuznets who said there’s four kinds of countries in the world there’s developed countries undeveloped countries Japan and Argentina. And I think the reason he said that is that Japan has been in the state since the 90s so they had a massive property and Equity bubble collapse. And they’ve not had to deal with anything that looked like typical economic issues since then and part of it is because the Govern plays a very big hand in the Japanese economy, there’s a lot of price controls there. So I don’t know I’m not sure what it is that we can learn there that you can extrapolate to the rest of the world. - Chamath Palihapitiya</em></p>
<p><em>When you have massive amounts of debt it definitely limits your flexibility. It’s just arithmetic, you are going to pay for it with either economic contraction, higher taxes, or inflation. Those are the three places it goes. - David Sacks &amp; David Friedberg</em></p>
<p><em>Well so it looks like since the start of the year they’ve sold 55% of their Holdings in apple. And if you look at the end of the year, this is what berkshire’s stock Holdings were in their non-majority owned businesses. So businesses that they don’t own the business outright and 50% of their portfolio was in Apple at $174 billion. We obviously saw Apple’s stock price Peak highest level ever just a few days ago, but it has since come down as it was reported that since the start of the year. Now Berkshire sold 55% of this position, so some people are arguing that they’ve got a point of view on the company strategy and comp competitive kind of landscape. Some folks have argued that the valuation multiple has gotten too high trading at nearly 30 times earnings the stock has risen 900% since Berkshire bought the stock in 2016. Bagger nicely done yeah and some people would argue that the percent of the portfolio is too high at over 50%, as you can see here at the start of the year. But you know I’ll kind of provide some of the counterarguments you know Warren Buffett does not do much analysis on corporate strategy when he provides reviews of the stocks that he’s picked he often finds and talks a lot about great managers that generate great returns. And he sticks with them and he sticks with them sometimes for many many decades. The management in this company has not changed the return profile on cash invested and cash returned has only improved since he put money in. They’re generating more cash flow they’re offering more dividends they’re doing more stock BuyBacks and he’s happy to be concentrated over the years he’s made large bets on single companies to the point that sometimes he just outright buys the entire company like he did with. Geico in 1996 he always talks a lot about finding a company that is run by great managers that has a premium product with a nice high margin and a durable moat strong brand value. As I look at kind of what’s really gone on here it feels to me like the difference between Apple and some of the other big Holdings in its portfolio is that many of those other businesses are regulated monopolies. So BNSF Railway is regulated by the Federal Railroad Administration Berkshire energy which owns mid americ is a regulated utility. The prices that they charge consumers are set by the government so they have a market that’s locked in the prices are set they have locked in distribution they have locked in utility value and the same is true in the insurance business. Geico’s rates are approved and set effectively by state Regulators Berkshire has a moat because they’ve got the largest Capital base and they’ve got this machine that just keeps generating cash and the rates are publicly set by government Apple. However is not regulated and it is very clear that apple is facing very deep and severe Financial impact from the regulatory authorities that are overseeing the business so if you look at the Google antitrust we’re going to get into the Google deal in a second. There’s a real regulatory risk there because Google’s paying Apple $20 billion a year to be the default search engine. Apple also has a very deep relationship with China they have a lot of manufacturing being done in China and they sell a lot of product into China. So as Regulators start to take a harder look as they said they’re going to at companies relationships with China that’s a real risk to Apple. Advertising tracking users and then the subscription fees that are charged to Consumers and most importantly we’ve talked a lot about the 30% Vig that Apple takes on their App Store and how Regulators are now stepping in and take a look at this. So because this business is not yet a regulated Monopoly it may be a monopoly in many senses of the world it’s not regulated yet. And that transition could be financially painful for Apple once they get to the other side it starts to look a lot more like a large scale Burkshire type business. So that that’s my kind of summary take on what’s going on with apple.  - David Friedberg</em></p>
<p><em>There’s very little kind of editorialization going on with respect to showing the rankings of the new sources. The ranking of the new sources is typically set by some ranking algorithm. The algorithm is usually around click-throughs views popularity of the sites, how many visitors there are, so there are other metrics that drive the order. So for example if NBC CNN Fox News all have kind of higher rankings than some smaller publication, they’re going to end up Hing the the ranking algorithm, because they have a higher quality score. There’s also measures on how often people click through and come back, the bounceback rate, so if they click through an article and then come back that can actually reduce the ranking versus if they click through and stay on the site. So there’s a lot of factors that go into the ranking algorithm. The thing that probably upsets people is that there isn’t any transparency into this, so there’s no understanding on how these things are ranked, how they’re set, and it’s probably very good guidance and feedback that there should be more transparency and openness. And I’m not necessarily trying to defend anyone’s product or behavior, I’m just saying that there’s a certainly a lack of understanding on why one thing is being shown versus another. I’ll also say Sach there’s probably the case or there might be the case that there’s many more sites potentially putting out pro Harris articles, and there are putting out pro Trump articles which can start to overweight the the algorithm as you know or overweight the rankings that are showing up. So that might also be feeding into this that that the general news media bias is what you’re actually seeing versus a Google bias. - David Friedberg</em></p>
<p><em>I just want to show you one chart because important for you to understand the number of people in journalism. This is from 1971 to 2022 who say the identifying Republican has just absolutely plummeted. I know this and this is what I’m trying to explain to you Sacks, is a incredible opportunity for your party since you know you’re passionate about this is to invest in more journalism, invest in more journalists, because I don’t buy this Independence the fact that they’re claiming they’re independent in journalism. I believe that’s cap I believe they say that the Gap is 33% now between people who say they’re Democrats and people who say they’re Republican in journalism that is a key piece to this problem. And layered on top of it, I agree with you that Google is filled with liberal people, and I agree with you Chamath, that they need to intervene and put at the top of the search results in news. These are the you know this is what we’re indexing, this is the percentage that’s left leaning, this is the percentage that’s right leaning, and there are a lot of organizations that examine and rate Publications on their bias left and right, And that’s something that Google could do that’s very unique and that could move the whole show that you’re saying which is they could showcase that up top. So to my friends at Google who are listening do a better job of just being more transparent, so we don’t have this tension in society. - Jason Calacanis</em></p>
<p><strong>― Yen Carry Trade, Recession odds grow, Buffett cash pile, Google ruled monopoly, Kamala picks Walz - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=LRKDisV_pcI">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Ross Taylor on LLM reasoning, Llama fine-tuning, Galactica, agents - Interconnects AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=KNsnarhMZRo&feature=youtu.be">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Sebastian Raschka on the state of open LLMs, Llama 3.1, and AI education - Interconnects AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=-q79uzz1Wik">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Here you can see that their (Starbucks) net revenue growth was only 1% year-over-year, but their operating margin’s been on the decline, so they have not really been able to boost their operating margin very much in the past 5 years. So while they’ve raised prices, they’ve had a really hard time making more money and that’s because the cost of food and the cost of Labor and the cost of rent, and the capital expenditures needed to upgrade stores has far exceeded the ability for them to grow revenue and compete. And now revenue is flatlining because consumers are getting tapped out with respect to how much they can spend and there’s only so much Innovation you can really do to charge more, get people to come in the store more and drive up revenue. - David Friedberg</em></p>
<p><em>Brian Nickel has an incredible reputation prior to Chipotle. He ran Taco Bell and he ran Taco Bell for several years and made it one of the most profitable Quick Serve Restaurants (QSR) in the world. He did this by focusing on every nickel. He is notorious for being a Cost Cutter, for being an efficiency driver, for being a productivity Hound. He goes into the business and he figures out every step in the supply chain, every step of the operating activities of the employee in the stores. So he was recruited heavily. I don’t know if you guys remember Chipotle’s founder was running Chipotle and at the time there was a lot of investor activism around Chipotle because they were wasting money like no one’s business. The guy had a private Jet, he was flying his management team back and forth between Denver and New York. They were spending money on crazy projects. And the board fired the CEO founder of Chipotle, brought in Nickel. Nickel came in and made Chipotle an incredibly profitable growing business. And the expectation is he’ll come and do the same here that maybe over the years Starbucks’s success has bred laziness. Starbucks’s success has bred fat slowness productivity decline, and that this guy is the right guy to come in and find all the nickels. And Brian Nichol is probably the right guy which is why you’re seeing the stock kind of rally as hard as it has. - David Friedberg</em></p>
<p><em>But the thing about Starbucks is they realized early on that when you can customize a consumer experience, the consumer comes back more frequently. So when you see your name written on that cup, you feel like you’re getting your product, you’re not buying an off-the-shelf product, you’re getting a custom personalized experience. What that led to is people customizing their drinks and what did they find that they liked when they customized their drinks sugary sweet add-ons. And then that became more and more of the standard menu and then that just kept evolving. And that’s just the consumer feedback mechanism working which is to Chamath’s point, led to 60 gram sugar drinks that are now the standard product at Starbucks, not an espresso or a cappuccino which is how they started, and it’s really unfortunate. - David Friedberg</em></p>
<p><em>So arguably I would say that trying to step in and cap prices will reduce competition, and as a result will reduce investment in improving productivity. And we have seen this countless times with every socialist experiment in human history has started with caps on food, and it has resulted in spread lines like you see in the image behind me today as we can see in Soviet Russia. This is a mistake, it is a problem, it is anti-American, it is anti-free Market, it is anti- innovation, it is anti- productivity, and ultimately it’s anti- liberty and I cannot stand it. - David Friedberg</em></p>
<p><em>To support your point, and what Chamath was messaging on our chat, look at Walmart stocks up 7% today, because they offer lower priced solutions to consumers, and Dollar General and Dollar Tree are rallying as well, when the market competes, consumers benefit, and there are companies that will win. And the companies that try to price gouge, and the companies that try to charge too much will lose. Starbucks has been trying to charge too much for sugar water, they have a real problem they are now tackling. Walmart is trying to bring value to consumers, they are winning. That is how free markets work. When the government steps in and says here’s how much margin you can make or here’s how much prices should be, it ruins everything, and the entire incentive structure goes away, and you end up with breadlines. - David Friedberg</em></p>
<p><strong>― Break up Google, Starbucks CEO out, Kamala’s price controls, Boeing disaster, Kursk offensive - All-in Podcasts</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xA5B6quoahY">Link</a>] </p>
</blockquote>
<h3 id="Paper-and-Reports"><a href="#Paper-and-Reports" class="headerlink" title="Paper and Reports"></a>Paper and Reports</h3><blockquote>
<p><strong>Gradient Boosting Reinforcement Learning</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.08250v1">Link</a>]</p>
</blockquote>
<p>Gradient-Boosting RL (GBRL) brings the advantages of GradientBoosting Trees (GBT) to reinforcement learning. </p>
<blockquote>
<p><strong>SpreadsheetLLM: Encoding Spreadsheets for Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09025">Link</a>]</p>
</blockquote>
<p>A great paper that outlines how you can turn a spreadsheet into a representation that is useful to a modern LLM. This can be used for Q&#x2F;A, formatting, and other data operations.</p>
<blockquote>
<p><strong>OpenAI Revenue</strong> [<a target="_blank" rel="noopener" href="https://futuresearch.ai/openai-revenue-report">Link</a>] </p>
</blockquote>
<blockquote>
<p><strong>The Llama 3 Herd of Models - Meta Research</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">Link</a>]</p>
</blockquote>
<p>This is a 92 pages paper, a comprehensive guide for LLM researchers and engineers.</p>
<blockquote>
<p><strong>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09413v1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>KAN or MLP: A Fairer Comparison</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.16674">Link</a>]</p>
</blockquote>
<p>Controlled study finds MLP generally outperforms KAN across various tasks. MLP outperformed KAN in machine learning (86.16% vs. 85.96%), computer vision (85.88% vs. 77.88%), NLP (80.45% vs. 79.95%), and audio processing (17.74% vs. 15.49%). KAN excelled only in symbolic formula representation (1.2e-3 RMSE vs. 7.4e-3). </p>
<blockquote>
<p><strong>NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.11963">Link</a>]</p>
</blockquote>
<p>The problem of current evaluation methods is that they are inadequate for assessing LLM performance on long context, however reasoning on long texts becomes more and more demanded. So they present a framework called NeedleBench for evaluating the long-context capabilities of LLMs across extensive text lengths. By some experiments, they find that current LLMs are struggling with complex reasoning tasks when it comes to long texts, showing a potential improvement room for LLMs.</p>
<blockquote>
<p><strong>Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.16833">Link</a>]</p>
</blockquote>
<p>This study investigates how large language models handle question-answering tasks under two conditions: when they receive comprehensive context information (long-context) versus when they are given only selected chunks of the necessary information (RAG). It shows that long context surpasses RAG significantly for Gemini-1.5-Pro, GPT-4O and GPT-3.5-Turbo. </p>
<blockquote>
<p><strong>A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.12994v2">Link</a>]</p>
</blockquote>
<p>This paper summarizes 38 prompt engineering techniques for LLM reasoning and lists the types of problems and datasets they have been used with.</p>
<blockquote>
<p><strong>Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.13121">Link</a>]</p>
</blockquote>
<p>This paper explores the capabilities of long-context language models (LCLMs) in handling tasks traditionally dependent on external tools like retrieval systems, RAG (Retrieval-Augmented Generation), and SQL databases. It reveals that LCLMs, such as Gemini 1.5 Pro, GPT-4o, and Claude 3 Opus, can perform competitively with specialized models in tasks like retrieval and RAG. In particular, at the 128k token context length, LCLMs rival the performance of state-of-the-art retrieval systems and even surpass some multi-modal retrieval models. However, LCLMs struggle significantly with more complex tasks requiring multi-hop compositional reasoning, such as SQL-like tasks. The findings also highlight the importance of prompt design, as performance can vary greatly depending on the prompting strategies used.</p>
<blockquote>
<p><strong>Apple Intelligence Foundation Language Models - Apple</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.21075">Link</a>]</p>
</blockquote>
<p>This report describes the architecture, the data used to train the model, the training process, how the models are optimized for inference, and the evaluation results, for the foundation language model developed to power Apple Intelligence features.</p>
<p>Notice that Apple includes the fundamentals of their RL methods, including a different type of soft margin loss for the reward model, regularizing binary preferences with absolute scores, their rejection sampling algorithm (iTeC) that is very similar to Meta’s approach, and their leave-one-out Mirror Descent RL algorithm, MDLOO. </p>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Google has an illegal monopoly on search, judge rules. Here’s what’s next - CNN</strong> [<a target="_blank" rel="noopener" href="https://amp-cnn-com.cdn.ampproject.org/c/s/amp.cnn.com/cnn/2024/08/05/business/google-loses-antitrust-lawsuit-doj">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Berkshire Hathaway sells off large share of Apple and increases cash holdings - The Guardian</strong> [<a target="_blank" rel="noopener" href="https://www.theguardian.com/business/article/2024/aug/03/berkshire-hathaway-warren-buffett-sells-off-apple-increases-cash-holdings">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Having accurate, reliable benchmarks for AI models matters, and not just for the bragging rights of the firms making them. Benchmarks “define and drive progress”, telling model-makers where they stand and incentivising them to improve, says Percy Liang of the Institute for Human-Centred Artificial Intelligence at Stanford University. Benchmarks chart the field’s overall progress and show how AI systems compare with humans at specific tasks. They can also help users decide which model to use for a particular job and identify promising new entrants in the space, says Clémentine Fourrier, a specialist in evaluating LLMs at Hugging Face, a startup that provides tools for AI developers.</em></p>
<p><strong>― GPT, Claude, Llama? How to tell which AI model is best - The Economist</strong> [<a target="_blank" rel="noopener" href="https://www.economist.com/science-and-technology/2024/07/31/gpt-claude-llama-how-to-tell-which-ai-model-is-best">Link</a>]</p>
</blockquote>
<p>Current benchmark MMLU (massive multi-task language understanding) has a few problems: 1) too easy for today’s models leading to the problem of ‘saturation’. New alternatives are developed such as MMLU-Pro, GPQA, MUSR, etc, 2) training data comes from internet which is a source of questions and answers for MMLU, resulting in a problem called “contamination”, 3) answers in MMLU tests are sometimes wrong or correct answers are more than one, 4) small changes in the way questions are posed to models can significantly affect their scores.</p>
<p>There are some trustworthy automated testing systems other than ChatBotArena leaderboard: HELM (holistic evaluation of language models) built by Dr Liang’s team at Stanford, and EleutherAI Harness uses by Dr Fourrier’s teams at Hugging Face for open source models.</p>
<p>As model gain new skills, new benchmarks are being developed to assess them. For example, GAIA tests model on real world problem solving, NoCha provides novel challenge, etc. However, new benchmarks are expensive to develop because they require human experts to create a detailed set of questions and answers. Dr Liang is working on project AutoBencher, Anthropic started funding the creation of benchmarks with a focus of AI safety.</p>
<blockquote>
<p><strong>GPT-4o mini: advancing cost-efficient intelligence - OpenAI News</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">Link</a>]</p>
</blockquote>
<p>GPT-4o is small and intelligent. It’s probably distilled from current or unreleased version of OpenAI’s models, similar to what Claude did with Claude Haiku and Google with Gemini Flash.</p>
<blockquote>
<p><strong>Made by Google 2024: Pixel 9, Gemini, a new foldable and other things to expect from the event - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/08/06/made-by-google-2024-pixel-9-gemini-a-new-foldable-and-other-things-to-expect-from-the-event/">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/11/The-Wisdom-of-the-Bullfrog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/08/11/The-Wisdom-of-the-Bullfrog/" class="post-title-link" itemprop="url">The Wisdom of the Bullfrog</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-08-11 09:34:39 / Modified: 12:31:05" itemprop="dateCreated datePublished" datetime="2024-08-11T09:34:39-04:00">2024-08-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>The book “The Wisdom of the Bullfrog” written by Admiral William H. McRaven is recommended by my mentor Dylan. It contains 18 sayings or mottos used in the military, which inspire Admiral William and others throughout his 4 decades Navy SEAL career.</p>
<p>Some favorite quotes from the author:</p>
<h3 id="Chapter-Three-When-in-Command-Command"><a href="#Chapter-Three-When-in-Command-Command" class="headerlink" title="Chapter Three - When in Command, Command"></a>Chapter Three - When in Command, Command</h3><blockquote>
<p>As a leader you must always appear to be in command, even on those days when you struggle with the pressures of the job. You must be confident. You must be decisive. You must smile. You must laugh. You must engage with your employees and be thankful for their work. You must have the look of a person in charge. You must instill in your men and women a sense of pride that their leader can handle any problem.</p>
<p>As a leader you can’t have a bad day. You must never look beaten, no matter the circumstance. If you sulk, if you hang your head, if you whine or complain about the leaders above you or the followers below you, then you will lose the respect of your men and women, and the attitude of despair will spread like wildfire.</p>
<p>Being a leader is an awesome responsibility. There are days when it can be frightening to know that the fate of the organization rests on your shoulders. But you must also realize that you were chosen to be the leader because you have proven yourself along the way. You have demonstrated that you know the business. You have shown that you can handle the pressures and be decisive. You have exhibited all the qualities necessary to lead. And even if none of the above holds true, now that you are the leader, you are in command. So, take the damn helm and command!</p>
</blockquote>
<h3 id="Chapter-Five-The-Only-Easy-Day-Was-Yesterday"><a href="#Chapter-Five-The-Only-Easy-Day-Was-Yesterday" class="headerlink" title="Chapter Five - The Only Easy Day Was Yesterday"></a>Chapter Five - The Only Easy Day Was Yesterday</h3><blockquote>
<p>The day you no longer believe you have something to prove, the day you no longer believe you must give it your all, the day you think you are entitled to special treatment, the day you think all your hard days are behind you, is the day you are no longer the right leader for the job.</p>
<p>Leadership requires energy. It requires stamina. It requires resilience. It requires everything you have and then some. The men and women that work for you will feed off your energy. If you look unprepared to deal with the challenges of the day, they will see this. If you look beaten down because today was harder than yesterday, they will feel this. If you are not prepared to give it your all, they will know this. And if you think this is just about leaders in combat, you’re mistaken. This is about every great leader who was given a difficult task and asked to inspire, motivate, and manage the people under their charge.</p>
</blockquote>
<h3 id="Chapter-Six-Run-to-the-Sound-of-the-Guns"><a href="#Chapter-Six-Run-to-the-Sound-of-the-Guns" class="headerlink" title="Chapter Six - Run to the Sound of the Guns"></a>Chapter Six - Run to the Sound of the Guns</h3><blockquote>
<p>Good leaders understand that organizations are going to have challenges. That’s why you were hired to lead. Embrace the challenge. Accept the fact that you must attack each problem with vigor and that sometimes only you, the leader, can solve the most vexing of institutional crises. Never shy away. Never retreat from a difficult problem.</p>
</blockquote>
<h3 id="Chapter-Eight-Who-Dares-Wins"><a href="#Chapter-Eight-Who-Dares-Wins" class="headerlink" title="Chapter Eight - Who Dares Wins"></a>Chapter Eight - Who Dares Wins</h3><blockquote>
<p>It is better to err on the side of daring than the side of caution.<br>     —Alvin Toffler, American writer and futurist</p>
</blockquote>
<h3 id="Chapter-Ten-No-Plan-Survives-First-Contact-with-the-Enemy"><a href="#Chapter-Ten-No-Plan-Survives-First-Contact-with-the-Enemy" class="headerlink" title="Chapter Ten - No Plan Survives First Contact with the Enemy"></a>Chapter Ten - No Plan Survives First Contact with the Enemy</h3><blockquote>
<p>No plan of operations reaches with any certainty beyond the first encounter of the enemy’s main force.<br>In other words, always have a Plan B. A contingency plan. A backup plan. Because once you encounter the enemy, no plan survives first contact.</p>
</blockquote>
<h3 id="Chapter-Fourteen-Expect-What-You-Inspect"><a href="#Chapter-Fourteen-Expect-What-You-Inspect" class="headerlink" title="Chapter Fourteen - Expect What You Inspect"></a>Chapter Fourteen - Expect What You Inspect</h3><blockquote>
<p>Truth is confirmed by inspection and delay; falsehood by haste and uncertainty.<br>     —Tacitus, Roman historian</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/07/Essentialism-The-Disciplined-Pursuit-of-Less/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/08/07/Essentialism-The-Disciplined-Pursuit-of-Less/" class="post-title-link" itemprop="url">Essentialism, The Disciplined Pursuit of Less</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-08-07 19:33:13" itemprop="dateCreated datePublished" datetime="2024-08-07T19:33:13-04:00">2024-08-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-08-19 01:18:30" itemprop="dateModified" datetime="2024-08-19T01:18:30-04:00">2024-08-19</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Essentialism written by Greg Mckeown is a book centered me to essentialism from my minimalism mindset and lifestyle. Dan recommended it to me in our first coffee chat :)</p>
<p>What Ela Bhatt said reminds me how I became a minimalism - </p>
<blockquote>
<p>Out of all virtues simplicity is my most favorite virtue. So much so that I tend to believe that simplicity can solve most of the problems, personal as well as the world problems. If the life approach is simple one need not lie so frequently, nor quarrel nor steal, nor envy, anger, abuse, kill. Everyone will have enough and plenty so need not hoard, speculate, gamble, hate. When character is beautiful, you are beautiful. That is the beauty of simplicity.</p>
</blockquote>
<h3 id="What-is-the-Core-Mindset-of-an-Essentialist"><a href="#What-is-the-Core-Mindset-of-an-Essentialist" class="headerlink" title="What is the Core Mindset of an Essentialist?"></a>What is the Core Mindset of an Essentialist?</h3><blockquote>
<p>The way of the Essentialist means living by design, not by default. Instead of making choices reactively, the Essentialist deliberately distinguishes the vital few from the trivial many, eliminates the nonessentials, and then removes obstacles so the essential things have clear, smooth passage. In other words, Essentialism is a disciplined, systematic approach for determining where our highest point of contribution lies, then making execution of those things almost effortless.</p>
</blockquote>
<blockquote>
<p>It is a discipline you apply each and every time you are faced with a decision about whether to say yes or whether to politely decline. It’s a method for making the tough trade-off between lots of good things and a few really great things. It’s about learning how to do less but better so you can achieve the highest possible return on every precious moment of your life.</p>
</blockquote>
<blockquote>
<p>A Nonessentialist approaches every trade-off by asking, “How can I do both?” Essentialists ask the tougher but ultimately more liberating question, “Which problem do I want?” An Essentialist makes trade-offs deliberately. She acts for herself rather than waiting to be acted upon. As economist Thomas Sowell wrote: “There are no solutions. There are only trade-offs.”</p>
</blockquote>
<p>It’s not only about mental discipline.</p>
<h3 id="Explore-Discerning-The-Trivial-Many-from-the-Vital-Few"><a href="#Explore-Discerning-The-Trivial-Many-from-the-Vital-Few" class="headerlink" title="Explore: Discerning The Trivial Many from the Vital Few"></a>Explore: Discerning The Trivial Many from the Vital Few</h3><p>Essentialisms systematically and deliberately explore and evaluate a broad set of options at first to ensure that they pick the right one later. This exploration requires time and space and this can be seen as trivial and unnecessary by nonessentialists. </p>
<p>We need to look for the lead rather than being distracted by minor details. we need to pay attention to those not explicitly stated rather than everything. We not only capture the dots, but also connect them to see the trends.</p>
<blockquote>
<p>He (Frank O’Brien) wrote: “I think it’s critical to set aside time to take a breath, look around, and think. You need that level of clarity in order to innovate and grow.” Furthermore, he uses the meeting as a litmus test to alert him if employees are spending too much time on the nonessential: “If somebody can’t make the meeting because of too much going on, that tells me either we’re doing something inefficiently or we need to hire more people.” If his people are too busy to think, then they’re too busy, period.</p>
</blockquote>
<blockquote>
<p>Being a journalist of your own life will force you to stop hyper-focusing on all the minor details and see the bigger picture. You can apply the skills of a journalist no matter what field you are in-you can even apply them to your personal life. By training yourself to look for “the lead,” you will suddenly find yourself able to see what you have missed. You’ll be able to do more than simply see the dots of each day: you’ll also connect them to see the trends. Instead of just reacting to the facts, you’ll be able to focus on the larger issues that really matter.</p>
</blockquote>
<p>We need to play to relieve stress and expand minds in ways that allow us to generate new ideas. We also need enough sleep hours to allow new neural connections to be made. </p>
<blockquote>
<p>Play expands our minds in ways that allow us to explore: to germinate new ideas or see old ideas in a new light. It makes us more inquisitive, more attuned to novelty, more engaged. </p>
</blockquote>
<blockquote>
<p>The best asset we have for making a contribution to the world is ourselves. If we underinvest in ourselves, and by that I mean our minds, our bodies, and our spirits, we damage the very tool we need to make our highest contribution. One of the most common ways people-especially ambitious, successful people-damage this asset is through a lack of sleep.</p>
</blockquote>
<blockquote>
<p>Sleep Is the New Status Symbol for Successful Entrepreneurs. </p>
</blockquote>
<h3 id="Eliminate-Cutting-Out-the-Trivial-Many"><a href="#Eliminate-Cutting-Out-the-Trivial-Many" class="headerlink" title="Eliminate: Cutting Out the Trivial Many"></a>Eliminate: Cutting Out the Trivial Many</h3><p>Clarity is the key.</p>
<blockquote>
<p>When there is a serious lack of clarity about what the team stands for and what their goals and roles are, people experience confusion, stress, and frustration. When there is a high level of clarity, on the other hand, people thrive.<br>When there is a lack of clarity, people waste time and energy on the trivial many. When they have sufficient levels of clarity, they are capable of greater breakthroughs and innovations- greater than people even realize they ought to have- in those areas that are truly vital. </p>
</blockquote>
<blockquote>
<p>Creating an essential intent is hard. It takes courage, insight, and foresight to see which activities and efforts will add up to your single highest point of contribution. It takes asking tough questions, making real trade-offs, and exercising serious discipline to cut out the competing priorities that distract us from our true intention. Yet it is worth the effort because only with real clarity of purpose can people, teams, and organizations fully mobilize and achieve something truly excellent.</p>
</blockquote>
<p>We need to make our choices about where to focus our energy and time purposefully and deliberately. This is necessary because “If you don’t prioritize your life, someone else will”. And this is not easy because sometime we are going against social expectation and we are under social pressure. We need courage and grace to navigate some hard moments.</p>
<blockquote>
<p>The only way out of this trap is to learn to say no firmly, resolutely, and yet gracefully. Because once we do, we find, not only that our fears of disappointing or angering others were exaggerated, but that people actually respect us more. Since becoming an Essentialist I have found it almost universally true that people respect and admire those with the courage of conviction to say no.</p>
</blockquote>
<blockquote>
<p>How do we learn to say no gracefully?</p>
<ol>
<li><p>Separate the decision from the relationship</p>
</li>
<li><p>Saying “No” gracefully doesn’t have to mean using the word No</p>
</li>
<li><p>Focus on the trade-off</p>
</li>
<li><p>Remind yourself that everyone is selling something</p>
</li>
</ol>
<p>  I am simply saying everyone is selling something-an idea, a viewpoint, an opinion-in exchange for your time. Simply being aware of what is being sold allows us to be more deliberate in deciding whether we want to buy it.</p>
<ol start="5">
<li>Make your peace with the fact that saying “No” often requires trading popularity for respect</li>
</ol>
<p>  When the initial annoyance or disappointment or anger wears off, the respect kicks in. When we push back effectively, it shows people that our time is highly valuable. It distinguishes the professional from the amateur.</p>
</blockquote>
<p>Becoming an Essentialism requires us to eliminate things that are really good in order to save time and space for something better.</p>
<blockquote>
<p>The Latin root of the word decision-cis or cid-literally means “to cut” or “to kill.” Since ultimately, having fewer options actually makes a decision “easier on the eye and the brain,” we must summon the discipline to get rid of options or activities that may be good, or even really good, but that get in the way. Yes, making the choice to eliminate something good can be painful. But eventually, every cut produces joy-maybe not in the moment but afterwards, when we realize that every. additional moment we have gained can be spent on something better. That may be one reason why Stephen King has written, “To write is human, to edit is divine.”</p>
</blockquote>
<blockquote>
<p>Condensing doesn’t mean doing more at once, it simply means less waste. It means lowering the ratio of words to ideas, square feet to usefulness, or effort to results. Thus to apply the principle of condensing to our lives we need to shift the ratio of activity to meaning. We need to eliminate multiple meaningless activities and replace them with one very meaningful activity.</p>
</blockquote>
<blockquote>
<p>Becoming an Essentialist means making cutting, condensing, and correcting a natural part of our daily routine-making editing a natural cadence in our lives.</p>
</blockquote>
<p>Setting boundaries is not having limits of life nor evidence of weakness. It’s a way of avoiding being distracted by something that is essential to others rather than that is essential to ourselves. We need to articulate our boundaries and set them up in advance.</p>
<blockquote>
<p>After all, if you don’t set boundaries-there won’t be any. Or even worse, there will be boundaries, but they’ll be set by default-or by another person-instead of by design.</p>
</blockquote>
<blockquote>
<p>Essentialists, on the other hand, see boundaries as empowering. They recognize that boundaries protect their time from being hijacked and often free them from the burden of having to say no to things that further others’ objectives instead of their own. They know that clear boundaries allow them to proactively eliminate the demands and encumbrances from others that distract them from the true essentials.</p>
</blockquote>
<blockquote>
<p>Whoever it is that’s trying to siphon off your time and energies for their own purpose, the only solution is to put up fences. And not at the moment the request is made, you need to put up your fences well in advance, clearly demarcating what’s off limits so you can head off time wasters and boundary pushers at the pass.</p>
</blockquote>
<blockquote>
<p>The simple reality is, if you can’t articulate these to yourself and others, it may be unrealistic to expect other people to respect them or even figure them out.</p>
</blockquote>
<h3 id="Execution-Removing-Obstacles-and-Making-Execution-Effortless"><a href="#Execution-Removing-Obstacles-and-Making-Execution-Effortless" class="headerlink" title="Execution: Removing Obstacles and Making Execution Effortless"></a>Execution: Removing Obstacles and Making Execution Effortless</h3><p>Time and space are required as a buffer to reduce friction and ensure success.</p>
<blockquote>
<p>The way of the Essentialist is different. The Essentialist looks ahead. She plans. She prepares for different contingencies. She expects the unexpected. She creates a buffer to prepare for the unforeseen, thus giving herself some wiggle room when things come up, as they inevitably do.</p>
</blockquote>
<blockquote>
<p>Essentialists accept the reality that we can never fully anticipate or prepare for every scenario or eventuality; the future is simply too unpredictable. Instead, they build in buffers to reduce the friction caused by the unexpected.</p>
</blockquote>
<p>Essentialists produce more by removing more instead of doing more.</p>
<blockquote>
<p>Essentialists don’t default to Band-Aid solutions. Instead of looking for the most obvious or immediate obstacles, they look for the ones slowing down progress. They ask, “What is getting in the way of achieving what is essential?” While the Nonessentialist is busy applying more and more pressure and piling on more and more solutions, the Essentialist simply makes a one-time investment in removing obstacles. This approach goes beyond just solving problems; it’s a method of reducing your efforts to maximize your results.</p>
</blockquote>
<p>Essentialists make progress by making small and concrete wins. It’s harder to make achievement when you set big, lofty, and impossible goals.</p>
<blockquote>
<p>The way of the Nonessentialist is to go big on everything: to try to do it all, have it all, fit it all in. The Nonessentialist operates under the false logic that the more he strives, the more he will achieve, but the reality is, the more we reach for the stars, the harder it is to get ourselves off the ground.</p>
<p>The way of the Essentialist is different. Instead of trying to accomplish it all and all at once, and flaring out, the Essentialist starts small and celebrates progress. Instead of going for the big, flashy wins that don’t really matter, the Essentialist pursues small and simple wins in areas that are essential.</p>
</blockquote>
<blockquote>
<p>A popular idea in Silicon Valley is “Done is better than perfect.” The sentiment is not that we should produce rubbish. The idea, as I read it, is not to waste time on nonessentials and just to get the thing done. In entrepreneurial circles the idea is expressed as creating a “minimal viable product.” The idea is, “What is the simplest possible product that will be useful and valuable to the intended customer?”</p>
</blockquote>
<p>Personalizing patterns of action (i.e. routine) allows us to pay more attention to matters that count rather than to other’s expectations.</p>
<blockquote>
<p>The way of the Nonessentialist is to think the essentials only get done when they are forced. That execution is a matter of raw effort alone. You labor to make it happen. You push through.</p>
<p>The way of the Essentialist is different. The Essentialist designs a routine that makes achieving what you have identified as essential the default position. Yes, in some instances an Essentialist still has to work hard, but with the right routine in place each effort yields exponentially greater results.”</p>
</blockquote>
<p>Be present - Focus on what is important now. Don’t pretend that you can multifocus. </p>
<blockquote>
<p>As he tells his players: “There is a difference between losing and being beaten. Being beaten means they are better than you. They are faster, stronger, and more talented.” To Larry, losing means something else. It means you lost focus. It means you didn’t concentrate on what was essential. It is all based on a simple but powerful idea: to operate at your highest level of contribution requires that you deliberately tune in to what is important in the here and now.</p>
</blockquote>
<blockquote>
<p>The ancient Greeks had two words for time. The first was chronos. The second was kairos. The Greek god Chronos was imagined as an elderly, gray-haired man, and his name connotes the literal ticking clock, the chronological time, the kind we measure (and race about trying to use efficiently). Kairos is different. While it is difficult to translate precisely, it refers to time that is opportune, right, different. Chronos is quantitative; kairos is qualitative. The latter is experienced only when we are fully in the moment-when we exist in the now.</p>
</blockquote>
<blockquote>
<p>Nonessentialists tend to be so preoccupied with past successes and failures, as well as future challenges and opportunities, that they miss the present moment. They become distracted. Unfocused. They aren’t really there.<br>The way of the Essentialist is to tune into the present. To experience life in kairos, not just chronos. To focus on the things that are truly important-not yesterday or tomorrow, but right now.</p>
</blockquote>
<blockquote>
<p>We can easily do two things at the same time. What we can’t do is concentrate on two things at the same time. When I talk about being present, I’m not talking about doing only one thing at a time. I’m talking about being focused on one thing at a time. Multitasking itself is not the enemy of Essentialism; pretending we can “multifocus” is.</p>
</blockquote>
<h3 id="Related-to-Leadership"><a href="#Related-to-Leadership" class="headerlink" title="Related to Leadership"></a>Related to Leadership</h3><p>Again, clarity is the key. </p>
<blockquote>
<p>When there was a high level of clarity of purpose, the teams and the people on it overwhelmingly thrived. When there was a serious lack of clarity about what the team stood for and what their goals and roles were, people experienced confusion, stress, frustration, and ultimately failure. As one senior vice president succinctly summarized it when she looked at the results gathered from her extended team: “Clarity equals success.”</p>
</blockquote>
<blockquote>
<p>The Nonessentialist disempowers people by allowing ambiguity over who is doing what. Often this is justified in the name of wanting to be a flexible or agile team. But what is actually created is a counterfeit agility. When people don’t know what they are really responsible for and how they will be judged on their performance, when decisions either are or appear to be capricious, and when roles are ill-defined, it isn’t long before people either give up or, worse, become obsessed with trying to look busy and therefore important instead of actually getting any real work done.</p>
</blockquote>
<blockquote>
<p>The Nonessentialist leader communicates in code, and as a result people aren’t sure what anything really means. Nonessentialist communication usually is either too general to be actionable or changes so quickly that people are always caught off guard. Essentialist leaders, on the other hand, communicate the right things to the right people at the right time. Essentialist leaders speak succinctly, opting for restraint in their communication to keep the team focused. When they do speak, they are crystal clear. They eschew meaningless jargon, and their message is so consistent it seems almost boring to their ears. In this way, teams are able to pick up the essential through all the trivial noise.</p>
</blockquote>
<p>Apply “less but better” in hiring people. </p>
<blockquote>
<p>And the cost of hiring too many wrong people (and one wrong hire often leads to multiple wrong hires because the wrong person will tend to attract more wrong people) is what Guy Kawasaki called a “Bozo explosion”—a term he uses to describe what happens when a formerly great team or company descends into mediocrity.</p>
</blockquote>
<blockquote>
<p>An Essentialist, on the other hand, is ridiculously selective on talent. She has the discipline to hold out for the perfect hire-no matter how many résumés she has to read, or interviews she has to conduct, or talent searches she has to make-and doesn’t hesitate to remove people who hold the team back. The result is a team full of all-star performers whose collective efforts add up to more than the sum of their parts.</p>
</blockquote>
<h3 id="Some-interesting-observations-or-research-results-mentioned"><a href="#Some-interesting-observations-or-research-results-mentioned" class="headerlink" title="Some interesting observations or research results mentioned"></a>Some interesting observations or research results mentioned</h3><p>This is how after you become a “go to” person and gain a lot of opportunities, you started to diffuse your efforts and be distracted by a lot of options.</p>
<blockquote>
<ol>
<li>The pursuit of success can be a catalyst for failure. Put another way, success can distract us from focusing on the essential things that produce success in the first place.</li>
<li>We are unprepared in part because, for the first time (in human history), the preponderance of choice has overwhelmed our ability to manage it. We have lost our ability to filter what is important and what isn’t. Psychologists call this “decision fatigue”: the more choices we are forced to make, the more the quality of our decisions deteriorates.</li>
</ol>
</blockquote>
<p>If you are an overachiever thinking you can do anything, how about taking the challenge of saying no to an opportunity and taking a nap.</p>
<blockquote>
<ol start="3">
<li>Stuart Brown, the founder of the National Institute for Play, has studied what are called the play histories of some six thousand individuals and has concluded that play has the power to significantly improve everything from personal health to relationships to education to organizations’ ability to innovate.<br>  “Play,” he says, “leads to brain plasticity, adaptability, and creativ-ity.” As he succinctly puts it, “Nothing fires up the brain like play.”</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>In a Harvard Business Review article called “Sleep Deficit: The Performance Killer,” Charles A. Czeisler, the Baldino Professor of Sleep Medicine at Harvard Medical School, has explained how sleep deprivation undermines high performance. He likens sleep deficit to drinking too much alcohol, explaining that pulling an all-nighter i.e., going twenty-four hours without sleep) or having a week of sleeping just four or five hours a night actually “induces an impairment equivalent to a blood alcohol level of 0.1%. Think about this: we would never say, ‘This person is a great worker! He’s drunk all the time!’ yet we continue to celebrate people who sacrifice sleep for work.”</li>
<li>The researchers explained that while we sleep our brains are hard at work encoding and restructuring information. Therefore, when we wake up, our brains may have made new neural connections, thereby opening up a broader range of solutions to problems, literally overnight.</li>
</ol>
</blockquote>
<p>Clarity is critical.</p>
<blockquote>
<ol start="6">
<li>In my work, I have noticed two common patterns that typically emerge when teams lack clarity of purpose.</li>
</ol>
<p>  a. Playing politics</p>
<p>  In the first pattern, the team becomes overly focused on winning the attention of the manager. The problem is, when people don’t know what the end game is, they are unclear about how to win, and as a result they make up their own game and their own rules as they vie for the manager’s favor. Instead of focusing their time and energies on making a high level of contribution, they put all their effort into games like attempting to look better than their peers, demonstrating their self-importance, and echoing their manager’s every idea or sentiment. These kinds of activities are not only nonessential but damaging and counterproductive.</p>
<p>  b. It’s all good (which is bad)</p>
<p>  In the second pattern, teams without purpose become leaderless. With no clear direction, people pursue the things that advance their own short-term interests, with little awareness of how their activities contribute to (or in some cases, derail) the long-term mission of the team as a whole.</p>
</blockquote>
<p>‘Uncommit’ is a way to minimize loss and win big.</p>
<blockquote>
<ol start="7">
<li>Sunk-cost bias is the tendency to continue to invest time, money, or energy into something we know is a losing proposition simply because we have already incurred, or sunk, a cost that cannot be re-couped. But of course this can easily become a vicious cycle: the more we invest, the more determined we become to see it through and see our investment pay off. The more we invest in something, the harder it is to let go.</li>
</ol>
</blockquote>
<p>The power of small wins.</p>
<blockquote>
<ol start="8">
<li>Research has shown that of all forms of human motivation the most effective one is progress. Why? Because a small, concrete win creates momentum and affirms our faith in our further success. In his 1968 Harvard Business Review article entitled “One More Time: How Do You Motivate Employees?” among the most popular Harvard Business Review articles of all time, Frederick Herzberg reveals research showing that the two primary internal motivators for people are achievement and recognition for achievement.</li>
</ol>
</blockquote>
<blockquote>
<ol start="9">
<li>Indeed, today Zimbardo is attempting a grand social experiment along those lines called the “Heroie Imagination Project.” The logic is to increase the odds of people operating with courage by teaching them the principles of heroism. By encouraging and rewarding heroic acts, Zimbardo believes, we can consciously and deliberately create a system where heroic aets eventually become natural and effortless.</li>
</ol>
</blockquote>
<p>Be present and focus on one thing.</p>
<blockquote>
<ol start="10">
<li>Thich Nhat Hanh, the Vietnamese Zen Buddhist monk who has been called the “world’s calmest man,” has spent a lifetime exploring how to live in kairos, albeit by a different name. He has taught it as mindfulness or maintaining “beginner’s mind.” He has written: “Mindfulness helps you go home to the present. And every time you go there and recognize a condition of happiness that you have, happiness comes.”</li>
</ol>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/27/Biased-and-Debiased-Machine-Learning-in-Causal-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/27/Biased-and-Debiased-Machine-Learning-in-Causal-Inference/" class="post-title-link" itemprop="url">Biased and Debiased Machine Learning in Causal Inference</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-27 21:53:36" itemprop="dateCreated datePublished" datetime="2024-07-27T21:53:36-04:00">2024-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-28 12:52:30" itemprop="dateModified" datetime="2024-07-28T12:52:30-04:00">2024-07-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>The application of machine learning methods in estimating treatment effects is a burgeoning area in causal inference. The regression function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span> and the propensity score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">e</span></span></span></span> used to estimate the average treatment effects can be estimated using machine learning methods like random forests. However, the naive applications of machine learning methods to estimate treatment effects lead to biased estimates due to regularization bias. The proof examines the asymptotic behavior of the estimator.</p>
<h2 id="Proof-Process"><a href="#Proof-Process" class="headerlink" title="Proof Process"></a>Proof Process</h2><ol>
<li><p><strong>Define the Model and Estimator</strong>:</p>
<ul>
<li>Assume a partially linear regression model where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> is the outcome, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> is the treatment indicator, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> represents covariates.</li>
<li>The regression function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and the propensity score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> are modeled non-parametrically using machine learning methods.</li>
</ul>
</li>
<li><p><strong>Assumptions</strong>:</p>
<ul>
<li>Treatment assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> is unconfounded given covariates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>.</li>
<li>Residuals (errors) satisfy usual assumptions (e.g., mean zero, finite variance).</li>
</ul>
</li>
<li><p><strong>Estimator Definition</strong>:</p>
<ul>
<li>Split the data into two groups.</li>
<li>Estimate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> using the second group with a machine learning method.</li>
<li>Regress <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y−\hat{g}(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> in the first group to obtain the estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> for the treatment effect.</li>
</ul>
</li>
<li><p><strong>Rewrite the Estimator</strong>:</p>
<ul>
<li><p>Express the estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> in a form that separates the effect of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and the residuals: </p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>treated</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>control</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\theta} = \frac{1}{N_1} \sum_{i \in \text{treated}} \left[ Y_i - \hat{g}(X_i) \right] - \frac{1}{N_0} \sum_{i \in \text{control}} \left[ Y_i - \hat{g}(X_i) \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">treated</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">control</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span></li>
</ul>
</li>
<li><p><strong>Decompose into Asymptotic Terms</strong>:</p>
<ul>
<li><p>Decompose <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> into terms that reveal the contributions of the estimation error from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{g}(X) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> and the residuals:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mi>θ</mi><mo>+</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>treated</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>ϵ</mi><mi>i</mi></msub><mo>−</mo><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mtext>control</mtext></mrow></msub><mrow><mo fence="true">[</mo><msub><mi>ϵ</mi><mi>i</mi></msub><mo>−</mo><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\theta} = \theta + \frac{1}{N_1} \sum_{i \in \text{treated}} \left[ \epsilon_i - (\hat{g}(X_i) - g(X_i)) \right] - \frac{1}{N_0} \sum_{i \in \text{control}} \left[ \epsilon_i - (\hat{g}(X_i) - g(X_i)) \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">treated</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord text mtight"><span class="mord mtight">control</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3271em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0em;">]</span></span></span></span></span></li>
</ul>
</li>
<li><p><strong>Analyze Asymptotic Distribution</strong>:</p>
<ul>
<li><strong>First Term</strong>: Under usual regularity conditions, the term involving <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\epsilon_i </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (residuals) converges in distribution to a normal distribution.</li>
<li><strong>Second Term</strong>: The term involving <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{g}(X_i) - g(X_i) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> represents the bias due to regularization in the machine learning method. This term does not have mean zero and can diverge to infinity.</li>
</ul>
</li>
<li><p><strong>Conclusion on Bias</strong>:</p>
<ul>
<li>The second term introduces bias because the machine learning method’s regularization bias does not vanish asymptotically.</li>
<li>This results in the estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> being asymptotically biased, even if the first term converges to a normal distribution.</li>
</ul>
</li>
</ol>
<h3 id="Detailed-Example"><a href="#Detailed-Example" class="headerlink" title="Detailed Example"></a>Detailed Example</h3><ol>
<li><p><strong>Model Setup</strong>:</p>
<ul>
<li>Let <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>Z</mi><mi>θ</mi><mo>+</mo><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">Y=Zθ+g(X)+ϵ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">Zθ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span></li>
<li>Estimate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> using a machine learning method (e.g., random forest).</li>
</ul>
</li>
<li><p><strong>Estimator</strong>:</p>
<ul>
<li><p>Split data into two parts.</p>
</li>
<li><p>Use part one to estimate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{g}(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>.</p>
</li>
<li><p>Use part two to calculate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span>: </p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msub><mi>Z</mi><mi>i</mi></msub><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{\theta} = \frac{1}{N_1} \sum_{i=1}^{N_1} (Y_i - \hat{g}(X_i)) Z_i - \frac{1}{N_0} \sum_{i=1}^{N_0} (Y_i - \hat{g}(X_i)) (1 - Z_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
<li><p><strong>Asymptotic Analysis</strong>:</p>
<ul>
<li><p>Rewrite the estimator to separate terms: </p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mi>θ</mi><mo>+</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><msub><mi>ϵ</mi><mi>i</mi></msub><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><msub><mi>ϵ</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\theta} = \theta + \left( \frac{1}{N_1} \sum_{i=1}^{N_1} \epsilon_i - \frac{1}{N_0} \sum_{i=1}^{N_0} \epsilon_i \right) - \left( \frac{1}{N_1} \sum_{i=1}^{N_1} (\hat{g}(X_i) - g(X_i)) - \frac{1}{N_0} \sum_{i=1}^{N_0} (\hat{g}(X_i) - g(X_i)) \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></li>
</ul>
</li>
<li><p><strong>Identify Bias Term</strong>:</p>
<ul>
<li>The second term <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></msubsup><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{N_1} \sum_{i=1}^{N_1} (\hat{g}(X_i) - g(X_i)) - \frac{1}{N_0} \sum_{i=1}^{N_0} (\hat{g}(X_i) - g(X_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4263em;vertical-align:-0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span> represents the bias due to regularization in the machine learning method.</li>
</ul>
</li>
<li><p><strong>Conclusion</strong>:</p>
<ul>
<li>The bias term does not converge to zero, leading to an asymptotically biased estimator.</li>
<li>This illustrates why naive application of machine learning methods without addressing regularization bias can lead to incorrect estimates of treatment effects.</li>
</ul>
</li>
</ol>
<h2 id="Steps-to-Obtain-a-Debiased-Estimator"><a href="#Steps-to-Obtain-a-Debiased-Estimator" class="headerlink" title="Steps to Obtain a Debiased Estimator"></a>Steps to Obtain a Debiased Estimator</h2><p>To obtain a debiased estimator using machine learning methods, we follow a systematic approach that addresses the regularization bias inherent in machine learning models. Here is a detailed process:</p>
<h4 id="1-Setup-the-Problem"><a href="#1-Setup-the-Problem" class="headerlink" title="1. Setup the Problem"></a>1. <strong>Setup the Problem</strong></h4><p>Define the outcome <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>, treatment indicator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>, and covariates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. The objective is to estimate the average treatment effect (ATE).</p>
<h4 id="2-Split-the-Data"><a href="#2-Split-the-Data" class="headerlink" title="2. Split the Data"></a>2. <strong>Split the Data</strong></h4><p>Divide the dataset into two parts to avoid overfitting and ensure valid inference:</p>
<ul>
<li><strong>Part 1</strong>: Used to estimate the propensity score.</li>
<li><strong>Part 2</strong>: Used to estimate the regression function.</li>
</ul>
<h4 id="3-Estimate-the-Propensity-Score"><a href="#3-Estimate-the-Propensity-Score" class="headerlink" title="3. Estimate the Propensity Score"></a>3. <strong>Estimate the Propensity Score</strong></h4><p>Using <strong>Part 1</strong> of the data, estimate the propensity score <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>Z</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(X) = P(Z = 1 | X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>. This can be done using a machine learning model such as logistic regression, random forests, or other methods.</p>
<h4 id="4-Estimate-the-Regression-Function"><a href="#4-Estimate-the-Regression-Function" class="headerlink" title="4. Estimate the Regression Function"></a>4. <strong>Estimate the Regression Function</strong></h4><p>Using <strong>Part 2</strong> of the data, estimate the regression function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">g(X) = E[Y | X]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">]</span></span></span></span> using a machine learning model such as random forests, gradient boosting machines, or any other suitable method.</p>
<h4 id="5-Calculate-Residuals"><a href="#5-Calculate-Residuals" class="headerlink" title="5. Calculate Residuals"></a>5. <strong>Calculate Residuals</strong></h4><p>For the treated and control groups in <strong>Part 2</strong> of the data, calculate the residuals:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>U</mi><mo>^</mo></mover><mi>i</mi></msub><mo>=</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{U}_i = Y_i - \hat{g}(X_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0968em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>

<h4 id="6-Debiasing-Step"><a href="#6-Debiasing-Step" class="headerlink" title="6. Debiasing Step"></a>6. <strong>Debiasing Step</strong></h4><p>Estimate the treatment effect using the residuals and propensity scores. Calculate the debiased estimate by adjusting for the propensity score:</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mover accent="true"><mi>e</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mover accent="true"><mi>e</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow><mo>+</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mover accent="true"><mi>g</mi><mo>^</mo></mover><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{\theta} = \frac{1}{N} \sum_{i=1}^N \left( \frac{Z_i (Y_i - \hat{g}(X_i))}{\hat{e}(X_i)} - \frac{(1 - Z_i) (Y_i - \hat{g}(X_i))}{1 - \hat{e}(X_i)} \right) + \frac{1}{N} \sum_{i=1}^N \hat{g}(X_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight">e</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">))</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight">e</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord mtight">^</span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0785em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">))</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>

<h4 id="7-Variance-Estimation"><a href="#7-Variance-Estimation" class="headerlink" title="7. Variance Estimation"></a>7. <strong>Variance Estimation</strong></h4><p>Estimate the variance of the debiased estimator to construct confidence intervals. This step involves calculating the standard error of the debiased estimate.</p>
<h4 id="8-Construct-Confidence-Intervals"><a href="#8-Construct-Confidence-Intervals" class="headerlink" title="8. Construct Confidence Intervals"></a>8. <strong>Construct Confidence Intervals</strong></h4><p>Using the standard error, construct confidence intervals for the treatment effect estimate.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/27/Lecture-Note-Overview-of-Modern-Approach-of-Causal-Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/27/Lecture-Note-Overview-of-Modern-Approach-of-Causal-Inference/" class="post-title-link" itemprop="url">Lecture Note - Overview of Modern Approach of Causal Inference</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-27 18:22:52" itemprop="dateCreated datePublished" datetime="2024-07-27T18:22:52-04:00">2024-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-28 12:54:42" itemprop="dateModified" datetime="2024-07-28T12:54:42-04:00">2024-07-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>This is one of my notes of the online Causal Inference Course in Columbia University, taught by Michael E. Sobel who is a professor in the Department of Statistics. It would be good to have this overview of causal inference regarding the framework in mind before getting into statistical and theoretical details especially for beginners. A clear approach framework is very important that it’s not only because rigorous experiment and analysis methods could be developed with this well-defined framework, but also because it can guide you to deal with challenging situations in a correct way, while being clear about the limitations and assumptions at the same time. This is why it became a Science.</p>
<h1 id="Modern-Approach-for-Causal-Inference"><a href="#Modern-Approach-for-Causal-Inference" class="headerlink" title="Modern Approach for Causal Inference"></a>Modern Approach for Causal Inference</h1><p>The modern dominant approach for causal inference, significantly influenced by Donald Rubin’s contributions, primarily revolves around the following key ideas:</p>
<ol>
<li><p>Potential Outcomes Framework:</p>
<ul>
<li><strong>Potential Outcomes Notation</strong>: Introduced by Neyman and further developed by Rubin, this framework involves conceptualizing the outcomes that would occur both with and without the treatment for each unit. Each unit has a potential outcome under treatment and a potential outcome under control, but only one of these outcomes is observed for each unit.</li>
<li><strong>Average Treatment Effects</strong>: The focus is on estimating the average causal effect of a treatment across a population. This involves comparing the average outcomes of treated and untreated groups, taking into account the potential outcomes framework.</li>
</ul>
</li>
<li><p>Randomization and Its Analogs:</p>
<ul>
<li><strong>Role of Randomization</strong>: In experimental studies, random assignment of treatments is crucial for ensuring that the treatment groups are comparable, allowing for unbiased estimation of causal effects.</li>
<li><strong>Randomization-like Conditions in Observational Studies</strong>: Rubin extended the framework to observational studies by arguing that causal inferences can be made if these studies fulfill conditions similar to randomization. This involves controlling for confounding variables that influence both the treatment and the outcome, often through methods like matching, regression adjustment, or instrumental variables.</li>
</ul>
</li>
<li><p>Counterfactual Reasoning:</p>
<ul>
<li><strong>Counterfactual Conditionals</strong>: Causal relationships must satisfy counterfactual conditions. This means that for a cause to be deemed responsible for an effect, it should be demonstrable that if the cause had not occurred, the effect would not have occurred. This is formalized through the potential outcomes framework.</li>
</ul>
</li>
</ol>
<h2 id="Key-Features-of-Rubin’s-Approach"><a href="#Key-Features-of-Rubin’s-Approach" class="headerlink" title="Key Features of Rubin’s Approach:"></a>Key Features of Rubin’s Approach:</h2><ul>
<li><strong>Application to Both Experimental and Observational Studies</strong>: Rubin’s framework is versatile and can be applied to both types of studies, providing a unified approach to causal inference.</li>
<li><strong>Focus on Estimating Causal Effects</strong>: The primary goal is to estimate the causal effect of treatments or interventions, rather than simply identifying associations.</li>
<li><strong>Use of Statistical Methods</strong>: The approach leverages statistical methods to control for confounding variables and to estimate causal effects, emphasizing the importance of rigorous statistical analysis.</li>
</ul>
<h2 id="Two-Key-Criteria-of-Modern-Causal-Inference"><a href="#Two-Key-Criteria-of-Modern-Causal-Inference" class="headerlink" title="Two Key Criteria of Modern Causal Inference"></a>Two Key Criteria of Modern Causal Inference</h2><p>The modern dominant approach to causal inference primarily builds on two key criteria:</p>
<ol>
<li><p>Causation at the Singular Level:</p>
<ul>
<li>This criterion allows for the possibility that causation can be specific to individual subjects or units, acknowledging effect heterogeneity. It means that a cause may produce an effect in one individual but not necessarily in another, depending on various conditions.</li>
</ul>
</li>
<li><p>Satisfaction of Counterfactual Conditionals:</p>
<ul>
<li>A causal relationship must sustain a counterfactual conditional. This means that for a cause to be deemed responsible for an effect, it should be demonstrable that if the cause had not occurred, the effect would not have occurred. This criterion is essential for defining and reasoning about causal relationships in both experimental and observational studies.</li>
</ul>
</li>
</ol>
<h2 id="Impact-on-Empirical-Research"><a href="#Impact-on-Empirical-Research" class="headerlink" title="Impact on Empirical Research:"></a>Impact on Empirical Research:</h2><p>Rubin’s contributions have led to more careful and precise inferences about causal effects in various disciplines, particularly in the social sciences. Researchers now more rigorously design studies and analyze data to ensure that their conclusions about causality are well-founded within this robust statistical framework.</p>
<h2 id="Challenges-in-Randomized-Studies"><a href="#Challenges-in-Randomized-Studies" class="headerlink" title="Challenges in Randomized Studies:"></a>Challenges in Randomized Studies:</h2><ol>
<li><p>Non-compliance with Treatment Assignments:</p>
<ul>
<li><strong>Example</strong>: In a study by the University of Michigan in the 1990s, unemployed persons were assigned to receive or not receive assistance in job searching. A significant percentage of those assigned to the treatment group did not actually take the treatment, complicating the comparison between groups and potentially overestimating the treatment’s effectiveness.</li>
</ul>
</li>
<li><p>Intermediate Variables:</p>
<ul>
<li><strong>Example</strong>: An educational researcher wants to know the effect of encouragement to study on test scores. While the researcher can estimate the effect of encouragement, estimating the direct effect of study time is more complicated because it involves intermediate variables (encouragement affecting study time, which in turn affects test scores).</li>
</ul>
</li>
<li><p>Breakdown of Random Assignment:</p>
<ul>
<li><strong>Example</strong>: If a subject’s treatment adherence is influenced by their perception of treatment benefits, comparing only those who comply can lead to biased estimates.</li>
</ul>
</li>
</ol>
<h2 id="Challenges-in-Observational-Studies"><a href="#Challenges-in-Observational-Studies" class="headerlink" title="Challenges in Observational Studies:"></a>Challenges in Observational Studies:</h2><ol>
<li><p>Identifying and Measuring All Covariates:</p>
<ul>
<li><strong>Example</strong>: When studying the effect of education on earnings, researchers must account for various covariates that affect both education levels and earnings. Failure to identify or measure all relevant covariates can lead to biased estimates.</li>
</ul>
</li>
<li><p>Estimating Average Treatment Effects:</p>
<ul>
<li><strong>Example</strong>: In observational studies, various methods like matching, weighting, and regression are used to estimate treatment effects. Each method has its own set of practical issues and assumptions that need to be carefully managed.</li>
</ul>
</li>
<li><p>Longitudinal Observational Studies:</p>
<ul>
<li><strong>Example</strong>: When treatments administered in different periods depend on previous treatments and outcomes, analysis becomes more complicated.</li>
</ul>
</li>
<li><p>Interference:</p>
<ul>
<li><strong>Example</strong>: In a housing experiment conducted by the U.S. government, participants assigned to move from housing projects to suburbs knew each other. If the treatment assignment of one participant influenced the decision or outcome of another, traditional analysis methods might not be adequate.</li>
</ul>
</li>
</ol>
<p>These examples illustrate that both randomized and observational studies require careful consideration of various factors to ensure accurate and reliable causal inferences.</p>
<h1 id="Potential-Outcomes-Unit-and-Average-Effect"><a href="#Potential-Outcomes-Unit-and-Average-Effect" class="headerlink" title="Potential Outcomes, Unit, and Average Effect"></a>Potential Outcomes, Unit, and Average Effect</h1><h2 id="Potential-Outcomes-Framework"><a href="#Potential-Outcomes-Framework" class="headerlink" title="Potential Outcomes Framework"></a>Potential Outcomes Framework</h2><ol>
<li>Potential Outcomes:<ul>
<li>Each unit (e.g., individual) has two potential outcomes: one if treated and one if not treated. However, only one outcome can be observed for each unit.</li>
<li>This leads to the “fundamental problem of causal inference,” where we cannot observe both potential outcomes for a single unit.</li>
</ul>
</li>
<li>Notation and Unit Effects:<ul>
<li>For a unit <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>, denote the outcome as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y_i (1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> if treated and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y_i (0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0</span><span class="mclose">)</span></span></span></span> if not treated.</li>
<li>The unit effect is defined as the difference <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Y_i (1)−Y_i (0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0</span><span class="mclose">)</span></span></span></span>.</li>
<li>The observed outcome Yi is determined by the treatment assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">Z_i=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> if the unit is treated and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">Z_i=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> if not.</li>
</ul>
</li>
<li>Randomized vs. Observational Studies:<ul>
<li>In randomized experiments, treatment assignment <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is random.</li>
<li>In observational studies, subjects choose their treatment, introducing potential biases.</li>
</ul>
</li>
</ol>
<h2 id="Average-Treatment-Effects"><a href="#Average-Treatment-Effects" class="headerlink" title="Average Treatment Effects"></a>Average Treatment Effects</h2><ol>
<li>Sample Average Treatment Effect (SATE):<ul>
<li>The average of the unit effects for the sample.</li>
</ul>
</li>
<li>Finite Population Average Treatment Effect (FATE):<ul>
<li>The average treatment effect for a finite population from which the sample is drawn.</li>
</ul>
</li>
<li>Average Treatment Effect (ATE):<ul>
<li>The average treatment effect in an infinite or large population. This is treated as an expectation of the potential outcomes.</li>
</ul>
</li>
<li>Estimands of Interest:<ul>
<li>Various estimands depend on the marginal distributions of potential outcomes, such as ATE and Average Treatment Effect on the Treated (ATT).</li>
</ul>
</li>
<li>Challenges and Assumptions:<ul>
<li>Estimating these effects requires assumptions like the Stable Unit Treatment Value Assumption (SUTVA), which ensures that the potential outcomes are well-defined and not affected by other units’ treatments.</li>
</ul>
</li>
</ol>
<h2 id="Practical-Implications"><a href="#Practical-Implications" class="headerlink" title="Practical Implications"></a>Practical Implications</h2><ol>
<li>Decision-Making:<ul>
<li>Knowledge of average treatment effects aids decision-making in contexts like medical treatments and policy implementations.</li>
</ul>
</li>
<li>Ignorability Conditions:<ul>
<li>Under certain conditions, known as ignorability or unconfoundedness, it is possible to use observed data to estimate causal effects reliably.</li>
</ul>
</li>
<li>Extensions and Assumptions:<ul>
<li>The framework extends to multiple treatments and continuous treatments, though additional assumptions may be required.</li>
<li>SUTVA assumes no alternative representations of treatment and no interference between units, which may need adjustments in certain studies.</li>
</ul>
</li>
</ol>
<h1 id="Conditions-Allow-Average-Effects-be-Unbiasedly-Consistently-Estimated"><a href="#Conditions-Allow-Average-Effects-be-Unbiasedly-Consistently-Estimated" class="headerlink" title="Conditions Allow Average Effects be Unbiasedly&#x2F; Consistently Estimated"></a>Conditions Allow Average Effects be Unbiasedly&#x2F; Consistently Estimated</h1><h2 id="Key-Concepts"><a href="#Key-Concepts" class="headerlink" title="Key Concepts"></a>Key Concepts</h2><ol>
<li>Average Treatment Effect (ATE) Estimation:<ul>
<li><strong>Random Sampling</strong>: Drawing random samples of treated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) and untreated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) units to estimate their respective means.</li>
<li><strong>Sample Means</strong>: The means of treated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\bar{y}_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) and untreated (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\bar{y}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>) samples serve as unbiased and consistent estimators of the population means.</li>
</ul>
</li>
<li>Unconfoundedness:<ul>
<li><strong>Definition</strong>: Treatment assignment z is independent of potential outcomes (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</li>
<li><strong>Intuition</strong>: In randomized experiments, treatment assignment is blind to potential outcomes, ensuring unconfoundedness. In observational studies, treatment assignment might depend on factors related to potential outcomes, potentially confounding the estimates.</li>
</ul>
</li>
</ol>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><ol>
<li>Randomized Experiment vs. Observational Study:<ul>
<li><strong>Randomized Experiment</strong>: Treatment assignment is random (e.g., coin flip), ensuring <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> is independent of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li>
<li><strong>Observational Study</strong>: Treatment assignment may depend on patient characteristics, potentially leading to biased estimates.</li>
</ul>
</li>
<li>Age and Treatment Example:<ul>
<li><strong>Scenario</strong>: Older patients might forego treatment believing it’s less beneficial, while younger patients might opt for treatment believing it’s more beneficial.</li>
<li><strong>Consequence</strong>: Naive comparison between treated and untreated groups might overestimate the treatment effect due to confounding by age.</li>
</ul>
</li>
</ol>
<h2 id="Ignorability-Condition"><a href="#Ignorability-Condition" class="headerlink" title="Ignorability Condition"></a>Ignorability Condition</h2><ol>
<li>Condition: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are independent of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> given covariates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> (e.g., age).<ul>
<li><strong>Stratified Analysis</strong>: In both randomized experiments and observational studies, stratifying on covariates like age can help achieve conditional unconfoundedness.</li>
</ul>
</li>
<li>Adjusting for Covariates:<ul>
<li><strong>Randomized Experiment</strong>: Can stratify on covariates either before or after the experiment.</li>
<li><strong>Observational Study</strong>: Treat it as a stratified randomized experiment by conditioning on covariates related to treatment status and potential outcomes.</li>
</ul>
</li>
</ol>
<h2 id="Practical-Implications-1"><a href="#Practical-Implications-1" class="headerlink" title="Practical Implications"></a>Practical Implications</h2><ol>
<li>Comparison of Groups:<ul>
<li>In a stratified randomized experiment, compare treated and control groups within each stratum (e.g., age group) to estimate ATE.</li>
<li>In observational studies, stratify on covariates to reduce bias and estimate ATE as if it were a stratified randomized experiment.</li>
</ul>
</li>
<li>Challenges in Observational Studies:<ul>
<li><strong>Unknown Assignment Mechanism</strong>: Unlike randomized experiments, the assignment mechanism in observational studies is not controlled, making it harder to ensure unconfoundedness.</li>
<li><strong>Measurement of Confounders</strong>: It’s crucial to measure and account for all relevant confounders, though it may not always be possible.</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/20/2024-July/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/20/2024-July/" class="post-title-link" itemprop="url">2024 July</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-20 00:22:38" itemprop="dateCreated datePublished" datetime="2024-07-20T00:22:38-04:00">2024-07-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-08-11 11:46:18" itemprop="dateModified" datetime="2024-08-11T11:46:18-04:00">2024-08-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><strong>Playing defense: How to control the narrative if your work is being questioned - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/playing-defense-how-to-control-narrative">Link</a>]</p>
</blockquote>
<p>It’s normal that people will misunderstand and disagree with you. what we need to do is to 1) learn to explain your ideas better and 2) stay calm and share your thought process in the most objective way possible.</p>
<p>Defending your thinking means to share logic, evidence and rationale that explains why you believe your conclusion is the right one. It’s not to try to protect your ego by refusing to acknowledge a good argument, and being delusional about the strength of your claim. Being able to play defense is important because it’s about your credibility. If you do it well you are building more trust, otherwise you will be diminishing trust.</p>
<p>Some suggestions mentioned in this article:</p>
<ul>
<li>﻿﻿Have a rationale of every small decision you made.</li>
<li>﻿﻿Try to anticipate questions.</li>
<li>﻿﻿Embrace “show, not tell”</li>
<li>﻿﻿React as positively as possible. e.g.<br> “Ah! I’m so glad you asked”.</li>
<li>﻿﻿Consider the question behind the question.</li>
<li>﻿﻿Be happy that the person voiced their concern.</li>
<li>﻿﻿Beware of insecure vibes.</li>
</ul>
<p>If you overcompensate, you’ll come across as defensive. This decreases your credibility too. You’ll need to use your judgment and read the situation. An open, curious, and almost playful attitude shows you’re not afraid of hard questions.</p>
<p>Many people underestimate the daily moments where your credibility can either be reinforced or eroded. This might sound dramatic, but it’s quite banal: Every interaction folks have with you gets added to their subconscious cumulative repository of data points about you.</p>
<blockquote>
<p><em>Insecure vibes are subconscious clues and signals that you might be giving off when you’re feeling anxious, nervous, or uncertain. Get rid of insecure vibes—and your writing, meetings, presentations, negotiations, and pitches will become stronger.</em></p>
<p><strong>― “Insecure vibes” are a self-fulfilling prophecy - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/insecure-vibes-are-a-self-fulfilling">Link</a>]</p>
</blockquote>
<p>In the following situations, insecure vibes happen: </p>
<ul>
<li><p>When other person touched on your sore spot and you feel threatened</p>
</li>
<li><p>You assume the person will say no before you even start</p>
<p>This can make you talk fast - showing you enter the conversation already playing defense. You don’t give the person a chance to say yes because you’ve already said no to yourself.</p>
</li>
<li><p>You insist on email or slack when you know a phone call is better</p>
<p>Explaining your point in writing is a sign of lacking confidence and avoiding confrontation.</p>
</li>
<li><p>You over-explain because you expect the other person to be skeptical</p>
<p>You bring up counterpoints to arguments no one has mentioned. Not a good time to do so. It looks like you intentionally bring up something new to surprise others rather than having a reasonable justification of your point.</p>
</li>
</ul>
<p>To avoid being doubtful if you actually feel confident:</p>
<ul>
<li>Don’t preface your idea with too many caveats. Speak in complete sentences. Remove “ands” and “buts” that create never-ending sentences, which can sound less authoritative. </li>
<li>Notice if you start to ramble. Try to prepare the first few lines of what you want to say to kick off a meeting, so you start strong. </li>
<li>Practice your actual script so you get comfortable saying those words.</li>
</ul>
<p>To get rid of insecure vibes, ask yourself</p>
<ul>
<li>Could this be interpreted as sounding defensive?</li>
<li>Am I overcompensating or overexplaining?</li>
<li>How would I respond on my best day?</li>
<li>Would I say this if I felt secure?</li>
</ul>
<blockquote>
<p><strong>Strategy, not self-expression: How to decide what to say when giving feedback - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/strategy-not-self-expression">Link</a>]</p>
</blockquote>
<p>Ask yourself “Is this strategy or self expression?” before giving feedback.</p>
<ul>
<li>Do not self-express your feeling or complain. Do not say anything that does not motivate them to change. Instead, say things that get you closer to changing the person’s behavior.</li>
</ul>
<p>How to focus on strategy rather than self-expression:</p>
<ul>
<li><p>Mentally forgive this person</p>
</li>
<li><p>Identify what is most likely to motivate them to change, </p>
</li>
<li><p>Say only 10% that will actually change behavior, thinking about:</p>
<ul>
<li>How does this make them even more effective?</li>
<li>How will this allow them to work even better with the people around them?</li>
<li>How does this get them closer to their goals?</li>
<li>How is this a skill they can apply now and in all future roles?</li>
</ul>
</li>
<li><p>Don’t trigger the defensiveness in the first place</p>
<p>The minute your recipient gets defensive, it becomes a lot harder to undo the defensiveness and get them to accept what you’re saying. </p>
</li>
<li><p>Let the other person talk, e.g.  “I’d love to hear what you think. What parts are resonating most with you?”</p>
<p>The other benefit of letting the other person talk is <em>cognitive dissonance</em>: if they say out loud what they are committed to doing differently, they are reinforcing the idea in their own mind. </p>
</li>
<li><p>Keep your eyes on the person’s behavior change</p>
</li>
<li><p>Always be framing</p>
<p>“Strategy, not self-expression” applies to many more situations too.</p>
</li>
</ul>
<blockquote>
<ol>
<li><em>The more controversial the idea, the higher the burden of proof.</em></li>
<li><em>Update your assumptions about how you add value.</em></li>
<li><em>Share where your hunch is coming from—because it’s coming from somewhere.</em></li>
<li><em>Describe why the problem matters, so people understand why you’re speaking up.</em></li>
<li><em>Don’t rely on your credentials. Your idea should make sense on its own.</em></li>
<li><em>Use language that accurately reflects your level of certainty.</em></li>
</ol>
<p><strong>― How to share your point of view (even if you’re afraid of being wrong) - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/high-performers-share-their-point-of-view">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Every week, we make business cases at work. I’m defining a business case as any recommendation to pursue a business opportunity or solve a problem. A business case can be a 5-page document, 5 sentences in Slack, or a 5-minute phone call. The larger the project, the more you may need to make a comprehensive business case. But the underlying premise is the same: If you don’t explain why a problem matters, your colleagues won’t have the necessary information to decide how to support you.</em></p>
<p><strong>― The #1 question every business case should answer - Wes Kao’s Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.weskao.com/p/the-1-question-every-business-case">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Skilled immigration is a national security priority - Noahpinion</strong> [<a target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/skilled-immigration-is-a-national">Link</a>]</p>
</blockquote>
<p>Skilled immigration should be supported while illegal immigration should be avoided. Also, avoid US education system to become corrupt system for immigration.</p>
<blockquote>
<p><strong>The low road, the high road, and the way the wind blows - Silver Bulletin</strong> [<a target="_blank" rel="noopener" href="https://www.natesilver.net/p/the-low-road-the-high-road-and-the">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Paramount Merges With Skydance - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/paramount-merges-with-skydance">Link</a>]</p>
</blockquote>
<p>PARA agreed to merge with Skydance. The new CEO is Skydance Media CEO David Ellison whose father Larry Ellison is the founder of Oracle. </p>
<p>Old paramount businesses: 1) filmed entertainment (Paramount Pictures and Nickelodeon movie), 2) TV media (Paramount’s broadcast) and cable television networks, like CBS and MTV, 3) Direct to consumer streaming services like Paramount+ and Pluto TV. Its current problems: 1) flat revenue, 2) streaming services are losing, 3) high long-term debt but low cash.</p>
<p>New Paramount Plan: 1) unify marquee rights, 2) reorganize finance, 3) transition into a tech-media hybrid.</p>
<p>For the #3, the vision is to better position Paramount on the front end (DTC apps) and the back end (cloud infrastructure, cloud-based production, and AI tools). Specifically, they are going to 1) rebuild DTC into a differentiated platform, 2) build studio-in-the-cloud, 3) leverage Gen AI.</p>
<blockquote>
<p><strong>Fintech Shake-Up - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/fintech-shake-up">Link</a>]</p>
</blockquote>
<p>Apple Pay unveiled a new peer-to-peer (P2P) feature called “Tap to Cash”, which is a natural evolution of the existing “Tap to Pay”.   This is not the only case where big tech offers features that directly compete with financial institutions: Google Wallet, Amazon’s lending program for sellers, etc, competing with PayPal’s Venmo, Block’s Cash App, etc. Big tech’s move not only intensifies competition within P2P payment, but also raises questions about the future of the payment industry.</p>
<p>Highlights:</p>
<ol>
<li>Visa and Mastercard both face mobile wallet threats to card-based business model.</li>
<li>American Express renowned for its premium card offerings, targeting high spending high credit quality customers, continuing to attract millennials and Gen Z customers. The recent strategic acquisitions are Tock (a reservation platform for high end restaurant and events) and Rooam (a mobile payment and ordering platform for restaurants and venues). However, it’s sensitive to economic downturns and facing competitions for other premium card issuers and digital payment platforms. </li>
<li>Fiserv’s merchant solutions and financial solutions look positive, it’s actively investing in digital transformation, and it recently acquired BentoBox (a digital marketing and commerce platform for restaurants).</li>
<li>Adyen serves large enterprise clients with its unified commerce platform</li>
<li>PayPal lowered its FY 2024 guidance. It’s facing a decline in active accounts. To solve this, it focuses on strategic partnerships such as collaboration with Apple. It’s facing competitive pressure from Big Tech payment solutions like Apple Pay and Google Pay. It’s currently undergoing significant restructuring such as layoffs and leadership change. And it’s initiating AI-powered personalized ads platform and strengthening relationships with SME customers.</li>
<li>Block’s growth is driven by its momentum of Cash App ecosystem, square ecosystem, and significant investment in Bitcoin. However, it’s facing challenges of regulatory scrutiny on cryptocurrency activities and compliance practices, competition from established competitors and fintech startups, needs of balancing growth and profitability given FY 2024 guidance.</li>
</ol>
<p>What to watch for the shift in payment landscape:</p>
<ul>
<li>Facing legal battle from Big Tech, can Visa and Mastercard find innovation or new solutions to maintain their revenue streams from swipe fee?</li>
<li>Will Digital Wallet dominant payment industry? Will traditional cards remain or be replace?</li>
<li>New possibilities of payments have been developed such as Buy Now and Pay Later (BNPL). Will innovations gain mainstream adoption in payment industry?</li>
<li>Can the challenges of cryptocurrencies be overcome? Will cryptocurrencies be mainstream adoption?</li>
<li>As consumers are demanding seamless, secure, cheaper, and personalized payment experiences, companies that can provide such services will become successful in the future.</li>
</ul>
<blockquote>
<p><strong>Nike: Losing Its Swoosh? - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/nike-losing-its-swoosh">Link</a>]</p>
</blockquote>
<p>Nike’s facing challenges of 1) shifting consumer preferences to newer brands (On and Hoka), 2) softer traffic and lower sales of classic footwear franchises in direct-to-consumer channel, 3) macroeconomic headwinds.</p>
<p>Nike Q4 2024 Highlights: 1) Nike is reducing supply of classic footwear franchises to create space for newness and innovation, 2) focusing on performance and innovation, 3) Jordan Brand is still growing YoY.</p>
<p>Other observation: Nike brand value declined by 4% YoY, while Adidas and Lululemon gain brand values.</p>
<blockquote>
<p><strong>Broadcom: AI Surge - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/broadcom-ai-surge">Link</a>]</p>
</blockquote>
<p>Broadcom now operates across two primary segments: 1) semiconductor solutions (chips for networking, server storage, broadband, wireless communication, and industrial applications), and 2) infrastructure software (a explosive leap with the acquisition of VMware). </p>
<p>Highlights: VMware acquisition brings significant revenue to Broadcom; AI as a great growth driver; jumbo acquisition resulted in gigantic net debt; strong cash generation; 10-for-1 stock split on July 15. </p>
<p>Future: Next-generation products include Tomahawk and Jericho; supply chain disruption and inflation resulted from macroeconomic environment; regulatory scrutiny into VMware acquisition.</p>
<blockquote>
<p><strong>Starbucks: A Brewing Crisis - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/starbucks-a-brewing-crisis">Link</a>] [<a target="_blank" rel="noopener" href="https://www.linkedin.com/feed/update/urn:li:activity:7193044402255110144/">LinkedIn</a>]</p>
</blockquote>
<p>Three main issues: </p>
<ol>
<li>the boycott impact: losing 1.5M loyal customers, as a result of the fact that in October 2023, Starbucks became embroiled in a controversy related to the ongoing violence in the Middle East, </li>
<li>significant loss in traffic from non-Rewards members due to additional reasons such as awareness of daily drink price, gourmet coffee boom, health-conscious consumers, changing work habits, and competitors with coffee offerings in lower prices. Solutions on this are new initiatives such as physical and digital enhancements like updated POS system, siren system speedup, and opening mobile orders beyond its loyalty programs.</li>
<li>Price war in Chinese coffee market e.g. Luckin Coffee.</li>
</ol>
<blockquote>
<p><strong>7 Mindsets That Are Slowing Down Your Career Growth - The Caring Techie Newsletter</strong> [<a target="_blank" rel="noopener" href="https://www.thecaringtechie.com/p/7-mindsets-that-are-slowing-down">Link</a>]</p>
</blockquote>
<ol>
<li>Solo Contributor Mindset -&gt; Prioritize get thing done with others</li>
<li>That’s not my job -&gt; willing to do things outside of my scope</li>
<li>My work will speak for itself -&gt; do the work and say that I did the work</li>
<li>If I do what I’m told, I will get promoted -&gt; I need to sit in the driver’s seat of my career growth</li>
<li>If I’m not getting any feedback, it means I’m doing good -&gt; I need to actively seek feedback</li>
<li>I’m not ready for the next level -&gt; I might be ready for a promotion despite my doubts</li>
<li>Picking the devil you know -&gt; next promotion might come from joining another company</li>
</ol>
<blockquote>
<p><strong>Mark Zuckerberg and Peter Thiel - Internal Tech Emails</strong> [<a target="_blank" rel="noopener" href="https://www.techemails.com/p/mark-zuckerberg-peter-thiel-millennials">Link</a>]</p>
</blockquote>
<p>Peter Thiel and Mark Zuckerberg on Facebook, Millennials, and predictions for 2030.</p>
<blockquote>
<p><em>Google owes its stable position as much to Generative AI’s slow progress as its own innovations. While OpenAI, Anthropic, Meta, and others have built more powerful AI models into their chatbots, people haven’t substituted those bots for traditional search. As of February, Bing still had less than 4% of search market share worldwide compared to Google’s 91%. ChatGPT, for context, debuted nearly two years ago.</em> </p>
<p><em>This week, when OpenAI introduced its own search engine, called SearchGPT, it didn’t exactly strike fear in the halls of Mountain View.</em></p>
<p><strong>― Surprisingly, Google Is Thriving In The GenAI Era - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/surprisingly-google-is-thriving-in">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Netflix: Ad Tech Focus - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/netflix-ad-tech-focus">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Tesla: Robotaxi Delay - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/tesla-robotaxi-delay">Link</a>]</p>
</blockquote>
<p>Analysis:</p>
<ul>
<li>Tesla’s revenue comes from three main sources 1) automative (78% revenue), 2) services and other (12% revenue), 3) energy generation and storage (10% revenue). </li>
<li>Production and Deliveries are the two main metrics.</li>
<li>Tesla’s margins have historically been ahead of other car manufacturers thanks to three critical leverages: 1) Economies of scale (though gigafactories), 2) Direct-to-consumer (online and via its showrooms), 3) Low marketing costs (Tesla barely spends on advertising).</li>
</ul>
<p>Highlights:</p>
<ul>
<li>Tesla missed earnings expectations for the fourth consecutive quarter.</li>
<li>Elon Musk pushed the Robotaxi announcement from August 8 to October 10.</li>
<li>Profits fell for the second straight quarter, driven by slower demand, competition, and price cuts. Price cut remain a double-edged sword.</li>
<li>Operating margin declined by 3% YoY and was at its lowest in years. Negative impacts are from 1) price cuts, 2) delivery decline, 3) AI projects, 4) restructuring costs. Positive impacts are from 1) lower cost per vehicle, production ramp of 4680 cells, higher regulatory credits, and non-auto segments.</li>
<li>Energy generation and storage doubled.</li>
</ul>
<p>Future:</p>
<ul>
<li>Humanoid Robots (Optimus): Tesla will begin producing humanoid robots for internal use next year and plans to sell to other companies in 2026.</li>
<li>Market Share and BYD: Tesla outsold BYD in Q2 2024, but the gap between the two companies was only 18K deliveries. Tesla had a 50% market share in BEV sales in the US, with 164K deliveries in Q2. As expected, the market share of BEVs has consistently declined, reflecting the continued adoption of all-electric cars.</li>
</ul>
<blockquote>
<p><em>More than 1.5 million developers are now using Gemini across our developer tools.</em></p>
<p><em>Waymo’s served more than 2 million trips to-date and driven more than 20 million fully autonomous miles on public roads. Waymo’s now delivering well over 50,000 weekly paid public rides, primarily in San Francisco and Phoenix</em>.</p>
<p><em>Our AI-driven profit optimization tools have been expanded to performance max and standard shopping campaigns. Advertisers use profit optimization and smart bidding see a 15% uplift in profit on average compared to revenue-only bidding.</em></p>
<p><em>Soon we’ll actually start testing Search and Shopping ads in AI overviews for users in the US, and they will have the opportunity to actually appear within the overview in a section clearly labeled as sponsored.</em></p>
<p><strong>― Google: AI Spending Spree - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/google-ai-spending-spree">Link</a>]</p>
</blockquote>
<p>Highlights of Q2 FY24: 1) Revenue growth slowed down, 2) search advertising showed no slowdown, 3) YouTube Ads growth slower than Q1, 4) subscriptions decelerated from Q1 due to YouTubeTV increased its price in Q2 FY23, 5) cloud accelerated, 6) margin improved YoY but are about to compress due to AI investments etc, 7) Capex were up and expected to continue being up, 8) Alphabet committed $5 B to the ongoing operations of Waymo, 9) The company returned $18.2 B to shareholders, including $15.7 B in buybacks, showing their confidence in stock value.</p>
<p>Highlights of Cookies, Cloud, and YouTube: 1) planned to phase out third-party cookies from Chrome to address privacy concerns regarding tracking but reversed its decide to let users choose their tracking preferences, 2) AI boost continues to accelerate cloud revenue growth especially in GCP and Workspace, 3) YouTube gains market share, 9.9% in Jun, up from 9.2% in prior year.</p>
<p>Future: 1) Project Astra, 2) SearchGPT competition: Search is critical for Alphabet because it contributes 57% revenue. SearchGPT could shake up the market but challenges are ensuring accuracy and avoiding hallucination. OpenAI doesn’t have either user engagement or ad performance which are required by a successful search business.  </p>
<blockquote>
<p><em>American Express had that network because of its legacy traveler’s check business so it was able to leverage that network to create and establish its credit card business. Without such a network, it’s impossible to operate a closed loop system.</em></p>
<p><strong>― I Am Buying American: American Express - Capitalist Letters</strong> [<a target="_blank" rel="noopener" href="https://www.capitalist-letters.com/p/i-am-buying-american-american-express">Link</a>]</p>
</blockquote>
<p>Why American Express is superior than Visa and Mastercard? It’s business model.</p>
<p>Visa is a typical payment processor. It connects the merchant to the issuer bank. It’s an open loop. American Express, on the other hand, is a closed loop system which makes it a money printing machine. It uses two strategies: 1) set stricter standards to issue cards, 2) provides travel privileges to attract frequent travelers who have higher net worth. </p>
<p>Why good investment: 1) Giant moat due to closed loop system, 2) inflation proof: customer base are those with stronger purchasing power, 3) it’s expanding internationally and among younger people: in 2023, 60% of new consumer accounts were Gen-Z and Millennial, international businesses billed for card services grew 14% YoY last quarter, accounting for 35% overall growth.</p>
<blockquote>
<p><strong>How Github grows and makes money - Productify by Bandan</strong> [<a target="_blank" rel="noopener" href="https://productify.substack.com/p/how-github-grows-and-makes-money">Link</a>]</p>
</blockquote>
<p>Github’s culture values: 1) ﻿﻿﻿Customer-obsessed, 2) ﻿﻿﻿Ship to learn 3) ﻿﻿﻿Growth mindset, 4) ﻿﻿﻿Own the outcome, 5) ﻿﻿﻿Better together, 6) ﻿﻿﻿Diverse and inclusive.</p>
<p>How does Github make money: 1) ﻿﻿﻿Al powered tools - Github CoPilot, 2) ﻿﻿﻿Subscription Plans, 3) ﻿﻿﻿Enterprise solutions, 4) ﻿﻿﻿Marketplace and additional services - Github Marketplace, Github Actions, Github Packages.</p>
<p>Revenue Breakdown: Major contributors are Github CoPilot and Enterprise solutions, Steady contributors are subscription plans, growing segments are marketplace and additional services.</p>
<p>Github’s product and engineering culture: 1) ﻿﻿﻿Open source, 2) ﻿﻿﻿Remote first prioneers - pull requests, 3) ﻿﻿﻿Octocat obsession, 4) ﻿﻿﻿Continuous learning and growth, 5) ﻿﻿﻿Al integration - Github Copilot, 6) ﻿﻿﻿Hackathons and innovation time, 7) ﻿﻿﻿Inclusive design.</p>
<p>Key Takeaways from Github’s growth strategy: 1) Unwavering developer-centric focus and positioning, 2) Building relevant products for its user problems, 3) strong cultural values and community engagement</p>
<blockquote>
<p><strong>No Rules Rules - The secret sauce of Netflix - Tech Books</strong> [<a target="_blank" rel="noopener" href="https://techbooks.substack.com/p/no-rules-rules">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to win at Enterprise AI - A playbook - Platforms, AI, and the Economics of BigTech</strong> [<a target="_blank" rel="noopener" href="https://platforms.substack.com/p/how-to-win-at-enterprise-ai-a-playbook">Link</a>]</p>
</blockquote>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><strong>Hot Swap growing, donors revolt, President Kamala? SCOTUS breakdown: Immunity, Chevron, Censorship - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=kOeARghNIaY&t=1893s&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Luxury Strategy | Why LVMH &amp; Hermès have Outperformed the Market w&#x2F; Christian Billinger (TIP643)</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rbmDgRRwkJ4&ab_channel=WeStudyBillionaires">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Simple Diffusion Language Models (15min video)</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=WjAUX23vgfg">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>You cannot spend this kind of money and show no incremental revenue potential. So while this is incredible for NVIDIA, the chicken is coming home to roast, because if you do not start seeing revenue flow to the bottom line of these companies that are spending 26 B dollars a quarter, the market cap of NVIDIA is not what the market cap of NVIDIA should be, and all of these other companies are going toe get punished for spending this kind of money. Where are all these new fangled things that we are supposed to see that justifies a hundred billion dollar of chip spend a year, two hundreds billion dollars of energy spend, a hundred billion dollars of all this other stuff, we are now spending 750 billion dollars. This is on the order of a national transfer payment, and we’ve seen nothing to show for it except that you can mimic somebody’s voice. It doesn’t all hang together yet. - Chamath Palihapitiya</em></p>
<p><em>There’s gaps in the quality of the products that can be created to not have hallucination. Those gaps are too large right now for them to be used reliably in production settings unless you have a very defined scope. If you have a defined scope though, the implementation costs are not nearly what needs the level of spend to support. So there is just a big mismatch. Second is that we have a huge problem with NVIDIA, which is you can’t spend this kind of money to have tech lock-in to one hardware vendor, and that makes no sense. And what you are seeing now is that Amazon Google Microsoft AMD Intel, a plethora of startups Grok, everybody trying to make now different hardware solution. The problem though is that we have this massive lock-in right now, because the code is littered with all these NVIDIA specific ways of implementing access to GPUs, that’s not sustainable. So we are in an existential thrash and I think the only way that we are going to get around this is to do a little bit of a reset. And I think that’s going to touch a lot of startups that have already taken down way too much money at really insane valuations. I think we are in a bit of a reckoning right now it’s going to be complicated couple of quarters to at a minimum and probably a complicated year to sort out who’s actually real. - Chamath Palihapitiya</em></p>
<p><em>There is ton of capital that was raised during the covid bubble era, and the ZIRP (Zero Interest Rate Policy) era, that needed a place to go. And a lot of traditional business model, traditional in the technology sense - SAS and a lot of biotech stuff, it became uninvestable. Then there is a lot of money in the public markets that was sitting on the sidelines, that was sitting in treasuries and so on. So every dollar is looking for growth and there is a lot of dollars still sitting around out there from the ZIRP era and the coming into this kind of post ZIRP era, looking for a place to growth. And there is very little growth as we talked about with the S&amp;P 479 not being very performative with respect to growth and revenue and having great outlook for the next five years. So then when there is a glimmer of upside there is a glimmer of opportunity, even if it’s just painting a picture of a growth story, all the capital drives into it. And we’ve all heard stories about these series a startups in AI, getting bit up to a 100M valuation. I’ve seen a couple of these where people have pitch me things on like protein modeling AI startups, and it’s literally like two guys from meta and openai that left and started this company, and they raised 30 on a 12 per year or something, and it’s just two guys building a model. That’s because that capital needs to find a place where it can tell itself a growth story. So I think we are still dealing with the capital hangover from ZIRP. And the fact there is an area to invest for real growth that has allowed the AI bubble to grow as quickly as it has. - David Friedberg</em></p>
<p><em>Now as Chamath points out we are kind of rationalizing that back and I do think that there is going to be a reset. Now I’ll also say that the Goldman report which I read and some of the other analyses that have been done. I think there was some commentary or some analysis that hey it costs me six times as much as having an analyst do this work. The energy cost of the AI is still so high, the actual performance of the model is not good. What that fails to write it’s right and wrong. It’s right in the sense that yes it’ s more expensive today and ROI is not there today. It’s wrong in that it ignores the performative model improvements that we’re seeing in nearly any metric over the past couple of months. Every few months as we know we see new models, new improvements, new architectures, new ways to leveraging the chips to actually drive a lover token cost, to drive lower energy cost per answer, lower energy cost per run. Every metric that matters is improving, so if you fast forward another 24 or 36 months, I do think that there is a great reason to be optimistic that there is going to be extraordinary ROI based on the infrastructure that’s being built. It’s a question of are you going to get payback before the next cycle of infrastructure needs to be made and everything comes back in. We saw this during the dotcom boom where a lot of people built out data centers and by the time they were able to actually able to make money on those data centers, it was like hey all the new Telco equipment, all the new servers needs to be put in, and everything got written off. So there is a big capex kind of question mark here, but I do think that the fundamental economics of AI will be proven over the next couple of quarters. - David Friedberg</em></p>
<p><em>I’m much more bullish than you guys about this investment that’s being made. Remember that when the internet got started in the 90s, it was via dialup. I mean you literally had to have a modem and you would dial up the internet and it was incredibly slow. Photo sharing didn’t even work, so social networking wasn’t possible. And basically what happened next was that the Telecom company spent a ton of money building out broadband and people started upgrading to broadband. Then we had the Doom crash everyone thought that telecom companies had wasted billions of dollars investing in all this Broadband infrastructure. And it turned out that no they were right to do that, it just took a while for that to get used and this is a pretty common pattern with technological revolutions is that you can have a bubble in the short term but then it gets justified in the mid to long term. The build out of the railroads in the United States another example of this we had huge railroad bubbles but it turned out that that investment was all worthwhile. - David Sacks</em></p>
<p><strong>― Biden chaos, Soft landing secured? AI sentiment turns bearish, French elections - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=w30WLkNU47g&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Project 2025: The Radical Conservative Plan to Reshape America Under Trump | WSJ</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=y16SZhZJHkI&ab_channel=TheWallStreetJournal">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Trump assassination attempt, Secret Service failure, Inside the RNC, VC liquidity problem - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=3z73JXD3pYU&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Trump’s VP pick JD Vance SPEAKS at 2024 RNC (FULL SPEECH) - NBC Chicago</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1if1ufZY6nI&ab_channel=NBCChicago">Link</a>] </p>
</blockquote>
<blockquote>
<p><em>You have to put one foot in front of the other every day, and you have to focus on tangible progress. And where that fails is when most people and I do it a lot and I’ve tried to get better as I’ve gotten older, is when I get comparative and I compare myself to the other person, the other company, the other funding round, there’s so many reasons for you to feel like you’re less than something else. And the reality is that has nothing to do with you, you’re not in control of that, but it’s so hard. And then if I don’t take that medicine, I become insecure, and then I make mistakes that are entirely avoidable. So it’s just tangible progress the things that I can control. That’s probably the most useful piece of advice that I try to remind myself of every day. - Chamath Palihapitiya</em></p>
<p><strong>― The Besties Take Napa | All-In Special  - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xk4G-ImoSvw&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>Sharing good insights about AI, David’s amazing story with Poker, some great career advice. And happy birthday to David Friedberg!</p>
<blockquote>
<p><em>We talked a little bit about it with Jonathan height. There’s some great studies that have shown in the past that the change in income is a better predictor of happiness than absolute income. Eventually everything normalizes so I think UBI makes no sense for three reasons. The first is this normalization of spending level. So once you’ve kind of had this increase, you have a moment of happiness, and then you actually start spending differently or spending more. And effectively every human has one innate trait desire. And desire is what drives humanity. It’s what drives progress. It’s what pushes us forward because no matter what our absolute condition, it’s our relative condition that matters relative to others or relative to ourselves in the past or perspectively in the future. And so we always want to improve our condition. So a UBI based system basically gives a flat income so the only way for it to really work is if you increase the income automatically by say 10% a year. So in a UBI world, no amount of money will actually make someone satisfied or meet their minimum thresholds because those minimum thresholds will simply shift. And you know the second issue is just the net economic effect if we gave 350 million Americans 1000 bucks a month, that’s $350 billion a month, that’s $4 trillion a year. Our prospective budget for next year is 7.3 trillion at the federal level, so you know that’s already more than 50% of the total projected federal budget next year finding the mechanism for funding this at scale is not what this study actually looked at. Because if you look at it the net effect would be inflationary. And that’s the third major reason is that ultimately this would have an inflationary effect anytime. We’ve stimulated the economy with outside money. With government-driven money, we see many bubbles emerge and we see an inflationary effect. So look at covid, there were all these little bubbles that popped up in the financial markets, we had NFTs, we had crypto, we had all these sort of new places that money found its way to and then we had an aggregate inflationary effect food prices are still up 30 40% since covid. And so I think that the study provides an interesting insight into the micro effect the psychological effects, the social effect, but macro effects are what is so like simply arithmetically obvious, which is inflation and an inability to actually fund us at scale. And fundamentally people want to work so they’ll take that money, and then they’ll go find ways to work and generate more money, and you have this inflationary effect so I think UBI does not make sense. - David Friedberg</em></p>
<p><em>That’s not UBI right and what you’re describing I think exist and there are incentives and programs and opportunities out there people can sign up with Roth IRAs they can contribute some percentage of their paycheck to a 401k. If they have a job that has a 401k setup for them there’s a lot of systems and mechanisms out there and you get tax breaks for doing that. So there’s mechanisms and incentives out there to do that sort of thing the concept with UBI is can you pay people a flat amount of money so that they don’t have to work, and then they end up being able to explore and do other things with their life as the robots and AI does everything for them. And I’ve just always been of the belief that I don’t think that there’s this natural border that we hit beyond which humans don’t work. I think that AI based tools and automation tools are the same as they’ve always been. When we developed a tractor people didn’t stop farming. They could get much more leverage using the tractor and farm more. And new jobs and new Industries emerged. And I expect that the same thing will happen with this next evolution of technology and human progress. Humans will find ways to create new things to push themselves forward to drive things forward. And for the natural market-based incentives that fundamentally are rooted in this internal system of Desire will create new opportunities that we’re not really thinking about so I don’t believe in this idea of UBI in some utopian world where everyone’s happy not working and letting machines do everything for them I think that the fundamental sense of a human is to find purpose, and to realize that purpose to drive themselves forward and progress themselves. And I think that that’s always going to be the case. - David Friedberg</em></p>
<p><strong>― Mag 7 sell-off, Wiz rejects Google, UBI, Kamala in, China’s nuclear buildout, Sacks responds to PG - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UQBPUAgVuJA&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Microsoft Volume II - Acquired Podcast</strong>  [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/2VlQlPDJQSheDFDqgOv8N0">Link</a>]</p>
</blockquote>
<h3 id="Blogs-and-Articles"><a href="#Blogs-and-Articles" class="headerlink" title="Blogs and Articles"></a>Blogs and Articles</h3><blockquote>
<p><strong>A year later, what Threads could learn from other social networks - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/04/a-year-later-what-threads-could-learn-from-other-social-networks/">Link</a>] </p>
</blockquote>
<p>Though Threads has reached 175 million monthly active users in its first year and has made some progress such as integrating fediverse, there are a lot of things need to be improved by learning from other social medias. </p>
<ol>
<li><p>Custom Feeds: Learning from Bluesky: Threads should implement advanced custom feed features to allow users to easily follow specific topics and events without relying solely on tags.</p>
</li>
<li><p>Third-Party Apps: Learning from Mastodon and Bluesky: Meta should consider opening up Threads to third-party developers to create diverse client applications, allowing for a broader range of user experiences and features.</p>
</li>
<li><p>Algorithm Improvement: Improving “For You” Feed: Threads needs to refine its algorithm to ensure that users receive more relevant and personalized content, avoiding random or irrelevant posts that can detract from user experience.</p>
</li>
<li><p>Handling News and Political Content: Learning from X and Mastodon: Threads should develop mechanisms to handle news and political content more effectively, balancing visibility without suppressing important information, and potentially integrating features like context-providing notes or bylines.</p>
</li>
<li><p>Local Content Engagement: Learning from Instagram and Twitter: Threads should enhance its focus on local content by developing partnerships and features that cater to regional interests and events, like live scores for popular sports in specific regions.</p>
</li>
<li><p>Separation from Instagram: Developing Independent Profiles: Threads should work on allowing users to create and manage profiles independent of Instagram accounts, offering more flexibility and autonomy in account management.</p>
</li>
</ol>
<blockquote>
<p><em>If “product-market-fit” means that you’ve found the right kind of product that the market wants…  “Position-market-fit” means that you’ve found the right combination of product&#x2F;brand&#x2F;marketing&#x2F;pricing&#x2F;go-to-market&#x2F;sales&#x2F;etc in a given domain.</em></p>
<p><strong>― Product-market fit is not enough anymore. You need position-market fit - Aakash Gupta on X</strong> [<a target="_blank" rel="noopener" href="https://threadreaderapp.com/thread/1808850674118959457.html">Link</a>]</p>
</blockquote>
<p>Product-market fit is about having the right product for the market, while position-market fit is about effectively positioning that product within the market to stand out and meet specific customer expectations.</p>
<blockquote>
<p><strong>A discussion of discussions on AI bias - Dan Luu</strong> [<a target="_blank" rel="noopener" href="https://danluu.com/ai-bias/#:~:text=Rather%2C%20%22AI%20bias%22%20is,due%20to%20the%20circumstances%20of">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to build a valuable tech company - Jason Shen on X</strong> [<a target="_blank" rel="noopener" href="https://threadreaderapp.com/thread/1806357605343691053.html?utm_source=tldrproduct">Link</a>]</p>
</blockquote>
<p>Jensen’s Mindmap about his secrets to building the mos tvaluable tech company in the world</p>
<p><img src="/digital-di/./images/jensen-mindmap.jpeg" alt="jensen-mindmap"></p>
<blockquote>
<p><em>As a general rule, don’t let your company start doing the next thing until you’ve dominated the first thing. No great company I know of started doing multiple things at once—they start with a lot of conviction about one thing, and see it all the way through. You can do far fewer things than you think. A very, very common cause of startup death is doing too many of the wrong things. Prioritization is critical and hard.</em></p>
<p><em>While great founders don’t do many big projects, they do whatever they do very intensely. They get things done very quickly. They are decisive, which is hard when you’re running a startup—you will get a lot of conflicting advice, both because there are multiple ways to do things and because there’s a lot of bad advice out there. Great founders listen to all of the advice and then quickly make their own decisions.</em></p>
<p><em>Please note that this doesn’t mean doing everything intensely—that’s impossible. You have to pick the right things. As Paul Buchheit says, find ways to get 90% of the value with 10% of the effort. The market doesn’t care how hard you work—it only cares if you do the right things.</em> </p>
<p><em>Fire quickly. Everyone knows this in principle and no one does it. But I feel I should say it anyway. Also, fire people who are toxic to the culture no matter how good they are at what they do. Culture is defined by who you hire, fire, and promote.</em></p>
<p><strong>― Startup Playbook by Sam Altman - Sam Altman</strong> [<a target="_blank" rel="noopener" href="https://playbook.samaltman.com/">Link</a>]</p>
</blockquote>
<p>A brief summary of Sam’s long article by <a target="_blank" rel="noopener" href="https://twitter.com/nurijanian/status/1807462862509723901">George from prodmgmt.world</a> on X.</p>
<p><img src="/digital-di/./images/startup-playbook-by-sam.jpeg" alt="startup-playbook"></p>
<blockquote>
<p><strong>Databricks vs. Snowflake: What their rivalry reveals about AI’s future - Foundation Capital</strong> [<a target="_blank" rel="noopener" href="https://foundationcapital.com/databricks-vs-snowflake-what-their-rivalry-reveals-about-ais-future/">Link</a>] </p>
</blockquote>
<blockquote>
<p><strong>How to Interview and Hire ML&#x2F; AI Engineers - eugeneyan</strong> [<a target="_blank" rel="noopener" href="https://eugeneyan.com/writing/how-to-interview/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Meta CTO Andrew Bosworth on the Metaverse, VR&#x2F;AR, AI, Billion-Dollar Expenditures, and Investment Timelines - MatthewBall.co</strong> [<a target="_blank" rel="noopener" href="https://www.matthewball.co/all/bozinterview2024">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Spotify is no longer just a streaming app, it’s a social network - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/10/spotify-is-no-longer-just-a-streaming-app-its-a-social-network/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Gen AI: too much spend, too little benefit? - Goldman Sachs</strong> [<a target="_blank" rel="noopener" href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Crypto x Al report</strong> [<a target="_blank" rel="noopener" href="https://x.com/dunleavy89/status/1811072580817695058">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI’s shift to efficiency</strong> [<a target="_blank" rel="noopener" href="https://www.canaan.com/latest/ai-s-shift-to-efficiency">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>What is AI? - Everyone thinks they know but no one can agree. And that’s a problem - MIT Technology Review</strong> [<a target="_blank" rel="noopener" href="https://www.technologyreview.com/2024/07/10/1094475/what-is-artificial-intelligence-ai-definitive-guide">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Folly of Certainty - Howard Marks</strong> [<a target="_blank" rel="noopener" href="https://www.oaktreecapital.com/insights/memo/the-folly-of-certainty">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>On July 19, 2024 at 04:09 UTC, as part of ongoing operations, CrowdStrike released a sensor configuration update to Windows systems. Sensor configuration updates are an ongoing part of the protection mechanisms of the Falcon platform. This configuration update triggered a logic error resulting in a system crash and blue screen (BSOD) on impacted systems. The sensor configuration update that caused the system crash was remediated on Friday, July 19, 2024 05:27 UTC. This issue is not the result of or related to a cyberattack.</em></p>
<p><strong>― Technical Details: Falcon Content Update for Windows Hosts</strong> [<a target="_blank" rel="noopener" href="https://www.crowdstrike.com/blog/falcon-update-for-windows-hosts-technical-details/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>In any massive failure there are a host of smaller errors that compound; in this case, CrowdStrike created a faulty file, failed to test it properly, and deployed it to its entire customer base in one shot, instead of rolling it out in batches. Doing something different at each one of these steps would have prevented the widespread failures that are still roiling the world</em></p>
<p><em>The real issue, though, is more fundamental: erroneous configuration files in userspace crash a program, but they don’t crash the computer; CrowdStrike, though, doesn’t run in userspace: it runs in kernel space, which means its bugs crash the entire computer — 8 million of them, <a target="_blank" rel="noopener" href="https://blogs.microsoft.com/blog/2024/07/20/helping-our-customers-through-the-crowdstrike-outage/">according to Microsoft</a>. Apple and Linux were not impacted, for a very obvious reason: both have long since locked out 3rd-party software from kernel space.</em></p>
<p><strong>― Crashes and Competition - Ben Thompson on Stratechery</strong> [<a target="_blank" rel="noopener" href="https://stratechery.com/2024/crashes-and-competition/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Munger Series - Learning from Benjamin Franklin - Investment Master Class</strong>  [<a target="_blank" rel="noopener" href="https://mastersinvest.com/newblog/2024/5/9/the-munger-series-learning-from-benjamin-franklin">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Benjamin Graham Survived World Panic on Wall Street (#17) - Beyond Ben Graham</strong> [<a target="_blank" rel="noopener" href="https://beyondbengraham.com/how-benjamin-graham-survived-world-panic-on-wall-street-17/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing Llama 3.1: Our most capable models to date - Meta AI Blog</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/meta-llama-3-1/">Link</a>]</p>
</blockquote>
<p>Meta is releasing Llama 3.1 405B, the first frontier-level open-source AI model. Along with Llama 3.1 70B and 8B models, they offer superior cost &#x2F; performance and are open for Fien-tuning and distilling. And they are collaborating with companies such as Amazon, Databricks, NVIDIA, Grow, etc, to support developers in fine-tuning and distilling models.</p>
<blockquote>
<p><strong>Open Source AI Is the Path Forward - Meta News</strong> [<a target="_blank" rel="noopener" href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/">Link</a>]</p>
</blockquote>
<p>In this letter, Zuckerberg emphasizes Meta’s commitment to open source AI. Similar to Unix and Linux, Zuckerberg believes AI development will eventually go to open source. Open source AI has several benefits: 1) it benefits developers in customization, control and security, cost efficiency, and long-term standards, 2) it benefits Meta in avoiding being locked into competitor’s ecosystems, allowing for freedom in innovation and product development, enhancing its competitiveness, and building a community of partnerships and developers, 3) it benefits the world in providing wide spread access to AI benefits, ensuring safety and security, and avoiding monopoly in AI power.</p>
<blockquote>
<p><strong>GPT-4o mini: advancing cost-efficient intelligence - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">Link</a>]</p>
</blockquote>
<h3 id="Paper-and-Reports"><a href="#Paper-and-Reports" class="headerlink" title="Paper and Reports"></a>Paper and Reports</h3><blockquote>
<p><strong>Meta 3D Gen - Meta AI</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/meta-3d-gen/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI Agents That Matter</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01502">Link</a>]</p>
</blockquote>
<p>This study suggests the importance of optimizing both cost and accuracy in benchmarking and evaluation of AI agents. Since the issues of inadequate hold-out sets, absence of standardized evaluation practices, etc, the authors also suggests a principled framework that emphasizes the development of agents effective especially in practical scenarios rather than on benchmarks.</p>
<blockquote>
<p><strong>Scaling Synthetic Data Creation with 1,000,000,000 Personas</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.20094">Link</a>]</p>
</blockquote>
<p>This team generated 1B personas based on web info and stored them into a Persona Hub. They introduced a synthetic data generation method called ‘persona-driven data synthesis’. These personas can be potentially used to 1) generate personalized content, 2) support LLM prompting, 3) enhance product research, 4) create NPCs in games. The compression perspective is more interesting and helpful for understanding the approach: Persona Hub can be seen as the compressed form of the world knowledge into distributed carriers. And the public web text can be seen as the decompressed content created by these personas with their knowledge and experiences.</p>
<blockquote>
<p><strong>TextGrad: AutoGrad for Text</strong> [<a target="_blank" rel="noopener" href="https://hai.stanford.edu/news/textgrad-autograd-text">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>RouteLLM: An Open-Source Framework for Cost-Effective LLM Routing</strong> [<a target="_blank" rel="noopener" href="https://lmsys.org/blog/2024-07-01-routellm/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A Survey on Mixture of Experts</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.06204">Link</a>]</p>
</blockquote>
<p>This is a comprehensive survey on LLM MoE technique. MoE stands out for enabling model scaling with minimal additional computation. This survey as a systematic MoE literature review, covers MoE’s structure, taxonomy, core designs, open-source resources, applications, and future research directions.</p>
<blockquote>
<p><strong>An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers v2</strong> [<a target="_blank" rel="noopener" href="https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Magic Insert: Style-Aware Drag-and-Drop - Google</strong> [<a target="_blank" rel="noopener" href="https://magicinsert.github.io/">Link</a>] </p>
</blockquote>
<blockquote>
<p><strong>PaliGemma: A versatile 3B VLM for transfer</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/html/2407.07726v1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</strong> [<a target="_blank" rel="noopener" href="https://tridao.me/blog/2024/flash3/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.07775">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures</strong> [<a target="_blank" rel="noopener" href="https://www.arxiv.org/abs/2407.09468">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Accuracy is Not All You Need</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09141">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI achieves silver-medal standard solving International Mathematical Olympiad problems - Google Research</strong> [<a target="_blank" rel="noopener" href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">Link</a>]</p>
</blockquote>
<p>This is one of the most surprising breakthrough in this AI and LLM year. AlphaProof got a silver medal in IMO. It’s a neurosymbolic system -  a combination of Google’s Gemini LLM and DeepMind’s Alpha Zero, so it uses LLM to generate plausible solutions and uses self-play style to search for the right one. It opens a research direction of AI use cases, which has been discussed about by many AI frontier experts and companies, which is “scientific discovery”. Mastering math can be the first step of expanding frontier of our knowledge. OpenAI’s Strawberry project seems to have the same ambitions.</p>
<blockquote>
<p><strong>Gen AI: Too Much Spend, Too Little Benefit? - Goldman Sachs Research Newsletter</strong>  [<a target="_blank" rel="noopener" href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf">Link</a>]</p>
</blockquote>
<p>As money’s flooded into GenAI projects, people started to question whether or when the investment would net a return. Though the bubble may or may not be bursting, a healthy discussion like this is worth a read.</p>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Prices fell in June for the first time since the start of the pandemic - CNN</strong> [<a target="_blank" rel="noopener" href="https://amp.cnn.com/cnn/2024/07/11/economy/us-cpi-consumer-inflation-june">Link</a>]</p>
</blockquote>
<p>CPI dropped 0.1% from May. Odds of Fed cutting the rate are increasing. Effect of high inflation is expected to be long lasting.</p>
<blockquote>
<p><strong>Here’s how far the Dow has fallen behind the S&amp;P 500 so far in 2024 - Morningstar</strong> [<a target="_blank" rel="noopener" href="https://www.morningstar.com/news/marketwatch/20240709188/heres-how-far-the-dow-has-fallen-behind-the-sp-500-so-far-in-2024">Link</a>]</p>
<p><strong>Tech Giants Face Tough Task to Sustain Second Half Stock Rally - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-09/tech-giants-face-tough-task-to-sustain-second-half-stock-rally">Link</a>]</p>
</blockquote>
<p>Magnificent 7 stocks have accounted for majority of the S&amp;P 500 growth this year. If this projection of AI optimism fails to materialize, it could trigger a massive decline of the index.</p>
<blockquote>
<p><strong>Apple Poised to Get OpenAI Board Observer Role as Part of AI Pact - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-02/apple-to-get-openai-board-observer-role-as-part-of-ai-agreement">Link</a>]</p>
<p><strong>Microsoft, Apple Drop OpenAI Board Plans as Scrutiny Grows - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-10/microsoft-quits-openai-board-after-antitrust-scrutiny-grows">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>This is Big Tech’s playbook for swallowing the AI industry - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/7/1/24190060/amazon-adept-ai-acquisition-playbook-microsoft-inflection">Link</a>]</p>
<p><strong>Amazon Hires Top Executives From AI Startup Adept for AGI Team - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-06-28/amazon-hires-top-executives-from-ai-startup-adept-for-agi-team">Link</a>]</p>
</blockquote>
<p>Big Tech companies are finding new ways to integrate AI startups into their operations without triggering antitrust scrutiny -  ‘reverse acquihire’, an approach where actual acquisitions are masked by employment and licensing agreements. This is highlighted by Microsoft hiring inflection’s team and licensing of its AI tech, and Amazon hiring roughly 2&#x2F;3 of Adept’s personnel and securing a deal to license its AI tech.</p>
<blockquote>
<p><strong>What happened to the artificial-intelligence revolution? - The Economics</strong> [<a target="_blank" rel="noopener" href="https://www.economist.com/finance-and-economics/2024/07/02/what-happened-to-the-artificial-intelligence-revolution">Link</a>]</p>
</blockquote>
<p>Silicon Valley companies are investing heavily in AI while the revenue from AI products is still far from the projected figures.</p>
<blockquote>
<p><strong>Humanoid robots powered by AI turn heads at the World Artificial Intelligence Conference - AP News</strong> [<a target="_blank" rel="noopener" href="https://apnews.com/video/artificial-intelligence-electric-vehicles-shanghai-china-robotics-1dfcfd6e5c6142a48c3df1dd43616353">Link</a>]</p>
<p><strong>Record 300,000 visitors attend World AI Conference</strong> [<a target="_blank" rel="noopener" href="https://www.shine.cn/news/metro/2407064491/">Link</a>]</p>
</blockquote>
<p>The World AI Conference and High-level Meeting on Global AI Governance (WAIC) 2024 closed in Shanghai on Saturday, covering investment plans, cooperation projects, city-level organizations, and development plans for AI. Robotic tech such as humanoid models is capturing the attention of attendees.</p>
<blockquote>
<p><strong>Fame, Feud and Fortune: Inside Billionaire Alexandr Wang’s Relentless Rise in Silicon Valley - The Information</strong> [<a target="_blank" rel="noopener" href="https://www.theinformation.com/articles/fame-feud-and-fortune-inside-billionaire-alexandr-wangs-relentless-rise-in-silicon-valley">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Robinhood snaps up Pluto to add AI tools to its investing app - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/01/robinhood-snaps-up-pluto-to-add-ai-tools-to-its-investing-app">Link</a>]</p>
</blockquote>
<p>The AI tool Pluto will allow Robinhood to add tools for quicker identification of trends and investment opportunities, help guide users with their investment strategies, and offer real-time portfolio optimization.</p>
<blockquote>
<p><em>“The algorithm is looking at traditional economic indicators that you would normally look at. But then inside of our proprietary algorithm, we’re ingesting the behavioral data and transaction data of 240 million Americans, which nobody else has,” said David Steinberg, co-founder, chairman and CEO of Zeta Global.</em></p>
<p><em>The eight verticals the economic index uses include automotive activity, dining and entertainment, financial services such as credit line expansion, health care, retail sales, technology and travel.</em></p>
<p><strong>― A new index is using AI tools to measure U.S. economic growth in a broader way - CNBC</strong> [<a target="_blank" rel="noopener" href="https://www.cnbc.com/2024/07/01/a-new-index-is-using-ai-tools-to-measure-us-economic-growth-in-a-broader-way.html">Link</a>]</p>
</blockquote>
<p>The Zeta Economic Index uses Gen AI to analyze “trillions of behavioral signals” to score growth of US economy.</p>
<blockquote>
<p><strong>OpenAI Hires Zapier Revenue Chief to Lead Sales Strategy - The Information</strong> [<a target="_blank" rel="noopener" href="https://www.theinformation.com/briefings/openai-hires-zapier-revenue-chief-to-lead-sales-strategy?utm_source=www.matthewberman.com&utm_medium=referral&utm_campaign=amazon-s-100b-bet-openai-s-legal-woes-and-robots-deployed-in-retail">Link</a>]</p>
</blockquote>
<p>OpenAI has recently hired new CFO and CPO to enhance its focus on both consumer and enterprise products. It appointed Giancarlo Lionetti (former CRO at Zapier, worked at Atlassian, Confluent, and Dropbox) to lead its sales strategy in OpenAI’s sales team.</p>
<blockquote>
<p><strong>Tesla’s Share of U.S. Electric Car Market Falls Below 50% - The New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/07/09/business/tesla-electric-vehicles-market-share.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Tesla’s Upcoming Model Y, Project Juniper, Spotted with Front Bumper Camera; Coming in 2025</strong> [<a target="_blank" rel="noopener" href="https://www.notateslaapp.com/news/2119/teslas-upcoming-model-y-project-juniper-spotted-with-front-bumper-camera-coming-in-2025">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Persona’s founders are certain the world can use another humanoid robot - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/06/26/personas-founders-are-certain-the-world-can-use-another-humanoid-robot/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Thermonuclear Blasts and New Species: Inside Elon Musk’s Plan to Colonize Mars - The New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/07/11/technology/elon-musk-spacex-mars.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>OpenAl says there are 5 ‘levels’ for AI to reach human intelligence - it’s already almost at level 2</strong> [<a target="_blank" rel="noopener" href="https://qz.com/openai-five-level-system-human-intelligence-ai-1851588122">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>The reason we decided to do the 100k H100 and next major system internally was that our fundamental competitiveness depends on being faster than any other AI company. This is the only way to catch up. Oracle is a great company and there is another company that shows promise also involved in that OpenAI GB200 cluster, but, when our fate depends on being the fastest by far, we must have our own hands on the steering wheel, rather than be a backseat driver. - Elon Musk @ X</em></p>
<p><strong>― xAI Appears to Confirm Ended Talks With Oracle Over Expanded AI Chips Agreement - WSJ</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/xai-appears-to-confirm-ended-talks-with-oracle-over-expanded-ai-chips-agreement-e06ade8b">Link</a>] [<a target="_blank" rel="noopener" href="https://x.com/xDaily/status/1810723880937607564">X</a>]</p>
</blockquote>
<p>Elon’s business strategy - being completely vertical integrated, on many of his companies (Tesla, SpaceX, etc) are working very well over the years. </p>
<blockquote>
<p><strong>Venture capital firm A16z stashing GPUs, including Nvidia’s, to win AI deals: report - Seeking Alpha</strong> [<a target="_blank" rel="noopener" href="https://www.msn.com/en-us/money/savingandinvesting/venture-capital-firm-a16z-stashing-gpus-including-nvidia-s-to-win-ai-deals-report/ar-BB1pGCNR">Link</a>]</p>
</blockquote>
<p>A16z has purchased thousands of GPUs including Nvidia’s H100, in an effort to win deals for AI startups. They store those H100s and give them to companies they invest in. It’s hard for startups to get vast amounts of computing power. So this practice can make them more competitive in these VC deals.</p>
<blockquote>
<p><strong>OpenAI and Los Alamos National Laboratory announce bioscience research partnership - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together/">Link</a>]</p>
</blockquote>
<p>OpenAI and LANL are working together on evaluating how frontier models like GPT-4o can assist humans in physical lab setting through multimodal capabilities to support bioscience research.</p>
<blockquote>
<p><em>In response to the fourth question in the <a target="_blank" rel="noopener" href="https://www.nintendo.co.jp/ir/pdf/2024/qa2406.pdf">investor call transcript</a>, Furukawa said the following (obtained via machine translation and edited for clarity):</em></p>
<p><em>“In the game industry, AI-like technology has long been used to control enemy character movements, so I believe that game development and AI technology have always been closely related.</em></p>
<p><em>Generative AI, which has been a hot topic recently, can be more creative [in its use], but I also recognize that it has issues with intellectual property rights.</em></p>
<p><em>Our company has [had] the know-how to create optimal gaming experiences for our customers for decades.</em></p>
<p><em>While we are flexible in responding to technological developments, we would like to continue to deliver value that is unique to us and cannot be created simply by technology alone.”</em></p>
<p><strong>― Nintendo becomes the biggest company in the games industry - and maybe the world - to say ‘no, thank you’ to using generative AI - PC Gamer</strong> [<a target="_blank" rel="noopener" href="https://www.pcgamer.com/gaming-industry/nintendo-becomes-the-biggest-company-in-the-games-industryand-maybe-the-worldto-say-no-thank-you-to-using-generative-ai/">Link</a>]</p>
</blockquote>
<p>Most gaming companies would like to incorporate AI in some sense but Nintendo as the biggest company in the game industry said no thank you to Gen AI. This sounds counter to what other game companying are aiming for, but it’s also reasonable because Nintendo has built incredible IP and they just want to be classic and they want everything to be their own.</p>
<p>However, many people have imagined the future of video game would be powered by AI with contents dynamically created for players in real time. </p>
<blockquote>
<p><strong>Watch a robot navigate the Google DeepMind offices using Gemini - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/07/11/watch-a-robot-navigate-the-google-deepmind-offices-using-gemini">Link</a>]</p>
</blockquote>
<p>Google DeepMind Robotics developed a robot navigation system powered by Gemini 1.5 Pro. It responds to human language commands, navigates the office environment. It uses “Multimodal Instruction Navigation with demonstration Tours (MINT)” to familiarize itself with the office and hierarchical Vision-Language-Action (VLA) for understanding and reasoning. The ability of recalling environment is boosted by 1M token context length of Gemini 1.5 Pro</p>
<blockquote>
<p><strong>OpenAI Scale Ranks Progress Toward ‘Human-Level’ Problem Solving - Bloomberg</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-07-11/openai-sets-levels-to-track-progress-toward-superintelligent-ai">Link</a>]</p>
</blockquote>
<p>OpenAI tiers range from the kind of AI that can interact in conversational language with people (lvl 1) to AI that can do the work of an organization (lvl 5). The OpenAI executives believes that they are at stage one and reaching towards the second tier. The third tier on the way to AGI would be ‘Agents’ - AI systems which can spend several days taking actions on a user’s behalf. Tier 4 would be the kind of AI that can come up with innovations. And the tier 5 would be called ‘organization’.</p>
<blockquote>
<p><strong>Samsung’s Jam-Packed Galaxy Unpacked: Galaxy Ring, Z Fold 6 and All the New Products Announced</strong> [<a target="_blank" rel="noopener" href="https://www.cnet.com/tech/mobile/samsungs-jam-packed-galaxy-unpacked-galaxy-ring-z-fold-6-and-all-the-new-products-announced/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Among the 35 companies approved to test by the California DMV, seven are wholly or partly China-based. Five of them drove on California roads last year: <a target="_blank" rel="noopener" href="https://archive.ph/o/rMutc/https://fortune.com/company/weride/">WeRide</a>, Apollo, AutoX, Pony.ai, and DiDi Research America. Some Chinese companies are approved to test in Arizona and Texas as well.</em> </p>
<p><strong>― Chinese self-driving cars have quietly traveled 1.8 million miles on U.S. roads, collecting detailed data with cameras and lasers - Fortune</strong> [<a target="_blank" rel="noopener" href="https://fortune.com/2024/07/08/chinese-self-driving-cars-us-roads-data-collection-surveillance-national-security-concerns-investigation/">Link</a>]</p>
</blockquote>
<p>Since 2017, self-driving cars owned by Chinese companies have traverse 1.8M miles of California alone. They captured video of their surroundings and map the state’s roads to within 2 cm of precision. These information have been transferred to data centers and been used to train their self-driving systems.</p>
<blockquote>
<p><strong>Evaluate prompts in the developer console - Anthropic News</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/evaluate-prompts">Link</a>]</p>
</blockquote>
<p>Anthropic releases some new features every week. Now they allow users to generate, test, and evaluate prompts in the Anthropic Console.</p>
<blockquote>
<p><strong>Fine-tune Claude 3 Haiku in Amazon Bedrock - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/fine-tune-claude-3-haiku">Link</a>]</p>
</blockquote>
<p>Customers can now fine-tune Claude 3 Haiku in Amazon Bedrock to customize model for vertical business usage.</p>
<blockquote>
<p><strong>Shooting at Trump Rally Comes at Volatile Time in American History - The New York Times</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/07/14/us/politics/trump-assassination-attempt-wounded.html">Link</a>]</p>
</blockquote>
<p>This is crazy but legendary.</p>
<blockquote>
<p><strong>Insurers Pocketed $50 Billion From Medicare for Diseases No Doctor Treated - The Wall Street Journal</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/health/healthcare/medicare-health-insurance-diagnosis-payments-b4d99a5d?st=2vdas0fpyug0ui5">Link</a>]</p>
</blockquote>
<p>UnitedHealth Group committed a $50 billion fraud over the three years of 2019, 2020, and 2021. Though treating doctors say “no treatment or minimal treatment necessary for this diagnosis”, UnitedHealth overrides the docstors’ judgment, generates its own diagnosis code, bills medicare with this new code. </p>
<blockquote>
<p><em>Thousands of Windows machines are experiencing a Blue Screen of Death (BSOD) issue at boot today, impacting banks, airlines, TV broadcasters, supermarkets, and many more businesses worldwide. A faulty update from cybersecurity provider CrowdStrike is knocking affected PCs and servers offline, forcing them into a recovery boot loop so machines can’t start properly. The issue is not being caused by Microsoft but by third-party CrowdStrike software that’s widely used by many businesses worldwide for managing the security of Windows PCs and servers.</em></p>
<p><strong>― Major Windows BSOD issue hits banks, airlines, and TV broadcasters - The Verge</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/7/19/24201717/windows-bsod-crowdstrike-outage-issue">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>That from Christopher Thornberg who heads a California-based consulting firm called Beacon Economics. He says moving a main office like this out of state would likely mean anywhere from dozens of lost jobs to a couple hundred, not thousands of jobs lost.</em></p>
<p><em>Governor Newsom’s press office took to X after Musk made the announcement comparing California to Texas saying, “The last time Elon Musk moved an HQ, Tesla ended up expanding in California, even relocating their Global Engineering and AI headquarters to California because of diverse, world leading talent.”</em></p>
<p><strong>― What Elon Musk’s Texas relocation plan for SpaceX, X HQs could mean for CA - ABC7 News</strong> [<a target="_blank" rel="noopener" href="https://abc7news.com/post/what-elon-musks-plan-move-spacex-headquarters-texas-could-mean-california">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>SearchGPT Prototype - OpenAI News</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/searchgpt-prototype/">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/07/04/Dare-to-Lead/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/07/04/Dare-to-Lead/" class="post-title-link" itemprop="url">Dare to Lead</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-04 18:40:23" itemprop="dateCreated datePublished" datetime="2024-07-04T18:40:23-04:00">2024-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-08-11 09:38:11" itemprop="dateModified" datetime="2024-08-11T09:38:11-04:00">2024-08-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>I’ve never looked so deeply into my feelings inside until I met this book written by Brené Brown. I fell in love with it immediately when I saw the quote from Theodore Roosevelt at the very beginning:</p>
<blockquote>
<p>It is not the critic who counts; not the man who points out how the strong man stumbles, or where the doer of deeds could have done them better. The credit belongs to the man who is actually in the arena, whose face is marred by dust and sweat and blood; who strives valiantly; who errs, who comes short again and again… who at the best knows in the end the triumph of high achievement, and who at the worst, if he fails, at least fails while daring greatly.</p>
</blockquote>
<h1 id="Part-1-Rumbling-with-Vulnerability"><a href="#Part-1-Rumbling-with-Vulnerability" class="headerlink" title="Part 1. Rumbling with Vulnerability"></a>Part 1. Rumbling with Vulnerability</h1><p>Definition of the courage to be vulnerable:</p>
<blockquote>
<p>The courage to be vulnerable is not about winning or losing, it’s about the courage to show up when you can’t predict or control the outcome. The only thing I know for sure after all of this research is that if you’re going to dare greatly, you’re going to get your ass kicked at some point. If you choose courage, you will absolutely know failure, disappointment, setback, even heartbreak. That’s why we call it courage. That’s why it’s so rare.</p>
</blockquote>
<p>Definition of rumbling with vulnerability. It’s a foundational and core skill of courage building, and “our ability to be daring leaders will never be greater than our capacity for vulnerability”.</p>
<blockquote>
<p>A rumble is a discussion, conversation, or meeting defined by a commitment to lean into vulnerability, to stay curious and generous, to stick with the messy middle of problem identification and solving, to take a break and circle back when necessary, to be fearless in owning our parts, and, as psychologist Harriet Lerner teaches, to listen with the same passion with which we want to be heard.</p>
</blockquote>
<h2 id="Section-1-The-Moment-and-The-Myths"><a href="#Section-1-The-Moment-and-The-Myths" class="headerlink" title="Section 1. The Moment and The Myths"></a>Section 1. The Moment and The Myths</h2><p>Good practices:</p>
<ol>
<li>Have the courage to show up when you can’t control the outcome</li>
</ol>
<blockquote>
<p>The definition of vulnerability is the emotion that we experience during times of uncertainty, risk, and emotional exposure. Vulnerability is not winning or losing. It’s having the courage to show up when you can’t control the outcome.</p>
</blockquote>
<ol start="2">
<li>Step over cheap-seat feedback and keep daring</li>
</ol>
<blockquote>
<p>If you are not in the arena getting your ass kicked on occasion, I’m not interested in or open to your feedback. There are a million cheap seats in the world today filled with people who will never be brave with their lives but who will spend every ounce of energy they have hurling advice and judgment at those who dare greatly. Their only contributions are criticism, cynicism, and fearmongering. If you’re criticizing from a place where you’re not also putting yourself on the line, I’m not interested in what you have to say.</p>
</blockquote>
<blockquote>
<p>Don’t grab hurtful comments and pull them close to you by rereading them and ruminating on them. Don’t play with them by rehearsing your badass comeback. And whatever you do, don’t pull hatefulness close to your heart.</p>
</blockquote>
<ol start="3">
<li>Don’t shield ourselves from all feedback</li>
</ol>
<blockquote>
<p>Again, if we shield ourselves from all feedback, we stop growing. If we engage with all feedback, regardless of the quality and intention, it hurts too much, and we will ultimately armor up by pretending it doesn’t hurt, or, worse yet, we’ll disconnect from vulnerability and emotion so fully that we stop feeling hurt. When we get to the place that the armor is so thick that we no longer feel anything, we experience a real death. We’ve paid for selfprotection by sealing off our heart from everyone, and from everything-not just hurt, but love.</p>
</blockquote>
<p>The six misguided myths of vulnerability:</p>
<ol>
<li>Vulnerability is weakness</li>
<li>I don’t do vulnerability</li>
</ol>
<blockquote>
<p>Choosing to own our vulnerability and do it consciously means learning how to rumble with this emotion and understand how it drives our thinking and behavior so we can stay aligned with our values and live in our integrity. Pretending that we don’t do vulnerability means letting fear drive our thinking and behavior without our input or even awareness, which almost always leads to acting out or shutting down.</p>
</blockquote>
<ol start="3">
<li>I can do it alone</li>
<li>You can engineer uncertainty out of vulnerability</li>
<li>Trust comes before vulnerability</li>
</ol>
<blockquote>
<p>We need to trust to be vulnerable, and we need to be vulnerable in order to build trust.</p>
</blockquote>
<blockquote>
<p>Trust is the stacking and layering of small moments and reciprocal vulnerability over time. Trust and vulnerability grow together, and to betray one is to destroy both.</p>
</blockquote>
<p>And I like this marble jar approach:</p>
<blockquote>
<p>We trust the people who have earned marbles over time in our life. Whenever someone supports you, or is kind to you, or sticks up for you, or honors what you share with them as private, you put marbles in the jar. When people are mean, or disrespectful, or share your secrets, marbles come out. We look for the people who, over time, put marbles in, and in, and in, until you look up one day and they’re holding a full jar. Those are the folks you can tell your secrets to. Those are the folks you trust with information that’s important to you.</p>
</blockquote>
<ol start="6">
<li>Vulnerability is disclosure</li>
</ol>
<h2 id="Section-2-The-Call-to-Courage"><a href="#Section-2-The-Call-to-Courage" class="headerlink" title="Section 2. The Call to Courage"></a>Section 2. The Call to Courage</h2><blockquote>
<p>Leaders must either invest a reasonable amount of time attending to fears and feelings, or squander an unreasonable amount of time trying to manage ineffective and unproductive behavior.</p>
</blockquote>
<ol>
<li>Hunt treasures</li>
</ol>
<blockquote>
<p>This is when I remember Joseph Campbell’s quote, which I believe is one of the purest calls to courage for leaders: “The cave you fear to enter holds the treasure you seek.</p>
</blockquote>
<p>When we are in fear or in self-protection, these are the patterns of how we assemble our armor. And they will NOT lead us to anywhere.</p>
<p>a. I’m not enough</p>
<p>b. If i’m honest about what’s happening, they will think less of me or maybe use it against me</p>
<p>c. No one else is going to be honest about what’s happening and so no way am I going to do that</p>
<p>d. They are not honest about what scares them and they’ve got a lot of issues</p>
<p>e. This is their fault and they are trying to blame me</p>
<p>f. I’m better than them</p>
<ol start="2">
<li>Serve people</li>
</ol>
<blockquote>
<p>When you find the courage to enter that cave, you’re never going in to secure your own treasure or your own wealth; you face your fears to find the power and wisdom to serve others.</p>
</blockquote>
<p>Good practices:</p>
<ol>
<li>Have a one-on-one discussion</li>
<li>Stop talking. Leave long white pauses and empty space so that we can start peeling and going deep.</li>
<li>When they start talking. Really listen.</li>
<li>When we are in tough rumbles with people, we can’t take responsibility for their emotions.</li>
<li>When rumbles become unproductive, give everyone minutes to walk around outside or catch their breath.</li>
</ol>
<h2 id="Section-3-The-Armory"><a href="#Section-3-The-Armory" class="headerlink" title="Section 3. The Armory"></a>Section 3. The Armory</h2><blockquote>
<p>The problem is that when we imprison the heart, we kill courage. In the same way that we depend on our physical heart to pump life-giving blood to every part of our body, we depend on our emotional heart to keep vulnerability coursing through the veins of courage and to engage all of the behaviors we talked about in the prior section, including trust, innovation, creativity, and accountability.</p>
</blockquote>
<p>You got to put down the weapons and show up.</p>
<blockquote>
<p>As children we found ways to protect ourselves from vulnerability, from being hurt, diminished, and disappointed. We put on armor; we used our thoughts, emotions, and behaviors as weapons; and we learned how to make ourselves scarce, even to disappear. Now as adults we realize that to live with courage, purpose, and connection to be the person who we long to be-we must again be vulnerable. We must take off the armor, put down the weapons, show up, and let ourselves be seen.</p>
</blockquote>
<p>Forms of armored leadership with top three as perfectionism, foreboding joy, numbing:</p>
<ol>
<li>Driving Perfectionism (armored leadership) vs encouraging for healthy striving (daring leadership).</li>
</ol>
<blockquote>
<p>Perfectionism is not the same thing as striving for excellence. Perfectionism is not about healthy achievement and growth. Perfectionism is a defensive move.</p>
</blockquote>
<blockquote>
<p>Perfectionism is not the self-protection we think it is. It is a twenty-ton shield that we lug around, thinking it will protect us, when in fact it’s the thing that’s really preventing us from being seen.</p>
</blockquote>
<blockquote>
<p>Perfectionism is not self-improvement. Perfectionism is, at its core, about trying to earn approval. Most perfectionists grew up being praised for achievement and performance (grades, manners, rule following, people pleasing, appearance, sports). Somewhere along the way, they adopted this dangerous and debilitating belief system: I am what I accomplish and how well I accomplish it. Please. Perform. Perfect. Prove. Healthy striving is self-focused: How can I improve? Perfectionism is other-focused: What will people think? Perfectionism is a hustle.</p>
</blockquote>
<blockquote>
<p>Perfectionism is not the key to success. In fact, research shows that perfectionism hampers achievement. Perfectionism is correlated with depression, anxiety, addiction, and life paralysis, or missed opportunities. The fear of failing, making mistakes, not meeting people’s expectations, and being criticized keeps us outside the arena where healthy competition and striving unfolds.</p>
</blockquote>
<blockquote>
<p>Last, perfectionism is not a way to avoid shame. Perfectionism is a function of shame.</p>
</blockquote>
<ol start="2">
<li><p>Squandering opportunities for joy and recognition (armored leadership) vs practicing gratitude and celebrating milestones (daring leadership).</p>
</li>
<li><p>Numbing (armored leadership) vs setting boundaries and finding real comfort (daring leadership)</p>
</li>
</ol>
<blockquote>
<p>We cannot selectively numb emotion. If we numb the dark, we numb the light. If we take the edge off pain and discomfort, we are, by default, taking the edge off joy, love, belonging, and the other emotions that give meaning to our lives.</p>
</blockquote>
<ol start="4">
<li>Propagating the false dichotomy of victim or viking (armored leadership) vs practicing integration - strong back, soft front, wild heart (daring leadership)</li>
</ol>
<blockquote>
<p>The opposite of living in a world of false binaries is practicing integration the act of bringing together all the parts of ourselves, as we talked about earlier. We are all tough and tender, scared and brave, grace and grit. The most powerful example of integrationa practice that I wrote about in Braving the Wilderness and that I try to live by-is strong back, soft front, wild heart.</p>
<p>How can we give and accept care with strongback, soft-front compassion, moving past fear into a place of genuine tenderness? I believe it comes about when we can be truly transparent, seeing the world clearly-and letting the world see into us.</p>
</blockquote>
<ol start="5">
<li>Being a knower and being right (armored leadership) vs being a learner and getting it right (daring leadership)</li>
</ol>
<blockquote>
<p>Having to be the “knower” or always being right is heavy armor. It’s defensiveness, it’s posturing, and , worst of all, it’s a huge driver of bullshit.</p>
</blockquote>
<ol start="6">
<li>Hiding behind cynicism (armored leadership) vs modeling clarity, kindness, and hope (daring leadership)</li>
<li>Using criticism as self-protection (armored leadership) vs making contributions and taking risks (daring leadership)</li>
<li>Using power over (armored leadership) vs using power with, power to, and power within (daring leadership)</li>
<li>Hustling for your worth (armored leadership) vs knowing your value (daring leadership)</li>
</ol>
<blockquote>
<p>When people don’t understand where they’re strong and where they deliver value for the organization or even for a single effort, they hustle. And not the good kind of hustle. The kind that’s hard to be around because we are jumping in everywhere, including where we’re not strong or not needed, to prove we deserve a seat at the table. When we do not understand our value, we often exaggerate our importance in ways that are not helpful, and we consciously or unconsciously seek attention and validation of importance.”</p>
</blockquote>
<ol start="10">
<li>Zigzagging and avoiding (armored leadership) vs talking straight and taking action (daring leadership)</li>
</ol>
<blockquote>
<p>Zigzagging is a metaphor for the energy we spend trying to dodge the bullets of vulnerability whether it’s conflict, discomfort, confrontation, or the potential for shame, hurt, or criticism.</p>
</blockquote>
<blockquote>
<p>When we find ourselves zigzagging-hiding out, pretending, avoiding, procrastinating, rationalizing, blaming, lying-we need to remind ourselves that running is a huge energy suck and probably way outside our values. At some point, we have to turn toward vulnerability and make that call.</p>
</blockquote>
<h2 id="Section-4-Shame-and-Empathy"><a href="#Section-4-Shame-and-Empathy" class="headerlink" title="Section 4. Shame and Empathy"></a>Section 4. Shame and Empathy</h2><p>The definition of shame:</p>
<blockquote>
<p>First, shame is the fear of disconnection. As we talked about in the myths of vulnerability, we are physically, emotionally, cognitively, and spiritually hardwired for connection, love, and belonging. Connection, along with love and belonging, is why we are here, and it is what gives purpose and meaning to our lives. Shame is the fear of disconnection-it’s the fear that something we’ve done or failed to do, an ideal that we’ve not lived up to, or a goal that we’ve not accomplished makes us unworthy of connection.</p>
<p>Shame is the intensely painful feeling or experience of believing that we are flawed and therefore unworthy of love, belonging, and connection.</p>
<p>Retreating into our smallness becomes the most seductive and easiest way to stay safe in the midst of the shame squeeze. But, as we’ve talked about, when we armor and contort ourselves into smallness, things break and we suffocate.</p>
</blockquote>
<p>Behavioral cues that shame has permeated a culture:</p>
<blockquote>
<p>Perfectionism; Favoritism; Gossiping; Back-channeling; Comparison; Self-worth tied to productivity; Harassment; Discrimination; Power over;  Bullying; Blaming; Teasing; Cover-ups.</p>
</blockquote>
<p>Shame resistance is not possible as long as we care about connection, but shame resilience is possible, learnable by all of us. We need to be empathy and self-compassion.</p>
<blockquote>
<p>Shame resilience is the ability to practice authenticity when we experience shame, to move through the experience without sacrificing our values, and to come out on the other side of the shame experience with more courage, compassion, and connection than we had going into it. Ultimately, shame resilience is about moving from shame to empathy the real antidote to shame.</p>
<p>it’s important to understand that if we share our story with someone who responds with empathy and understanding, shame can’t survive. Self-compassion is also critically important, but because shame is a social concept-it happens between people it also heals best between people. A social wound needs a social balm, and empathy is that balm. Self-compassion is key because when we’re able to be gentle with ourselves in the midst of shame, we’re more likely to reach out, connect, and experience empathy.</p>
</blockquote>
<p>The definition of empathy:</p>
<blockquote>
<p>Empathy is not connecting to an experience, it’s connecting to the emotions that underpin an experience.</p>
</blockquote>
<blockquote>
<p>Empathy is a choice. And it’s a vulnerable choice, because if I were to choose to connect with you through empathy, I would have to connect with something in myself that knows that feeling. In the face of a difficult conversation, when we see that someone’s hurt or in pain, it’s our instinct as human beings to try to make things better. We want to fix, we want to give advice.  But empathy isn’t about fixing, it’s the brave choice to be with someone in their darkness-not to race to turn on the light so we feel better.</p>
<p>If struggle is being down in a hole, empathy is not jumping into the hole with someone who is struggling and taking on their emotions, or owning their struggle as yours to fix. If their issues become yours, now you have two people stuck in a hole. Not helpful. Boundaries are important here. We have to know where we end and others begin if we really want to show up with empathy.</p>
</blockquote>
<blockquote>
<p>Empathy is at the heart of connection-it is the circuit board for leaning into the feelings of others, reflecting back a shared experience of the world, and reminding them that they are not alone.</p>
</blockquote>
<p><strong>Empathy skills:</strong></p>
<p>From practical perspective, empathy is first to take the perspective of another person, second to stay out of judgment, third to understand their emotion, and fourth to communicate my understanding of their emotion.</p>
<ol>
<li>To see the world as others see it, or perspective taking</li>
</ol>
<blockquote>
<p>Perspective taking requires becoming the learner, not the knower.</p>
<p>Again, it’s only when diverse perspectives are included, respected, and valued that we can start to get a full picture of the world, who we serve, what they need, and how to successfully meet people where they are.</p>
<p>I love what Beyoncé said in her first-person essay in the September 2018 issue of Vogue: ”If people in powerful positions continue to hire and cast only people who look like them, sound like them, come from the same neighborhoods they grew up in, they will never have a greater understanding of experiences different from their own. They will hire the same models, curate the same art, cast the same actors over and over again, and we will all lose. The beauty of social media is it’s completely democratic. Everyone has a say. Everyone’s voice counts, and everyone has a chance to paint the world from their own perspective.”</p>
</blockquote>
<ol start="2">
<li>To be unjudgmental</li>
</ol>
<blockquote>
<p>Based on research, there are two ways to predict when we are going to judge: We judge in areas where we’re most susceptible to shame, and we judge people who are doing worse than we are in those areas.</p>
</blockquote>
<ol start="3">
<li>To understand another person’s feelings</li>
<li>To communicate your understanding of that person’s feelings</li>
</ol>
<blockquote>
<p>Fluency in emotional conversation means being able to name at least thirty of them.</p>
</blockquote>
<blockquote>
<p>One reason emotion is difficult to identify and name is the iceberg effect.</p>
</blockquote>
<blockquote>
<p>Many of the emotions that we experience show up as pissed off or shut down on the surface. Below the surface, there’s much more nuance and depth. Shame and grief are two examples of emotions that are hard to fully express, so we turn to anger or silence.</p>
<p>The vast majority of us find it easier to be mad than hurt. Not only is it easier to express anger than it is to express pain, our culture is more accepting of anger. So the next time you’re shutting down or angry, ask yourself what lies beneath.</p>
</blockquote>
<ol start="5">
<li>Mindfulness &#x2F; Paying attention</li>
</ol>
<p><strong>Self-compassion skills</strong></p>
<ol>
<li>Maintain clear line</li>
</ol>
<blockquote>
<p>Do not take responsibility and ownership for the words of other people-just own your part.</p>
</blockquote>
<blockquote>
<p>Jumping into the hole with no way out is enmeshment-jumping into struggle with someone while maintaining clear lines about what belongs to whom is empathy.</p>
</blockquote>
<ol start="2">
<li>Stop beating yourself</li>
</ol>
<blockquote>
<p>Talk to yourself the way you’d talk to someone you love.</p>
</blockquote>
<p>Four elements of shame resilience:</p>
<ol>
<li>Recognizing shame and understanding its triggers</li>
</ol>
<p>When we have understanding and awareness around shame, we are less likelyy to default to our shame shields or the following three strategies of disconnection:</p>
<blockquote>
<p>Moving away: Withdrawing, hiding, silencing ourselves, and keeping secrets. Moving toward: Seeking to appease and please. Moving against: Trying to gain power over others by being aggressive, and by using shame to fight shame.</p>
</blockquote>
<ol start="2">
<li>Practicing critical awareness</li>
<li>Reaching out</li>
<li>Speaking shame</li>
</ol>
<h2 id="Section-5-Curiosity-and-Grounded-Confidence"><a href="#Section-5-Curiosity-and-Grounded-Confidence" class="headerlink" title="Section 5. Curiosity and Grounded Confidence"></a>Section 5. Curiosity and Grounded Confidence</h2><blockquote>
<p>Dheeraj explained to me that when leaders don’t have the skills to lean into vulnerability, they’re not able to successfully hold the tension of the  paradoxes that are inherent in entrepreneurship. His examples of the paradoxes that elicit vulnerability in leaders align with what we heard from the research participants: • Optimism and paranoia • Letting chaos reign (the act of building) and reining in chaos (the act of scaling) • Big heart and tough decision making • Humility and fierce resolve • Velocity and quality when building new things • Left brain and right brain • Simplicity and choice • Thinking global, acting local • Ambition and attention to detail • Thinking big but starting small • Short-term and long-term • Marathons and sprints, or marathon of sprints in business-building Dheeraj told me, “Leaders must learn the skills to hold these tensions and get adept at balancing on the ‘tightrope’ of life. Ultimately, leadership is the ability to thrive in the ambiguity of paradoxes and opposites.”</p>
</blockquote>
<p>How to build skills to hold tensions of the paradoxes:</p>
<ol>
<li>Rumble skills: easy learning does not build strong skills</li>
</ol>
<blockquote>
<p>The reality is that to be effective, learning needs to be effortful. That’s not to say that anything that makes learning easier is counterproductive-or that all unpleasant learning is effective. The key here is desirable difficulty. The same way you feel a muscle “burn” when it’s being strengthened, the brain needs to feel some discomfort when it’s learning. Your mind might hurt for a while-but that’s a good thing.</p>
</blockquote>
<ol start="2">
<li>Curiosity</li>
</ol>
<blockquote>
<p>In his book Curious: The Desire to Know and Why Your Future Depends on It, Ian Leslie writes, “Curiosity is unruly. It doesn’t like rules, or, at least, it assumes that all rules are provisional, subject to the laceration of a smart question nobody has Yet thought to ask. It disdains the approved pathways, preferring diversions, unplanned excursions, impulsive left turns. In short, curiosity is deviant.”</p>
</blockquote>
<ol start="3">
<li>Practice vulnerability, become self-aware, and engage in tough conversations</li>
</ol>
<blockquote>
<p>There’s an old saying that I lead by now: “People don’t care how much you know until they know how much you care.” I’ve learned one way to help people understand how much you care is to share your story.</p>
</blockquote>
<h1 id="Part-2-Living-into-Our-Values"><a href="#Part-2-Living-into-Our-Values" class="headerlink" title="Part 2. Living into Our Values"></a>Part 2. Living into Our Values</h1><p>Values and living into our values:</p>
<blockquote>
<p>A value is a way of being or believing that we hold most important. Living into our values means that we do more than profess our values, we practice them. We walk our talk-we are clear about what we believe and hold important, and we take care that our intentions, words, thoughts, and behaviors align with those beliefs.</p>
</blockquote>
<blockquote>
<p>More often than not, our values are what lead us to the arena door-we’re willing to do something uncomfortable and daring because of our beliefs. And when we get in there and stumble or fall, we need our values to remind us why we went in, especially when we are facedown, covered in dust and sweat and blood. Here’s the thing about values: While courage requires checking our armor and weapons at the arena door, we do not have to enter every tough conversation and difficult rumble completely empty-handed.</p>
</blockquote>
<p>Three steps to help you know more about yourself and how to live into your values:</p>
<ol>
<li>We can’t live into values that we can’t name</li>
<li>Taking values from BC to behavior</li>
<li>Empathy and self-compassion: the two most important seats in the arena</li>
</ol>
<blockquote>
<p>Regardless of the values you pick, daring leaders who live into their values are never silent about hard things.</p>
</blockquote>
<blockquote>
<p>“You first listen about race. You will make a lot of mistakes. It will be super uncomfortable. And there’s no way to talk about it without getting some criticism. But you can’t be silent.” To opt out of conversations about privilege and oppression because they make you uncomfortable is the epitome of privilege.</p>
</blockquote>
<blockquote>
<p>Silence is not brave leadership, and silence is not a component of brave cultures. Showing up and being courageous around these difficult conversations is not a path you can predetermine. A brave leader is not someone who is armed with all the answers. A brave leader is not someone who can facilitate a flawless discussion on hard topics. A brave leader is someone who says I see you. I hear you. I don’t have all the answers, but I’m going to keep listening and asking questions. We all have the capacity to do that. We all have the ability to foster empathy. If we want to do good work, it’s imperative that we continue to flesh out these harder conversations, to push against secrecy, silence, and judgment. It’s the only way to eradicate shame from the workplace, to clear the way for a performance in the arena that correlates with our highest values and not the fearmongers from the stands.</p>
</blockquote>
<p>The biggest challenge we face when it comes to values is the necessity to give feedback and receive feedback. You have to know when you are ready to give feedback and be good at receiving feedback.</p>
<ol>
<li>Understand their values</li>
</ol>
<blockquote>
<p>You don’t really know people until you take the time to understand their values.</p>
</blockquote>
<ol start="2">
<li>Daring leaders assume the best about people’s intention and assume they are doing the best they can. Leaders struggling with ego, armor, and&#x2F;or a lack of skills do not make that assumption.</li>
</ol>
<blockquote>
<p>What is the foundational skill of assuming the best in people? Setting and maintaining boundaries. What’s the fundamental belief underpinning the assumption of positive intent? That people are doing the best they can.</p>
</blockquote>
<blockquote>
<p>The people who are the most generous in their assumptions of others have the clearest boundaries. The most compassionate and generous people I’ve interviewed in my career are the most boundaries. It turns out that we assume the worst about people’s intentions when they’re not respectful of our boundaries: It is easy to believe that they are trying to disappoint us on purpose. However, we can be very compassionate toward people who acknowledge and respect what’s okay and what’s not.</p>
</blockquote>
<blockquote>
<p>In addition to boundaries, an assumption of positive intent relies on the core belief that people are doing the best they can with what they’ve got, versus that people are lazy, disengaged, and maybe even trying to piss us off on purpose. Sure, we’re all capable of change and growth, but assuming positive intent requires the belief that people are really trying in that moment.</p>
</blockquote>
<blockquote>
<p>Assuming positive intent does not mean that we stop helping people set goals or that we stop expecting people to grow and change. It’s a commitment to stop respecting and evaluating people based solely on what we think they should accomplish, and start respecting them for who they are and holding them accountable for what they’re actually doing. And when we’re overwhelmed and struggling, it also means turning those positive assumptions toward ourselves: I’m doing the very best I can right now.</p>
</blockquote>
<h1 id="Part-3-Braving-Trust"><a href="#Part-3-Braving-Trust" class="headerlink" title="Part 3. Braving Trust"></a>Part 3. Braving Trust</h1><p>Importance of talking about trust:</p>
<blockquote>
<p>Because talking about trust is tough, and because these conversations have the potential to go sideways fast, we often avoid the rumble. And that’s even more dangerous. First, when we’re struggling with trust and don’t have the tools or skills to talk about it directly with the person involved, it leads us to talk about people instead of to them. It also leads to lots of energy-wasting zigzagging.</p>
</blockquote>
<p>To measure individual level of trustworthiness, you can refer to the following seven behaviors - BRAVING inventory:</p>
<blockquote>
<p>Boundaries: You respect my boundaries, and when you’re not clear about what’s okay and not okay, you ask. You’re willing to say no. Reliability: You do what you say you’ll do. At work, this means staying aware of your competencies and limitations so you don’t overpromise and are able to deliver on commitments and balance competing priorities. Accountability: You own your mistakes, apologize, and make amends. Vault: You don’t share information or experiences that are not yours to share. I need to know that my confidences are kept, and that you’re not sharing with me any information about other people that should be confidential. Integrity: You choose courage over comfort. You choose what is right over what is fun, fast, or easy. And you choose to practice your values rather than simply professing them. Nonjudgment: I can ask for what I need, and you can ask for what you need. We can talk about how we feel without judgment. We can ask each other for help without judgment. Generosity: You extend the most generous interpretation possible to the intentions, words, and actions of others.</p>
</blockquote>
<p>Unpacking Vault:</p>
<blockquote>
<p>When I walk into a co-worker’s office and spill, there might be a moment of connection, but it’s counterfeit connection. The second I walk out, that colleague is likely thinking, “I should be careful about what I tell Brené; she’s got no boundaries.”</p>
</blockquote>
<p>Unpacking nonjudgment:</p>
<p>We are afraid of being judged for a lack of knowledge or lack of understanding, so we hate asking questions.</p>
<blockquote>
<p>We asked a thousand leaders to list marble earning behaviors-what do your team members do that earns your trust? The most common answer: asking for help. When it comes to people who do not habitually ask for help, the leaders we polled explained that they would not delegate important work to them because the leaders did not trust that they would raise their hands and ask for help.</p>
</blockquote>
<blockquote>
<p>Trust is built in small moments. If you struggle with reliability, make small and doable promises to yourself that are easy to fulfill, until you get a flywheel of reliability going again. If you struggle with boundaries, set small ones with your partner-like you will not be responsible for both cooking and cleaning up dinner-until you are adept at putting boundaries into action in a more meaningful way. That’s how you fill your own marble jar. And never forget-we can’t give people what we don’t have.</p>
</blockquote>
<h1 id="Part-4-Learning-to-Rise"><a href="#Part-4-Learning-to-Rise" class="headerlink" title="Part 4. Learning to Rise"></a>Part 4. Learning to Rise</h1><blockquote>
<p>We can’t expect people to be brave and risk failure if they’re not prepped for hard landings.</p>
</blockquote>
<blockquote>
<p>Here’s the bottom line: If we don’t have the skills to get back up, we may not risk falling. And if we’re brave enough often enough, we are definitely going to fall. The research participants who have the highest levels of resilience can get back up after a disappointment or a fall, and they are more courageous and tenacious as a result of it. They do that with a process that I call Learning to Rise. It has three parts: the reckoning, the rumble, and the revolution.</p>
</blockquote>
<p>Three steps process for learning to rise:</p>
<blockquote>
<p>When we have the courage to walk into our story and own it, we get to write the ending. And when we don’t own our stories of failure, setbacks, and hurt-they own us.</p>
</blockquote>
<ol>
<li>The Reckoning</li>
</ol>
<blockquote>
<p>The reckoning is as simple as that: knowing that we’re emotionally hooked and then getting curious about it.</p>
</blockquote>
<blockquote>
<p>The ego doesn’t own stories or want to write new endings; it denies emotion and hates curiosity. Instead, the ego uses stories as armor and alibi. The ego says “Feelings are for losers and weaklings.”</p>
</blockquote>
<blockquote>
<p>The most effective strategy for staying with emotion instead of offloading it is something I learned from a yoga teacher. And from a few members of the military Special Forces. It’s breathing.</p>
</blockquote>
<blockquote>
<p>Breathing is also the key to another strategy for reckoning with emotion, and one of the most underrated leadership superpowers: practicing calm.</p>
<p>I define calm as creating perspective and mindfulness while managing emotional reactivity.</p>
<p>Calm is a superpower because it is the balm that heals one of the most prevalent workplace stressors: anxiety.</p>
</blockquote>
<ol start="2">
<li>Rumble: conspiracies, confabulations, and shitty first drafts</li>
</ol>
<blockquote>
<p>If the reckoning is how we walk into a tough story, the rumble is where we go to the mat with it and own it.</p>
<p>The rumble starts with this universal truth: In the absence of data, we will always make up stories. It’s how we are wired. Meaning making is in our biology, and when we’re in struggle, our default is often to come up with a story that makes sense of what’s happening and gives our brain information on how best to self-protect. And it happens a hundred times a day at work.</p>
</blockquote>
<blockquote>
<p>In our SFDs, fear fills in the data gaps. What makes that scary is that stories based on limited real data and plentiful imagined data, blended into a coherent, emotionally satisfying version of reality, are called conspiracy theories. Yes, we are all conspiracy theorists with our own stories, constantly filling in data gaps with our fears and insecurities.</p>
</blockquote>
<blockquote>
<p>Confabulation has a really great and subtle definition: A confabulation is a lie told honestly. To confabulate is to replace missing information with something false that we believe to be true.</p>
</blockquote>
<blockquote>
<p>Confabulation shows up at work when we share what we believe is factual information, but it’s really just our opinion.</p>
</blockquote>
<blockquote>
<p>Gottschall writes, “Conspiracy is not limited to the stupid, the ignorant, or the crazy. It is a reflex of the storytelling mind’s compulsive need for meaningful experience.” The problem is that rather than rumbling with vulnerability and staying in uncertainty, we start to fill in the blanks with our fears and worst-case-scenario planning. I love this line from Gottschall: “To the conspiratorial mind, shit never just happens.”</p>
</blockquote>
<blockquote>
<p>The three most dangerous stories we make up are the narratives that diminish our lovability, divinity, and creativity.</p>
<p>The reality check around our lovability: Just because someone isn’t willing or able to love us, it doesn’t mean that we are unlovable.</p>
<p>The reality check around our divinity: No person is ordained to judge our divinity or to write the story of our spiritual worthiness.</p>
<p>The reality check around our creativity: Just because we didn’t measure up to some standard of achievement doesn’t mean that we don’t possess gifts and talents that only we can bring to the world. And just because someone failed to see the value in what we can create or achieve doesn’t change its worth or ours.</p>
</blockquote>
<blockquote>
<p>When we own a story and the emotion that fuels it, we get to simultaneously acknowledge that something was hard while taking control of how that hard thing is going to end. We change the narrative. When we deny a story and when we pretend we don’t make up stories, the story owns us. It drives our behavior, and it drives our cognition, and then it drives even more emotions until it completely owns us.</p>
</blockquote>
<ol start="3">
<li>The Revolution</li>
</ol>
<blockquote>
<p>I’m not afraid of the word revolution, I’m afraid of a world that’s becoming less courageous and authentic. I’ve always believed that in a world full of critics, cynics, and fearmongers, taking off the armor and rumbling with vulnerability, living into our values, braving trust with open hearts, and learning to rise so we can reclaim authorship of our own stories and lives is the revolution. Courage is rebellion.</p>
</blockquote>
<blockquote>
<p>Revolution might sound a little dramatic, but in this world, choosing authenticity and worthiness is an absolute act of resistance. Choosing to live and love with our whole hearts is an act of defiance. You’re going to confuse, piss off, and terrify lots of people-including yourself. One minute you’ll pray that the transformation stops, and the next minute you’ll pray that it never ends. You’ll also wonder how you can feel so brave and so afraid at the same time. At least that’s how I feel most of the time … brave, afraid, and very, very alive.</p>
</blockquote>
<blockquote>
<p>Own the fear, find the cave, and write a new ending for yourself, for the people you’re meant to serve and support, and for your culture. Choose courage over comfort. Choose whole hearts over armor. And choose the great adventure of being brave and afraid. At the exact same time.</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/06/20/2024-June/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/06/20/2024-June/" class="post-title-link" itemprop="url">2024 June</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-06-20 04:22:31" itemprop="dateCreated datePublished" datetime="2024-06-20T04:22:31-04:00">2024-06-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-02 00:21:17" itemprop="dateModified" datetime="2024-07-02T00:21:17-04:00">2024-07-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><strong>Salesforce: Worst Day in 20 Years - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/salesforce-worst-day-in-20-years">Link</a>]</p>
</blockquote>
<p>PayPal hired Mark Grether who was head of Uber’s ad business to lead the initiative of an ad network. </p>
<p>Costco’s membership fees declined from 86% to 50% of the its operating profit. It has shown economies of scale and benefits from a more favorable revenue mix.</p>
<p>Salesforce’s revenue grew 11% to $9.1B, missing Wall Street estimates by $20M. Current Remaining Performance Obligations - the best indicator of future growth - rose 10%, missing estimates of 12%. The slowing growth is partially due to broader macroeconomic challenges and internal execution issues. Salesforce Data Cloud is contributing to 25% of the deals valued above $1M, indicating it’s well-positioned to benefit from AI boom.</p>
<p>Live Nation has caused such widespread outrage in 2022 Taylor Swift Eras Tour ticket sales because fans faced technical glitches and exorbitant fees. Live Nation was accused of locking venues into exclusive deals and bullying artists into using its services, which caused higher ticket prices through service and convenience fees. Live Nation is under scrutiny by the government. It is forced to divest Ticketmaster (acquired in 2020). Fans &#x2F; artists are expecting increased competition in live music industry and lower prices, and a smoother ticket buying experience.</p>
<blockquote>
<p><strong>Online Travel: AI is Coming - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/online-travel-ai-is-coming">Link</a>]</p>
</blockquote>
<p>AI agents as the next frontier could make traveling personalized. The key metrics to define their success are 1) gross bookings, 2) nights booked, 3) average daily rate (ADR), 4) revenue per available room (RevPAR), customer acquisition cost (CAC). </p>
<p>The largest travel companies (online travel agencies and rentals and hotel chains) are Booking Holdings, Airbnb, Expedia, Marriott, and Hilton.</p>
<p>Highlights: 1) Booking Holdings (operating as an OTA): CEO Glenn Fogel envisions AI enhancing connected trips (single booking that include multiple travel elements such as flights, accommodations, car rentals, etc), 2) Airbnb exceeded expectations on both revenue and profitability in Q1 due to its robust international expansion, while slowing down the growth in North America. Airbnb is aiming to create an AI powered concierge to elevate the overall Airbnb experiences, 3) Expedia (operating as an OTA): Expedia is currently facing challenges of transition and adjustment: Vrbo vacation rental platform integration into Expedia platform is slower than expected. And it’s also facing challenges in attracting and retaining customers in its B2C segment. A new CEO Ariane Gorin was recently appointed to help navigate through these challenges. 4) Marriott (operating as booking platform): Marriott has developed Homes &amp; Villas tool that allows users to search for vacation rentals using language. A slow-down RevPAR in North America has been observed which indicates a shift in consumer preferences towards international destinations and alternative accommodations. Its brand reputation, loyalty program and focus on group&#x2F;business travel remain strong. 5) Hilton: has strong emphasis on personalization and loyalty programs though facing headwinds in the US. CEO Chris Nassetta envisions AI-powered tools to address guest concerns in real time.</p>
<blockquote>
<p><em>From graphics rendering, gaming and media, cloud computing and crypto, Nvidia’s chips have led the way in each of these past innovation cycles as it saw its GPU applications expand over the last 2 decades. And now it is getting ready to advance the next industrial revolution, that will be powered by AI.</em></p>
<p><em>Some industry experts believe that<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/how-a-shifting-ai-chip-market-will-shape-nvidias-future-f0c256b1"> 20% of the demand for AI chips next year</a> will be due to model inference needs, with “Nvidia deriving about 40% of its data center revenue just from inference.”</em> </p>
<p><strong>― NVIDIA’s chips are the tastiest AI can find. It’s stock still has ways to go - The Pragmatic Optimist</strong> [<a target="_blank" rel="noopener" href="https://amritaroy.substack.com/p/nvidias-chips-are-the-tastiest-ai">Link</a>]</p>
</blockquote>
<p>This is a good summary of Nvidia’s strategies towards computing, path to AI domination, tailwinds of efficiency, position in the future.</p>
<p>Nvidia is “at the right place at the right time”: </p>
<ul>
<li>During 2000-2010 where the world successfully emerged from the dot-com bust, demand of Nvidia’s GPUs increased as the proliferation of games and multimedia applications. By 2011, Nvidia had already begun to reposition the company’s strategy for GPU chips towards mobile computing. At the same time, the concept of cloud computing, crypto-mining, and data center started to form.</li>
<li>Nvidia has built grounded relationship with academics and researchers. According to the paper published by Andrew Ng to show the power of NVIDIA GPU. During 2011-2015, Ng had been working as the Chief Scientist at many big tech firms and deployed data center architectures based on Nvidia’s GPUs. During 2010-2014, data center and HPC grew at a compounded growth rate of 64%. This period of time was one of the moments that set Nvidia on the course to dominate AI.</li>
</ul>
<p>In semiconductor industry, there are two different ways of manufacturing chips at scale:</p>
<ol>
<li>Designing and manufacturing your own chip - what Intel was doing. Manufacturing chips can be very expensive and hard. Today, chip foundries such as Taiwan’s TSMC and South Korea’s Samsung are able to maintain leading edge.</li>
<li>Designing and producing powerful chips at a quicker pace by partnering with chip foundries like TSMC - what Nvidia and AMD fabless companies are doing.</li>
</ol>
<p>2024 could be the first year that Huang’s Nvidia could cede some market share to AMD. AMD launched their own MI300-series and Intel launched their Gaudi3 AI Accelerator chip, aiming to get back share from Nvidia’s H100&#x2F;H200 chips. However Huang looks ahead:</p>
<ul>
<li><p>Huang believes Nvidia must turn its attention to the next leg of AI - Model Inference. </p>
<p>Tech companies spend more on AI data center equipment over years, Nvidia’s revenue won’t slow down.</p>
</li>
<li><p>Nvidia’s executives also believe that company can benefit from demand from specific industry verticals, such as automotive.s</p>
<p>Tesla, for example, is leading self driving cars.</p>
</li>
<li><p>Automotive AI and Sovereign AI are two future areas of growth where enterprises continue to spend on data centers for model training and inferencing.</p>
</li>
</ul>
<p>The authors also assessed Nvidia’s valuation and believe that:</p>
<ul>
<li>Between 2023 and 2026, Nvidia’s sales should be growing at a compounded annual growth rate of 43–45%.</li>
<li>Over the next 3 years, they expect operating profit to grow in line with revenue growth, with operating profit margins remaining relatively flat in 2025 and 2026.</li>
</ul>
<blockquote>
<p><strong>The Coming Wave of AI, and How Nvidia Dominates - Fabricated Knowledge</strong> [<a target="_blank" rel="noopener" href="https://www.fabricatedknowledge.com/p/the-coming-wave-of-ai-and-how-nvidia">Link</a>]</p>
</blockquote>
<p>Nvidia is the clear leader in 1) System and Networking, 2) Hardware (GPUs and Accelerators), and 3) Software (Kernels and Libraries) but offers the whole solution as a product.</p>
<blockquote>
<p><em>Amazon drives tremendous savings from custom silicon which are hard for competitors to replicate, especially in the standard CPU compute and storage applications. Custom silicon drives 3 core benefits for cloud providers.</em></p>
<ol>
<li><em>Engineering the silicon for your unique workloads for higher performance through architectural innovation.</em></li>
<li><em>Strategic control and lock-in over certain workloads.</em></li>
<li><em>Cost savings from removing margin stacking of fabless design firms.</em></li>
</ol>
<p><em>The removal of these workloads from server CPU cores to the custom Nitro chip not only greatly improves cost, but also improves performance due to <a target="_blank" rel="noopener" href="https://www.semianalysis.com/p/is-ampere-computings-cloud-native">removing noisy neighbor problems</a> associated with the hypervisor, such as shared caches, IO bandwidth, and power&#x2F;heat budgets.</em></p>
<p><strong>― Amazon’s Cloud Crisis: How AWS Will Lose The Future Of Computing - Semianalysis</strong> [<a target="_blank" rel="noopener" href="https://www.semianalysis.com/p/amazons-cloud-crisis-how-aws-will">Link</a>]</p>
</blockquote>
<p>A good overview of Amazon’s in-house semiconductor designs (Nitro, Graviton, SSDs, Inferentia, and Trainium). It includes how Microsoft Azure, Google Cloud, Nvidia Cloud, Oracle Cloud, IBM Cloud, Equinix Fabric, Coreweave, Cloudflare, and Lambda are each fighting Amazon’s dominance across multiple vectors and to various degrees.</p>
<p>Amazon’s custom silicon efforts - Nitro:</p>
<ul>
<li>AWS worked with Cavium on developing the custom SoC on a discrete PCIe card and associated software, named “Nitro System”. It removes workloads from server CPU cores to the custom Nitro chips.</li>
<li>Annapurna Labs was acquired by Amazon in 2015. It focuses on server SOCs for networking and storage. Amazon was trying to continue its efforts on storage, and Nitro is the main enabler of a competitive advantage in these storage and databases.</li>
<li>Nitro provides services such as virtual disk to the tenant’s virtual machines and enables customers to dynamically grow and shrink high performance storage at low cost. </li>
<li>Amazon worked with Marvell to co-design the AWS Nitro SSD controller. The focus was on avoiding latency spikes and latency variability, and maximizing the lifetime of the SSD.</li>
</ul>
<p>Other two clouds (Google and Microsoft) are years behind Amazon, both required a partner, and both were stuck with 1st or 2nd generation merchant silicon for the next few years. </p>
<p>James Hamilton, an engineer in Amazon, had and look at two key ways in which using AWS-designed, Arm-based CPUs could offer advantages compared to their external counterparts.</p>
<ol>
<li>Using Arm’s scale in mobile by using the arm-designed Neoverse cores or </li>
<li>TSMC’s manufacturing scale. Both would reduce costs and offer better value to customers.</li>
</ol>
<p>In-house CPUs enables Amazon to design CPUs to maximize density and minimize server and system level energy which helps reduce costs. The tremendous scale of Amazon especially regarding general-purpose compute and storage-related verticals will continue to drive a durable advantage in the cloud for many years.</p>
<blockquote>
<p><em>Ultrafusion is Apple’s marketing name for using a local silicon interconnect (bridge die) to connect the two M2 Max chips in a package. The two chips are exposed as a single chip to many layers of software. M2 Ultra utilizes <a target="_blank" rel="noopener" href="https://www.semianalysis.com/p/advanced-packaging-part-1-pad-limited">TSMC’s InFO-LSI packaging technology</a>. This is a similar concept as TSMC’s CoWoS-L that is being adopted by Nvidia’s Blackwell and future accelerators down the road to make large chips. The only major difference between Apple and Nvidia’s approaches are that InFO is chip-first vs CoWoS-L is chip-last process flow, and that they are using different types of memory.</em></p>
<p><strong>― Apple’s AI Strategy: Apple Datacenters, On-device, Cloud, And More - Semianalysis</strong> [<a target="_blank" rel="noopener" href="https://www.semianalysis.com/p/apples-ai-strategy-apple-datacenters">Link</a>]</p>
</blockquote>
<p>Apple’s purchases of GPUs are minuscule and Apple is not a top 10 customer of Nvidia. The production of M2 Ultras can be consistent with the fact that Apple is using their own silicon in their own data centers for serving AI to Apple users. And Apple has expansion plans for their own data center infrastructure. Furthermore, Apple made a number of hires including Sumit Gupta who joined to lead cloud infrastructure at Apple in March. </p>
<blockquote>
<p><em>One of the best known non-bank banks is Starbucks – “a bank dressed up as a coffee shop”. Trung Phan, <a target="_blank" rel="noopener" href="https://www.readtrung.com/p/starbucks-digital-dilemna">rates</a> the misperception up there alongside “McDonald’s is a real estate company dressed up as a hamburger chain” and “Harvard is a hedge fund dressed up as an institution of higher learning”.</em></p>
<p><em>Today, more than 60% of the company’s peak morning business in the US comes from Starbucks Rewards members who overwhelmingly order via the app. The program has 33 million users, equivalent to around one in ten American adults.</em> </p>
<p><strong>― Banks in Disguise - Net Interest</strong> [<a target="_blank" rel="noopener" href="https://www.netinterest.co/p/banks-in-disguise">Link</a>]</p>
</blockquote>
<p>Starbucks had offered a gift card since 2001 and started to pair it with a new loyalty program “Starbucks Rewards” in 2008. Consumers are allowed to access free wifi and refillable coffee by paying with a reloadable card. The card was put onto an app in 2010 and expanded to over 9000 locations. It quickly became the largest combined mobile payments in loyalty program in the US. Uses load or reload around $10 B of value onto their cards each year and so about $1.9B of stored card value sat on the company’s balance sheet, just like customer deposits. There are several advantages: 1) the company does not pay interest on customer funds, and 2) sweep customer funds into company’s own bank account when it concludes customers may have forgotten about them - this is called ‘breakage’. In late 2023, Starbucks was accused of making it impossible for consumers to spend down their stored value cards by only allowing funds to be added in $5 increments and requiring a $10 minimum spend. Although the company has to pay rewards to customers, it saves on merchant discount fees and receives a lots of free and valuable personal information about customers.</p>
<p>Delta’s SkyMiles scheme is one of the largest globally with 25 M active members. There are two ways points schemes generate money: 1) when scheme member buy a regular ticket, they also buy mileage credit they can redeem in the future, and 2) they make money from card companies (such as American Express) and other partners. </p>
<blockquote>
<p><strong>VC Says “Chaos” Coming for Startups, Ads, and Online Business as Generative AI Eats Web - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/vc-says-chaos-coming-for-startups">Link</a>]</p>
</blockquote>
<p>The main point is that, as generative AI is ingested into the web, a decades-old system of online referrals and business building will be reshaped. The business model of every existing business (online travel, ecommerce, online advertising, etc) on the internet are impacted due to the transformation of online search by AI. It decreases the number of customer’s impressions on the internet thus reduce advertiser’s chance of being charged. And it also reduces the chance for startups to be observed and build brands. </p>
<blockquote>
<p><strong>OpenAI: $80 Billion - Trendline</strong> [<a target="_blank" rel="noopener" href="https://getthetrendline.substack.com/p/openai-80-billion">Link</a>]</p>
</blockquote>
<p>So top 10 most valuable unicorns are 1) ByteDance, 2) SpaceX, 3) OpenAI, 4) SHEIN, 5) Stripe, 6) Databricks, 7) Revolut, 8) Fanatics, 9) Canva, 10) Epic Games</p>
<blockquote>
<p><em>Nvidia’s four largest customers each have architectures in progress or production in different stages:</em> </p>
<ol>
<li><em>Google Tensor</em></li>
<li><em>Amazon Inferentium and Trainium</em></li>
<li><em>Microsoft Maia</em></li>
<li><em>Meta MTIA</em></li>
</ol>
<p><strong>― What’s all the noise in the AI basement? - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/whats-all-the-noise-in-the-ai-basement?utm_source=/inbox/saved&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>Current situation of players in semiconductor industry in the context of AI competition.</p>
<blockquote>
<p><strong>Big 4 Visualized - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/big-4-visualized">Link</a>]</p>
</blockquote>
<p>The four titans of accounting industry - Deloitte, PwC, EY, and KPMG. They make money from 1) audit: verifying financial statement, 2) assurance: including processes, internal control, cybersecurity assessments, and fraud investigations, 3) consulting: offering advice on everything from M&amp;A to digital transformation, especially in helping enterprise software sales, 4) risk adn tax advisory: navigating compliance, regulations, and tax laws.</p>
<p>Insights:</p>
<p>Deloitte: 1) fastest growing in revenue, 2) heavily investing in AI and digital transformation, 3) acquisition as a growth strategy.</p>
<p>PwC: 1) heavily investing $1B in Gen AI initiative with Microsoft, 2) will become the largest customer and 1st reseller of OpenAI’s enterprise product, 3) leader of financial services sector, serving most global banks and insurers, 4) has faced scrutiny over its audit of the failed cryptocurrency exchange FTX, raising concerns about its risk management practices.</p>
<p>EY: 1) invested $1.4B to create EY.ai EYQ, an AI platform and LLM, 2) abandoned its “Project Everest” plan to split it audit and consulting businesses in 2023, 3) growing business through strategic acquisitions, 4) has faced criticism for an about $2B hole in its accounts, raising concerns about its audit practices and risk management, 5) was fined $100M because hundreds of employees cheated on ethics exams.</p>
<p>KPMG: 1) focusing on digital transformation (data analytics, AI, and cybersecurity), 2) has faced regulatory scrutiny and fines due to audit practices, raising concerns about its audit quality and independence.</p>
<blockquote>
<p><em>I think the release highlights something important happening in Al right now: experimentation with four kinds of models - Al models, models of use, business models, and mental models of the future. What is worth paying attention to is how all the Al giants are trying many different approaches to see what works.</em></p>
<p><em>This demonstrates a pattern: the most advanced generalist Al models often outperform specialized models, even in the specific domains those specialized models were designed for.</em></p>
<p><em>That means that if you want a model that can do a lot - reason over massive amounts of text, help you generate ideas, write in a non-robotic way - you want to use one of the three frontier models: GPT-40, Gemini 1.5, or Claude 3 Opus.</em></p>
<p><em>The potential gains to AI, the productivity boosts and innovation, along with the weird risks, come from the <a target="_blank" rel="noopener" href="https://www.oneusefulthing.org/p/superhuman">larger, less constrained models</a>. And the benefits come from figuring out how to apply AI to your own use cases, even though that takes work. Frontier models thus have a very different approach to use cases than more constrained models. Take a look at this <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=wfAYBdaGVxs">demo, from OpenAI, where GPT-4o (rather flirtatiously?) helps someone work through an interview,</a> and compare it to <a target="_blank" rel="noopener" href="https://youtu.be/Q_EYoV1kZWk?si=lspCJUSZed9se-QR">this demo of Apple’s AI-powered Siri</a>, helping with appointments. Radically different philosophies at work.</em></p>
<p><strong>― What Apple’s AI Tells Us: Experimental Models⁴ - One Useful Thing</strong>  [<a target="_blank" rel="noopener" href="https://www.oneusefulthing.org/p/what-apples-ai-tells-us-experimental">Link</a>]</p>
</blockquote>
<ol>
<li><p>Al Models: Apple does not have frontier model like Google and Microsoft do, but they have created a bunch of small models that are able to run on Al-focused chips in their products. The medium-sized model that can be called by iPhone in the cloud. The model that’s running on iPhone and the model that’s running in the cloud are as good as Mistral’s and ChatGPT.</p>
</li>
<li><p>Models of Use: However, larger, less constrained models are the potential gains to Al, the productivity boosts and innovation. You would prefer to use GPT-4o to do nuanced tasks such as helping with your interviews rather than use Apple Al-powered Siri.</p>
</li>
<li><p>Business Models: Apple sounds like they will start with free service as well, but may decide to charge in the future. The truth is that everyone is exploring this space, and how they make money and cover costs is still unclear (though there is a lot of money out there. People don’t trust Al companies because they are concerning about privacy. However Apple makes sure models cannot learn about your data even if it wanted to. Personal data on your iPhone are only accessed by local Al.</p>
<p>And those handed to the cloud is encrypted. For those data given to OpenAl, it’s anonymous and requires explicit permission. Apple is making very ethical use of Al. Though we should still be cautious about Apple’s training data.</p>
</li>
<li><p>Models of the Future: Apple and OpenAl have different goals. Apple is building narrow Al systems that can accurately answer questions about your personal data. While OpenAl is building autonomous agents that would complete complex tasks for you. In comparison, Apple has a clear and practical vision of how Al can be applied, while the future OpenAl’s AGI remains to be seen.</p>
</li>
</ol>
<blockquote>
<p><em>Elon has been spreading significant FUD by threatening to prohibit Apple devices at his companies. The truth is Apple at no point will be sending any of your data to OpenAI without explicit user permission. Even if you opt for “Use ChatGPT” for longer questions, OpenAI isn’t allowed to store your data.</em></p>
<p><em>According to Counterpoint Research, smartphone makers who have launched AI features on their smartphones have seen a revival in sales. Look at Samsung for example, where its S24 series grew 8% compared to S23 in 2024 with sales for its mid-range premium model growing 52% YoY. With Apple having a larger market share, along with receding expectations for an economic recession, this could be the start of a new growth chapter for the Cupertino darling once again.</em></p>
<p><em>Pete Huang at <a target="_blank" rel="noopener" href="https://www.theneurondaily.com/">The Neuron</a> explains in a step by step process of what really goes down when you ask Siri with AI a question.</em></p>
<ol>
<li><p><em>For almost all questions, Siri uses AI that lives on the device, aka it won’t need to hit up the cloud or ChatGPT, aka your question won’t ever leave the phone.</em></p>
<ul>
<li><em>These on-device models are decent (they’re built on top of open-source models) and outperform Google’s on-device model, Gemma-7B, 70% of the time.</em></li>
</ul>
</li>
<li><p><em>For more complex questions like “Find the photo I took at the beach last summer,” Siri will consult a smarter AI model that runs on Apple’s servers.</em></p>
<ul>
<li><em>When Siri sends your question to Apple’s servers, your data is anonymized and not stored there forever.</em></li>
</ul>
</li>
<li><p><em>Now, for longer questions like “Can you help me create a weekly meal plan?” or “Rewrite this email using a more casual tone,” Siri will use ChatGPT only if you give it permission to.</em></p>
<ul>
<li><em>Even if you opt for “Use ChatGPT,” OpenAI isn’t allowed to store your data.</em></li>
</ul>
</li>
</ol>
<p><strong>― The Real Test For Consumer’s AI Appetite Is About To Begin - The Pragmatic Optimist</strong> [<a target="_blank" rel="noopener" href="https://amritaroy.substack.com/p/consumers-ai-appetite-will-be-tested">Link</a>]</p>
</blockquote>
<p>Interested to know how it actually works when you ask Siri with AI a question.</p>
<blockquote>
<p><strong>5 Founder-Led Businesses - Invest in Quality</strong> [<a target="_blank" rel="noopener" href="https://www.investinassets.net/p/5-founder-led-businesses">Link</a>]</p>
</blockquote>
<p>Three research findings:</p>
<ol>
<li>Founder-led businesses outpaced other companies by a wide margin. (Researched by Ruediger Fahlenbrach in 2009).</li>
<li>Family-owned businesses ignored short-term quarterly numbers to focus on the long-term value creation, which lead to a major outperformance because of 1) lower risk-taking in the short term, and 2) greater vision and investment for the long term. (Researched by Henry McVey in 2005).</li>
<li>Businesses managed by billionaires outperformed the market by 7% annually from 1996 to 2011. (researched by Joel Shulman in 2012).</li>
</ol>
<p>Insights behind the findings above:</p>
<ol>
<li>Founders and owners often have their life savings invested in the shares of the business, so they have the incentive aligned.</li>
<li>Bureaucracy reduces business performance. They will almost never make a radical shift, because politicians care more about their job title than the long term prospects of the business. Founders on the other hand are able to make radical decisions and overrule the bureaucracy, therefore they can take the business in a direction to fulfill long term vision. </li>
<li>Founders and billionaires are exceptional people to run business.</li>
</ol>
<p>The article listed five examples of founder-led businesses: MercadoLibre, Adyen, Fortinet, Intercontinental Exchange, and Paycom. </p>
<blockquote>
<p><em>This move positions Apple as an AI aggregator, offering users a curated selection of the best AI tools while keeping their data private. It’s a win-win. Apple gets to enhance its user experience with powerful AI capabilities. At the same time, OpenAI gains access to Apple’s massive user base for brand recognition and potential upsell to ChatGPT Plus. There is no detail available on the exact terms of the partnership.</em></p>
<p><strong>― Apple: AI for the Rest of Us - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/apple-ai-for-the-rest-of-us">Link</a>]</p>
</blockquote>
<p>Integrating ChatGPT alongside Apple Intelligence features is a smart move that allows Apple to focus on their strengths (privacy, personalization) while leveraging general knowledge AI from OpenAI. This will enable Apple to blame any wrong answers and hallucinations on the LLMs the company partners with and stay out of PR trouble. </p>
<blockquote>
<p><strong>The Other Side of the Trade - The Rational Walk</strong> [<a target="_blank" rel="noopener" href="https://rationalwalk.com/the-other-side-of-the-trade/">Link</a>]</p>
</blockquote>
<p>An ethical implication about taking advantage of a glitch caused by software malfunction.</p>
<blockquote>
<p><em>I have noticed the proliferation of a different type of species in academia: what I call The Failed Corporatist. This is someone who stumbles upon academia not so much out of a love for The Truth, as due to an inability to thrive in corporate settings for various other, unrelated reasons. But the Failed Corporatist has a very conventional, corporate like mindset anyway. It usually loves process, admin and adding more admin and adding more process and METRICS and social conformity. This skill set enables them to ascend the ranks of academic administration, often gaining significant influence and control over The Weird Nerd. Confronted with this altered habitat, The Nerd often finds itself in a state of distress and confusion. Its intrinsic motivation clashes with the newly imposed corporate-like order and the demand for conformity, leading to frantic efforts to assert its natural tendencies. Unfortunately, these efforts are often met with resistance or outright rejection, not only from The Failed Corporatist but also from the broader world that the academic reserve is a part of. All in all, I think this disturbance means the remaining Nerds are further driven away.</em></p>
<p><strong>― The flight of the Weird Nerd from academia - Ruxandra’s Substack</strong> [<a target="_blank" rel="noopener" href="https://www.writingruxandrabio.com/p/the-flight-of-the-weird-nerd-from">Link</a>]</p>
<p><em>A couple of months ago I wrote a piece called <a target="_blank" rel="noopener" href="https://www.writingruxandrabio.com/p/the-flight-of-the-weird-nerd-from">“The flight of the Weird Nerd from academia”</a>, in which I argued there is a trend wherein Weird Nerds are being driven out of academia by the so-called Failed Corporatist phenotype. Katalin Karikó is a perfect example of a Weird Nerd. I recently argued that many Weird Nerds (I called them autistics, but people really hated that<a target="_blank" rel="noopener" href="https://www.writingruxandrabio.com/p/the-weird-nerd-comes-with-trade-offs?utm_source=/inbox/saved&utm_medium=reader2#footnote-2-144974567">2</a>), have <a target="_blank" rel="noopener" href="https://www.writingruxandrabio.com/p/autism-and-the-internet-will-defeat">found a refuge on the Internet</a>, where their strengths are amplified and their weaknesses are less important.</em> </p>
<p><em>And I believe the conversation here starts with accepting a simple truth, which is that Weird Nerds will have certain traits that might be less than ideal, that these traits come “in a package” with other, very good traits, and if one makes filtering or promotion based on the absence of those traits a priority, they will miss out on the positives. It means really internalizing the existence of trade-offs in human personality, in an era where accepting trade-offs is deeply unfashionable, and structuring institutions and their cultures while keeping them in mind.</em></p>
<p><em>Everything comes at a cost: spend more time worrying about politics, there will be less time for science. What’s more, the kind of people who really care about science or truth to the extent that Karikó did, are not the same people that get motivated by playing politics or being incredibly pleasant. There is a strong anti-correlation between these interests (that of course does not mean there is no one who is good at both.) Selecting future intellectuals based on traits like Agreeableness or Extraversion might not be only unnecessary, but actually harmful. We might be actively depleting the talent pool of the kind of people we do want to see in academic institutions.</em></p>
<p><strong>― The Weird Nerd comes with trade-offs - Ruxandra’s Substack</strong> [<a target="_blank" rel="noopener" href="https://www.writingruxandrabio.com/p/the-weird-nerd-comes-with-trade-offs">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>The intersection of AI with the ocean of mass surveillance data that’s been building up over the past two decades is going to put truly terrible powers in the hands of an unaccountable few. - <a target="_blank" rel="noopener" href="https://x.com/Snowden/status/1801792686724182242">Edward Snowden</a></em></p>
<p><em>The former head of the NSA may be a great guy. But you don’t put the former head of the NSA on your board (as OpenAI just did) because he’s nice. You put him there to signal that you’re open to doing business with the IC and DoD. - <a target="_blank" rel="noopener" href="https://x.com/matthew_d_green/status/1801649274398163166">Matthew Green</a></em></p>
<p><strong>― Is OpenAI an AI Surveillance Tool?</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/is-openai-an-ai-surveillance-tool">Link</a>]</p>
</blockquote>
<p>OpenAI hired retired US Army general Paul M. Nakasone to its board of directors. This fact raises an issue of trust and makes people question where this leads to.</p>
<blockquote>
<p><strong>Adobe: Expanding Universe - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/adobe-expanding-universe">Link</a>]</p>
</blockquote>
<p>Adobe is one of the companies potentially most disrupted by Gen AI but it turns out to be one of the fastest to capitalize on the technology. Adobe benefits the most from AI as they incorporate it in all layers of their existing stack.</p>
<p>Revenue has three main segments: 1) 74% digital media (creative cloud including Adobe express, document cloud including adobe acrobat), 2) 25% digital experience, 3) publishing and advertising (1%).</p>
<p>New AI powered product: 1) GenStudio platform is a new Gen AI powered tool aiming to streamline the entire content creation process. It’s announced at Adobe Summit 2024 in March and expected to launch in Q3 2024. It will be integrated into Adobe Experience Cloud plans or offered as a standalone product. 2) Adobe Experience Platform AI Assistant is a natural language chatbot. 3) Adobe Experience Manager is a tool to deliver right content to users at the right time. 4) Adobe Content Analytics gives access to tools to measure the marketing performance of AI created content, 4) Acrobat AI Assistant was integrated into Adobe Acrobat Reader. Others: 1) Firefly Services, 2) Adobe Express on mobile, etc.</p>
<blockquote>
<p><em>One thing is clear: the future of fast food will be shaped by brands that can adapt to the changing landscape and evolve through savvy marketing, new menus, and the boost of tech to prepare and deliver your favorite meal.</em></p>
<p><strong>― Fast Food Economics - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/fast-food-economics">Link</a>]</p>
</blockquote>
<p>Quick-service restaurant (QSR) industry is undergoing a shift. This article helps to understand how QSR giants navigates a landscape of soaring inflation, labor shortages, and ever-changing consumer tastes.</p>
<p>Giants: </p>
<ol>
<li>McDonald: primary as a real estate company with majority of revenue from franchised restaurants paying rent and royalties. Working on offering more compelling value deals, menu innovation, digital sales and MyMcDonald’s rewards program, growth plan of reaching 50000 restaurants globally by 2027 and doubling sales from its loyalty program. </li>
<li>Chipotle: digital platform works well, great menu that worths growing prices, rewards program members shows an impressive loyal and boosting sales, testing its new automated digital makeline and food prep robot ‘Autocado’.</li>
<li>YUM! (KFC, Taco Bell, Pizza Hut, Habit Burger Grill): Taco Bell is proved resilient and popular. KFC and Pizza Hut are experiencing sales decline. Digital delivers and sales are bright, proving their investment in online ordering, delivery, and AI-powered drive-thru tech are successful.</li>
<li>Restaurant Brand International (RBI) (Tim Hortons, Burger King, Popeyes, Firehouse Subs): Burger King’s investment in store renovations, menu innovations, marketing campaigns since 2022 are paying off. The coffee and donut chain performs reliably especially in its home market of Canada. Popeyes continues strong store sales growth. The main component of RBI’s growth strategy is digital transformation.</li>
</ol>
<blockquote>
<p><strong>Broadcom: AI Surge - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/broadcom-ai-surge">Link</a>]</p>
</blockquote>
<p>Broadcom operates across two primary segments: 1) semiconductor solutions, which has traditionally been Broadcom’s core strength, and 2) infrastructure software, which was propelled since acquisition of VMware in 2023 Nov. </p>
<p>Highlights: 1) $3.1B (roughly 26% of all) in revenue is from AI products. AI alone contributed to a $2.2B revenue increase year over year. 2) Margins were down year over year significantly, primarily due to expenses related to VMware integration. 3) Broadcom has a gigantic net debt position of $62B. 4) strong cash generation - $18 B in past 12 months. 5) 10-for-1 stock split will happen in July 15. 6) it’s known for regular cadence of product introduction - Tomahawk and Jericho switching products.</p>
<blockquote>
<p><em>AI is both a threat and an opportunity for software leaders. But for cybersecurity giants, AI means business. New technology means new threats, with Large Language Models (LLMs) dealing with vast amounts of data in the cloud and on devices.</em></p>
<p><strong>― Cybersecurity Earnings - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/cybersecurity-earnings">Link</a>]</p>
</blockquote>
<p>AI tech stack has 3 layers: 1) top: Apps or enterprise software, 2) middle: LLMs, 3) bottom: compute hardware and chips. The bottom layer (NVIDIA, AMD, ASML, TSMC) and middle layer (AWS, Azure, Google Cloud) have already benefitted from AI revenue boost. However it usually takes longer time to manifest because companies take time to adapt to new ways of optimizing processes, particularly in ERP, CRM, and BI verticals.</p>
<p>There is sentiment around enterprise software saying that AI would make the cost of software go to zero. But there are also some counterarguments: 1) the main expense for most software companies is not R&amp;D but sales and marketing, 2) switching cost is high enough that even freemium software is not able to disrupting existing solutions, 3) resources needed to develop new features will decline, 4) implementing and maintaining a software solution is costly.</p>
<p>This article shows how some of the cybersecurity companies are navigating current environment.</p>
<p>Highlights:</p>
<ol>
<li><p>Palo Alto Networks</p>
<p>Strong strength and rapid growth in Next-Gen Security (NGS) offerings. Its platformization focus and one-stop shop for security needs include cloud-delivered security services like Prisma Access (SASE), Prisma Cloud (cloud security), and Cortex (security operations). It’s facing billing issues: it’s slashing its FY24 billings guidance by $600M.</p>
</li>
<li><p>CrowdStrike</p>
<p>Strong Q1 performance, lower Total Cost of Ownership (TCO) due to  lightweight agent and unified approach, $4B in ARR growing at over 30% YoY.</p>
</li>
<li><p>Fortinet</p>
<p>It specializes in network security appliances, secure SD-WAN, and operational tech security. It’s hardware-centric. And it’s currently under competitive pressure.</p>
</li>
<li><p>Zscaler</p>
<p>It specializes in Zero Trust solutions, a security model that assumes no user or device should be trusted by default. It has strong growth and optimistic outlook. It’s riding the wave of increasing cybersecurity demand. And it current has a rumor of Broadcom acquisition.</p>
</li>
<li><p>Cloudflare</p>
<p>Descipte beating earnings estimates in Q1 FY24, stock price has dropped due to concerns about its conservative guidance. Although there is short term headwind, long term growth is still promising.</p>
</li>
</ol>
<blockquote>
<p><strong>AI may take longer to monetize than most expect. How long will investor optimism last? - The Pragmatic Optimist</strong> [<a target="_blank" rel="noopener" href="https://amritaroy.substack.com/p/ai-may-take-longer-to-monetize-than">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Dark Stain on Tesla’s Directors - Lawrence Fossi</strong> [<a target="_blank" rel="noopener" href="https://montanaskeptic.substack.com/p/the-dark-stain-on-teslas-directors">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>2,596 - How to make the most out of Google’s leaked ranking factors</strong> [<a target="_blank" rel="noopener" href="https://www.growth-memo.com/p/2596">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Ramp and the AI Opportunity</strong> [<a target="_blank" rel="noopener" href="https://www.notboring.co/p/ramp-and-the-ai-opportunity">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Perplexity builds product</strong> [<a target="_blank" rel="noopener" href="https://www.lennysnewsletter.com/p/how-perplexity-builds-product">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>IBM’s Evolution of Qiskit</strong> [<a target="_blank" rel="noopener" href="https://www.thequantumfoundry.com/p/ibms-evolution-of-qiskit">Link</a>]</p>
</blockquote>
<h3 id="Articles-and-Blogs"><a href="#Articles-and-Blogs" class="headerlink" title="Articles and Blogs"></a>Articles and Blogs</h3><blockquote>
<p><em>Today, foundries manufacture supermajority of the chips produced in the world, and Taiwan Semiconductor Manufacturing Company (<strong>TSMC</strong>) alone has ~60% market share in the global foundry market.</em></p>
<p><em>Perhaps more astonishingly, TSMC has a de-facto monopoly with <strong>~90%</strong> market share in the leading edge nodes (manufacturing processes with the smallest transistor sizes and highest densities). Leading edge nodes are crucial for applications requiring the highest computing performance like supercomputers, advanced servers, high-end PCs&#x2F;laptops, smartphones, AI&#x2F;machine learning, and military&#x2F;defense systems. As a result, the very basic tenet of modern life is essentially standing on the shoulders of one company based in Taiwan.</em></p>
<p><strong>― TSMC: The Most Mission-Critical Company on Earth</strong> [<a target="_blank" rel="noopener" href="https://www.mbi-deepdives.com/tsm/">Link</a>]</p>
</blockquote>
<p>This is a deep dive report of Taiwan Semiconductor Manufacturing Company (TSMC).</p>
<blockquote>
<p><em>In terms of next steps, Google has “limited the inclusion of satire and humor content” as part of “better detection mechanisms for nonsensical queries.” Additionally:</em></p>
<ul>
<li><em>“We updated our systems to limit the use of user-generated content in responses that could offer misleading advice.”</em></li>
<li><em>“We added triggering restrictions for queries where AI Overviews were not proving to be as helpful.”</em></li>
<li><em>“For topics like news and health, we already have strong guardrails in place. For example, we aim to not show AI Overviews for hard news topics, where freshness and factuality are important. In the case of health, we launched additional triggering refinements to enhance our quality protections.”</em></li>
</ul>
<p><strong>― Google explains AI Overviews’ viral mistakes and updates, defends accuracy</strong> [<a target="_blank" rel="noopener" href="https://9to5google.com/2024/05/30/google-ai-overviews-accuracy/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The AI Revolution Is Already Losing Steam</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/the-ai-revolution-is-already-losing-steam-a93478b1">Link</a>]</p>
</blockquote>
<p>It remains questions whether AI could become commoditized, whether it has potential to produce revenue and profits, and whether a new economy is actually being born.</p>
<p>According to Anshu Sharma, the future of AI startups (OpenAI and Anthropic) could be dim, and big tech companies (Microsoft and Google) will make profits from existing users and networks but need to spend a lot of money for a long time, which would leave the AI startups unable to compete. This is true that AI startups are already struggling right now, because at current stage AI is hard to commoditized, and it requires a lot of investments.</p>
<p>The improvement of AI is slowing down because they exhausted all available data on the internet. Regarding the adoption of AI in enterprise, time is required to make sure that chatbots can replace the specialized knowledge of human experts due to technical challenges.</p>
<blockquote>
<p><em>One thing we’ve learned: the business goal must be paramount. In our work with clients, we ask them to identify their most promising business opportunities and strategies and then work backward to potential gen AI applications. Leaders must avoid the trap of pursuing tech for tech’s sake. The greatest rewards also will go to those who are not afraid to think big. As we’ve observed, the leading companies are the ones that are focusing on reimagining entire workflows with gen AI and analytical AI rather than simply seeking to embed these tools into their current ways of working.  For that to be effective, leaders must be ready to manage change at every step along the way. And they should expect that change to be constant: enterprises will need to design a gen AI stack that is robust, cost-efficient, and scalable for years to come. They’ll also need to draw on leaders from throughout the organization. Realizing profit-and-loss impact from gen AI requires close partnership with HR, finance, legal, and risk to constantly readjust the resourcing strategies and productivity expectations. - Alex Singla</em></p>
<p><em>Although it varies by industry, roughly half of our survey respondents say they are using readily available, off-the-shelf gen AI models rather than custom-designed solutions. This is a very natural tendency in the early days of a new technology—but it’s not a sound approach as gen AI becomes more widely adopted. If you have it, your competitor probably has it as well. Organizations need to ask themselves: What is our moat? The answer, in many cases, likely will be customization. - Alexander Sukharevsky</em> </p>
<p><strong>― The state of AI in early 2024: Gen AI adoption spikes and starts to generate value - McKinsey</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai?stcr=D65B59511D5A4090A48ACEA19F2A2068&cid=other-eml-alt-mip-mck&hlkid=663b07a2cb3546e4a8a439ebd78d5ef0&hctky=14527191&hdpid=4e5b39a9-b017-49dc-bc7c-df8a492b551a">Link</a>]</p>
</blockquote>
<p>Industries are struggling with budgeting for Gen AI. There are some areas where investments are paying off, such as meaningful cost reductions in HR and revenue increases in supply chain management from Gen AI.</p>
<p>There are varies risks of Gen AI usage: data privacy, bias, intellectual property (IP) infringement, model management risks, security and incorrect use, etc. Among all, inaccuracy and intellectual property infringement ar eincreasingly considered relevant risks to organizations’ Gen AI use.</p>
<p>According to the three archetypes for implementing Gen AI solutions (takers, shapers, and makers), survey has found that in most industries, organizations are finding off-the-shelf offerings applicable to their business needs, about half of reported Gen AI uses publicly available models or tools with little or no customization. Respondents in energy and materials, technology, and media and telecommunications are more likely to report significant customization or tuning of publicly available models or developing their own proprietary models to address specific business needs.</p>
<p>The time required to put Gen AI to production for most of the respondents is around 1-4 months.</p>
<p>Gen AI high performers are excelling. Some common characteristics or practices: 1) They are using Gen AI in more business functions (an average of 3) compared to others average 2,  2) They are more likely to use Gen AI in marketing and sales and product or service development like others, but they are more likely than other s to use Gen AI solutions in risk, legal, and compliance; in strategy and corporate finance; and in supply chain and inventory management, 3) They are three times as likely as others to be using Gen AI in activities ranging from processing of accounting doc and risk assessment to R&amp;D testing and pricing and promotions, 4) They are less likely to use those off-the-shelf options than to either implement significantly customized version to develop their own proprietary foundation models, 5) encountered challenges with their operating model.</p>
<blockquote>
<p><em>Asian Americans are crucial in today’s knowledge economy: around <a target="_blank" rel="noopener" href="https://www.wsj.com/lifestyle/careers/employers-open-more-doors-to-workers-without-degrees-but-few-are-getting-in-732f1098">60% hold at least a bachelor’s degree</a> and, despite representing only <a target="_blank" rel="noopener" href="https://www.pewresearch.org/short-reads/2021/04/29/key-facts-about-asian-americans/">about 7% of the U.S. population</a>, account for <a target="_blank" rel="noopener" href="https://www.eeoc.gov/special-report/diversity-high-tech">50% of the workforce</a> in leading Silicon Valley tech companies.</em></p>
<p><em>A detailed analysis of top Fortune 500 technology companies shows that Asian professionals are even <a target="_blank" rel="noopener" href="https://www.linkedin.com/pulse/more-diverse-less-equitable-api-leadership-pipeline-large-buck-gee-iyatc/">less likely to progress in their careers today than they were a decade ago</a>.</em></p>
<p><strong>― Stop Overlooking the Leadership Potential of Asian Employees - Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/06/stop-overlooking-the-leadership-potential-of-asian-employees">Link</a>]</p>
</blockquote>
<p>This article talked about the reasons why Asian employees’ careers stagnate, solutions for the organization to help employees move past the roadblock, and reasons of investment in Asian employees.</p>
<blockquote>
<p><strong>How to do great work</strong> [<a target="_blank" rel="noopener" href="https://www.paulgraham.com/greatwork.html">Link</a>]</p>
</blockquote>
<p>A good summary of this great article:</p>
<p><img src="/digital-di/./images/greatwork.jpg" alt="greatwork"></p>
<blockquote>
<p><strong>Introducing Apple’s On-Device and Server Foundation Models</strong> [<a target="_blank" rel="noopener" href="https://machinelearning.apple.com/research/introducing-apple-foundation-models">Link</a>]</p>
</blockquote>
<p>This article provides details about how Apple developers trained models, fine-tuned adapters for specific user needs, and evaluated model performance.</p>
<blockquote>
<p><em>The analogy here is to Search, another service that requires astronomical investments in both technology and infrastructure; Apple has never built and will never need to build a competitive search engine, because it owns the devices on which search happens, and thus can charge Google for the privilege of making the best search engine the default on Apple devices. This is the advantage of owning the device layer, and it is such an advantageous position that Apple can derive billions of dollars of profit at essentially zero cost.</em></p>
<p><em>First, with regards to the title of this Article, the fact it is possible to be too early with AI features, as Microsoft seemed to be in this case, implies that not having AI features does not mean you are too late. Yes, AI features could differentiate an existing platform, but they could also diminish it. Second, Apple’s orientation towards prioritizing users over developers aligns nicely with its brand promise of privacy and security: Apple would prefer to deliver new features in an integrated fashion as a matter of course; making AI not just compelling but societally acceptable may require exactly that, which means that Apple is arriving on the AI scene just in time.</em></p>
<p><strong>― Apple Intelligence is Right On Time - Stratechery</strong> [<a target="_blank" rel="noopener" href="https://stratechery.com/2024/apple-intelligence-is-right-on-time/">Link</a>]</p>
</blockquote>
<p>This article worths a read. It famously talks about Aggregation Theory as applied to the internet, and predicted much of how the Google&#x2F;Facebook age unfolded through that lens. This is one main reason why winners are still old players in AI era at least for now. </p>
<blockquote>
<p><strong>How to Fund Growth (&amp; when not to)</strong> [<a target="_blank" rel="noopener" href="https://www.cfosecrets.io/p/capital-allocation-funding-growth">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>So You Want To Build A Browser Engine</strong> [<a target="_blank" rel="noopener" href="https://robert.ocallahan.org/2024/06/browser-engine.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs</strong> [<a target="_blank" rel="noopener" href="https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>What matters most? Eight CEO priorities for 2024 - McKinsey</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/what-matters-most-eight-ceo-priorities-for-2024?stcr=394A106D8BD3483F97F8ED2B6AF5EC98&cid=other-eml-alt-mip-mck&hlkid=411e594200b247bfb3abfce66520ad22&hctky=14527191&hdpid=97189783-1eb7-45dc-af69-cc1fdb6f90c1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Gen AI’s second wave - McKinsey</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/quarterly/the-five-fifty/five-fifty-gen-ais-second-wave">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Extracting Concepts from GPT-4 - OpenAI</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/extracting-concepts-from-gpt-4/">Link</a>]</p>
</blockquote>
<p>OpenAI presents new approach to interpret concepts captured by GPT-4’s neural networks. They used sparse autoencoder to make sense of neural activity within LLMs and found 16 million features in GPT-4. Limitations are 1) hard to interpret, 2) no good way to check the validity of interpretations, 3) not all behaviors are captured, 4) challenging to scale to frontier LLMs.</p>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><em>In an H100 GPU, every second we can move at most 3.35 terabytes of RAM in and out of memory registers. And in the same second, we can multiply 1.98 quadrillion 8bit floating point numbers. This means that it can do 591 floating point operations in the time it takes to move one byte. In the industry this is known as a 591:1 ops:byte ratio. In other words, if you are going to spend time moving an entire gigabyte around you should do at least 591 billion floating point operations. If you don’t, you are just wasting GPU and potential compute. But if you do more than that, you are just waiting around on memory bandwidth to get your data in there. In our models, the amount of memory we need to move around is relatively fixed, it’s roughly the size of our model. This means that we do have some control over on how much math that we can do by changing our batch size.</em> </p>
<p><em>In reality, we’ve discovered that bottleneck can arise from everywhere from memory bandwidth, network bandwidth between GPUs, between nodes, and other areas. Furthermore the location of those bottlenecks will change dramatically on the model size, architecture, and usage patterns.</em></p>
<p><strong>― Behind the scenes scaling ChatGPT - Evan Morikawa at LeadDev West Coast 2023</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=PeKMEXUrlq4&ab_channel=LeadDev">Link</a>]</p>
</blockquote>
<p>This is a behind the scenes look at how OpenAI scaled ChatGPT and the OpenAI APIs. But also a very good talk to show how hard it is to scale infrastructure for model architecture etc, and how important it is to master these skills and knowledge in chip manufacture and design industry and in LLM development industry. The talk covers 1) GPU RAM and KV Cache, 2) batch size and ops:bytes, 3) scheduling in dozens of clusters, 4) autoscaling (and the lack thereof). </p>
<p>Key facts to consider when developing metrics for compute optimization and model scaling:</p>
<ol>
<li>GPU memory is valuable. But it is frequently a bottleneck, not necessarily compute.</li>
<li>Cache misses are non linear on compute, because we suddenly need to start recomputing all stuff.</li>
</ol>
<p>When scaling ChatGPT, we need to:</p>
<ol>
<li>Look at KV cache utilization and maximize all the GPU RAM we have, and </li>
<li>Monitor batch size - the number of concurrent requests we run to the GPU at the same time, to ensure the GPUs are fully saturated. These are two main metrics used to determine how loaded our servers were.</li>
</ol>
<p>In reality, there are more bottlenecks (memory bandwidth, network bandwidth between GPUs, between nodes, and other areas) and the location where they arise can change according to the model size, architecture, and usage patterns. The variability has made it very hard for AI model developer and chip manufactures to design chips to get that balance right. Future ML architectures and sizes have been very difficult to predict. But overall we need to be tweaking this math as the models evolve. </p>
<p>The third challenge is to find enough GPUs. Note that the time of a response is dominated by the GPU streaming out one token at a time, as a result, it’s been more important to just get capacity and optimized a well balanced fleet, over putting things geographically close to users.</p>
<p>The fourth challenge is the inability to scale up this fleet. OpenAI has delayed some feature of ChatGPT due to the limitation of compute resources.</p>
<p>Some lessons they have learned in solving GPU challenges: </p>
<ol>
<li>It’s important to treat this as a system engineering challenge as opposed to a pure research project. </li>
<li>It’s important to adaptively factor in the novel constraints of these systems. </li>
<li>Every time model architecture shifts, a new inference idea is proposed or a product decision is changed, we need to adapt and rerun a lot of this math again. Diving really deep has been important. This low level of implementation details matter.</li>
</ol>
<p>The final challenge is abuse on the system and AI safety challenges.</p>
<blockquote>
<p><em>For many years, particularly following the original SARS pandemic, there was a lot of conversations around how do we get in front of the next pandemic, how do we figure out what’s coming and how do we prepare for it. And there was a lot of research that was launched to try and resolve that key question. It’s like does the effort to try and stop the problem cause the problem. I think that from my point of view there is a very high probability that there was some leak that meant that the work that was going on to try and get in front of the next pandemic and understand what we could do to prepare ourselves, and what vaccines could be developed and so on, actually led to the pandemic. So then when that happens how do you respond when you are sitting in that seat, that’s the key question that I think this committee is uncovering. - David Friedberg</em></p>
<p><strong>― Trump verdict, COVID Cover-up, Crypto Corner, Salesforce drops 20%, AI correction? - All-in Podcast</strong>  [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=R6hJh-OwoZw">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The TED AI Show: What really went down at OpenAI and the future of regulation w&#x2F; Helen Toner</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=K6BvU4I5ANc">Link</a>]</p>
</blockquote>
<p>In the interview, Toner revealed that the reason of firing Altman is his psychological abuse and being manipulative in different situation. Looking at Altman’s track record prior to OpenAI, it seems those are not new problems of Sam.</p>
<blockquote>
<p><strong>How Walt Mossberg Built Relationships With Jobs, Gates, and Bezos - Big Technology Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/how-walt-mossberg-built-relationships">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Nvidia’s 2024 Computex Keynote: Everything Revealed in 15 Minutes</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Zgn7KJXVxNk&ab_channel=CNET">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>What really works when it comes to digital and AI transformations? - McKinsey</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-really-works-when-it-comes-to-digital-and-ai-transformations?stcr=8C2EBECC6A7746E78BB590C9D48E31F0&cid=other-eml-alt-mip-mck&hlkid=6c3691cd7890438f920d484bf1e19aaa&hctky=14527191&hdpid=97189783-1eb7-45dc-af69-cc1fdb6f90c1">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>… but what I do take offense at is labeling millions and millions of ordinary Americans as somehow lacking in empathy, lacking in caring, not being a good parents, because you don’t like their support for Trump. And I think that that is a statement that frankly reeks of being cocooned in an elite bubble for way too long. Let me just explain. If you look at where Trump’s support is strongest. It’s really in Middle America and sort of the heartland of America, basically the part of America that the Coastal at least dismissively refer to as flyover country. It’s a lot of the industrial midwest and frankly that part of the country had not had the same type of economic experience that we’ve had in Silicon Valley. They have not been beneficiaries of globalization. If you are in a handful of export industries in America and I’m talking about if you are in Hollywood or you are in Big Finance or you are in Software, then globalization has been great for you, because it has created huge global markets for our products. However, if you are in an industry that has to compete with global exports, then it’s been very bad with you and blue collar workers have been hurt, labor’s been hurt, people who work with their hands have been hurt. They have not benefitted in the same way from the system we’ve had in this country for the last 30 years. So you can understand why they would not be so enchanted with elite thinking. I think to then label those people as lacking in caring or empathy or not being good parents because they haven’t had the same economic ride that you had for the last 30 years and then you are the one who is fighting a legal battle to kick some of those people off the public beach in front of your beach house, and then you are saying they are the ones lacking in empathy, dude, look in the mirror. - David Sacks</em></p>
<p><em>This is the future of how smart reasonable moderate people should make decisions. It is an example. Talking to somebody you disagree with does not make your opinion bastardized, it actually makes your opinion valuable. There are these simple truths to living a productive live that if you want to embrace, you need to find friends that you can trust, even on issues when you disagree, you can hear them out. - Chamath Palihapitiya</em></p>
<p><em>There is no law that defines why you should or shouldn’t buy a security, with respect to the diligence you have individually done, to determine whether the underlying business is worth the price you are paying. The law says, that the business that are listing their securities for public trading have an obligation to make disclosures on their financials and any other material events to the public and they do that through the SEC filing process. That’s all out there. And then what you as an individual will do with it is up you to. - David Friedberg.</em></p>
<p><strong>― DOJ targets Nvidia, Meme stock comeback, Trump fundraiser in SF, Apple&#x2F;OpenAI, Texas stock market - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UuwCy9hmhIE&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Deloitte’s Pixel: A Case Study on How to Innovate from Within - HBR On Leadership Podcast</strong>  [<a target="_blank" rel="noopener" href="https://hbr.org/podcast/2024/06/deloittes-pixel-a-case-study-on-how-to-innovate-from-within">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>WWDC 2024 — June 10 | Apple</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RXeOiIDNNek&t=12s&ab_channel=Apple">Link</a>] [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=sBXdyUA6A88&ab_channel=TheVerge">Short Version</a>]</p>
</blockquote>
<p>Apple’s promising updates on visionOS, iOS, Audio&amp;Home, watchOS, iPadOS, and macOS.</p>
<blockquote>
<p><strong>Let’s reproduce GPT-2 (124M)</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=l8pRSuU81PU&ab_channel=AndrejKarpathy">Link</a>]</p>
</blockquote>
<p>This four hours video guides you to create a fully functional GPT-2 model from scratch. It includes details about model construction, speed optimization, hyperparameter setup, model evaluation, and training.</p>
<blockquote>
<p><strong>Building open source LLM agents with Llama 3</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=j2OAeeujQ9M&ab_channel=LangChain">Link</a>]</p>
</blockquote>
<p>LangChain and Meta uploads new recipes&#x2F;tutorials to build agents that runs locally using LangGraph and Llama 3.</p>
<blockquote>
<p><em>Apple took a shortcut to get here, they partnered with open ai. And this is something that I don’t think they’ve ever really done before at the operating system level. Apple is famous for being vertically integrated, for being a walled garden, for being end to end. They control everything from the chips to the hardware to the operating system, and they don’t let anybody else in, until you are at the App Store Layer. This is allowing somebody in beneath the level of the App Store. This is allowing someone OpenAI to get access to your data, and to control your apps, at the operating system level. Elon pointed out wait a sec what are the privacy implications here. And I think there are major privacy implications. There is simply no way that you are going to allow an AI on your phone to take. Remember Apple in the past has been the advocate for consumer privacy. There is a whole issue of the San Bernardino terrorist where the FBI went to Apple and said we want you to give us back door access to their phone and Apple refused to do it and went to court to defend user privacy. And furthermore, one of Apple’s defenses to the antitrust arguments for allowing sideloading and allowing other apps to get access to parts of the operating system, they’ve always said we can’t do this because it would jeopardize user privacy and user security. Well here they are opening themselves up to OpenAI in a very deep and fundamental way in order to accelerate the development of these features… I think this is going to open Pandora’s box for Apple, because again they’ve proven that they can open up the operating system to a third party now, and who knows what the privacy implications of this are going to be. - David Sacks</em></p>
<p><em>I think there are three numbers that matter: the inflation rate, the growth in GDP, and the cost to borrow. The growth in GDP in the first quarter of 2024 was a lousy - 1.3% on the annualized basis. And even if the rate of inflation came down, we are still inflating the cost of  everything by north of 3%. So the economy is only growing by 1.3% and it costs more than 3% each year to buy stuff. So that means everyone’s spending power is reducing, and our government’s ability to tax is declining, because the economy is only growing by 1.3%. And the most important fact is that the interest rates are still between 4-5% (4.7%). That means that borrowing money costs 4.7%, but the business the economy on average is only growing 1.3%. So just think about that for a second. We have tremendous amount of leverage on businesses on economy on the federal government. That leverage, the cost to pay for that debt is more than 4-5% but you are only growing your revenue by 1.3%. So at some point you cannot make your payments. That is true for consumers, it’s true for enterprises, and it’s true for federal government. The whole purpose of raising rates is to slow the flow of money through the economy. And by slowing the flow of money through the economy, there is less spending which means that you are reducing the demand relative to the supplies, so the cost of things should come down, you should reduce the rate of increasing in the cost of things… There is certainly a shift in the market because what this tells us is that the timeline at which the fed will cut rates is coming is a little bit. So the market is saying okay let’s adjust to lower rates, the 10 year treasury yield has come down a little bit, but we are still in a difficult situation for people, and for businesses. - David Friedberg</em></p>
<p><em>If the revenue of everything combined which is GDP isn’t going faster than the increase in the cost of everything, people, businesses, and government can’t afford their stuff. And that’f fundamentally what is going on right now. What we need to see is a normalization where GDP growth is greater than inflation rate. And as soon as that happens then we have a more normalized and stable economy. So right now things are not stable. There is a lot of difficulty and strain in the system. - David Friedberg</em></p>
<p><em>You had 1.3% GDP growth rate with a 6% of GDP deficit by the government. If the government wasn’t printing so much money, wasn’t over spending, and you were to have a balanced budget, it would be a recession. It would be negative GDP growth if not for the government’s program stimulating the economy. And a lot of jobs you are talking about are government jobs. The government is creating jobs like crazy, not in the private sector but in the public sector, because it is an election year. So there is a lot of political forces proping things up, and I wonder what happens after the election. - David Sacks</em> </p>
<p><strong>― Elon gets paid, Apple’s AI pop, OpenAI revenue rip, Macro debate &amp; Inside Trump Fundraiser - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=NVYMKDiJGcI&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>Energy is high at the beginning with a blackjack! Went through several news and topics: 1) Elon’s comp package approved by shareholders, besties criticized some reneging people, who are really not good ones to do business with, 2) Apple announces “Apple Intelligence” and ChatGPT deal at WWDC, first time of opening up OS to the third party, raising data privacy concerns, 3) OpenAI reportedly hit a $3.4B revenue run rate, 4) state of US economy.</p>
<blockquote>
<p><strong>Leopold Aschenbrenner - 2027 AGI, China&#x2F;US Super-Intelligence Race, &amp; The Return of History</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=zdbVtZIn9IM&ab_channel=DwarkeshPatel">Link</a>]</p>
</blockquote>
<p>An Interview with Leopold Aschenbrenner. Refering to his 165 page essay about AI safety: <a target="_blank" rel="noopener" href="https://situational-awareness.ai/">https://situational-awareness.ai/</a>.</p>
<blockquote>
<p><strong>Private Cloud Compute: A new frontier for AI privacy in the cloud  - Apple Security Research</strong> [<a target="_blank" rel="noopener" href="https://security.apple.com/blog/private-cloud-compute/?utm_source=www.theneurondaily.com&utm_medium=referral&utm_campaign=the-truth-about-apple-intelligence">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>What I learned from all of that, if I look at his mistakes and successes, I learned a couple things. The first is most of the money he’s made by holding onto things, not the momentum trading that he was known for in, in public equities. And number two, he made most of his money buying quality, like quality was very important to his success. And that’s something I’ve taken from him. And I truly believe, like <u>the environment in which you grow up dictates the kind of person and mentality you will have in life</u>. So let me just quickly expand on that. If you grow up during the Great Depression, I would presume you’re focused on saving every penny and looking for cheap. And I think I’m just taking a guess that you’re gonna be much more focused on buying cigar butts in life than you might be on buying the highest quality asset you can find and maybe paying up for. Somehow my father figured out that the <u>real money is in the best businesses and the higher quality assets</u>. And he instilled that in me very early. And sometimes these things look expensive. And so my point earlier is that he taught me very early <u>not to dismiss something that might look expensive on the surface before you do the deep work and really understand what you’re buying and what it’s worth</u>.</em> </p>
<p><em>And the problem that a lot of value investors have, I think, is that they all screen for low p ratios, high dividend yields, you know, low ev to cash flows, what whatever it is. They’re screening and they will miss because the kind of any value in that area is gonna get competed away. And so I’m more interested in businesses that might look expensive on the surface, but actually aren’t, and you have to be careful because a lot actually are expensive, right? And there’s no margin safety there. But there is Peter Kaufman said <u>there’s margin where there’s mystery</u>. I think that’s so true. There’s margin where there’s mystery. And so sometimes <u>the best investments are those that are misunderstood and might appear expensive, and they’re often quality kinds of businesses</u>. So I gravitate toward quality partly as a result of that influence he had on me, if that makes sense.</em> </p>
<p><em>Tesla company is definitely one of the most misunderstood companies that I’ve seen in my 25 years or so of managing money for others. It’s such an interesting company and it, and it’s so misunderstood and I think it’s misunderstood for a few reasons. One, you have this kind of overarching personality where people start to formulate opinions based on what Elon is. And people think about it as a car company. And third, most people haven’t actually dived in, right? They’ve not spent the hundreds and hundreds of hours on this company and they haven’t really gone through the financials to understand the economics of the business. So there are a few things coming together where I think that this company still remains misunderstood, but there’s a reason why it’s up whatever 15000% or so since the IPO. And there is a reason why it continues to go higher over time because there are plenty of people that do get it right and that it’s just getting more and more concentrated into what I would probably call hands of smart money.</em></p>
<p><em>I’d say it’s not just a car company, <u>it is very much an EV company, but it’s not just a car company</u>… Why would the future look any different? And of course it, it it did. Why were people skeptical? While there were no paved roads, supply chains were very limited. There were very few fueling stations, there was very little manufacturing capacity. Kind of sound familiar right to today in EV terms. But ice vehicles, Henry Ford disrupted the horse and carriage very quickly within 20 years, which is happened to be pretty much the timeframe during which curves take formation is a 20 year disruption period with respect to pretty much all these transformational technologies.</em> </p>
<p><em>Going back to the guttenberg printing press and the steam engine and the spinning wheel, it’s all about 20 years. So my point is that there’s all of this skepticism and you had horse and carriage competing against this noisy ice vehicle. Both were forms of transportation, both gotten you from point A to point B, but one was fundamentally different. It was fundamentally different because it was a much more efficient process of getting you from point A to point B. And that is the lens from a kind of very high top down level that I look at Tesla and electric vehicles in general, <u>they’re just a much more efficient way to get you from point A to point B than ice vehicles. And what I mean by that is the cost of ownership and cost per mile is just much lower</u>. And so then it’s a question of what are the risks? What are the competitive advantage does Tesla have over the rest of the competition in EV and how will Tesla survive and thrive against ice vehicles? Which to me are going the way of the dinosaur. That is a big assumption that I believe is true because I think that <u>EV adoption is following the traditional S curve adoption phase</u> and there’s not a lot of time left for ice vehicles to exist.</em> </p>
<p><em>The real voyage of discovery is not in seeking new landscapes, but in having new eyes.</em> </p>
<p><em>I gave you the first kind of like lens at which I’m looking at Tesla as competing as an EV company against ice vehicles and ev as a whole being much more efficient than ice. But the other lens I should share is that I don’t think you can understand this company if you don’t understand. I could be totally wrong, but as assuming that I’m right, I don’t believe you can understand the company if you don’t understand that - to me it’s an advanced electronics manufacturer and software company competing against a traditional automobile manufacturing company.</em> </p>
<p><em><u>This is super important. It’s an electronics slash software company competing against traditional auto.</u> It’s super important to understand that because there’s certain things that kind of like come into play. There was an aeronautical engineer by the name of Theodore Wright, he devised this concept called the rights law, which states that for every doubling of cumulative production, that costs fall by a constant percentage. And when you understand that Tesla is an electronic software company, you understand like where is this company along this rights law curve.</em> </p>
<p><em>Tesla is so much further along the curve than any of the ice vehicles that are constrained because they’re not electronic in software companies, they’re traditional auto companies. And it’s Tesla’s so much further along the curve with respect to other EV companies. And so as ice vehicles traditional auto catches up, Tesla just moves much further along the curve. And so <u>the spread between the competitive advantage of Tesla, the other EV companies and traditional auto is actually widening</u>. It’s not getting more narrow, it’s widening because of its massive scale, which allows it to push itself out along the, the cost curve further than anybody else.</em> </p>
<p><em>We actually did buy more around current prices and these arguments, most of them at least except for the 50 billion compensation package, most of these arguments sound like the same arguments that you could go back and read since the company went public. They’re probably less negative articles today than there were around 2011, 2012, 2013. But they seem very similar. And yet the stock continues to go higher up 15,000 or so percent since it’s IPO. And what’s the case with pretty much every growth company from Amazon to Microsoft? <u>Any great growth company, there are always periods when the stock is not going up</u>. There have been so many massive drawdowns in Tesla since it’s IPO, like there’s gotta be a couple dozen, at least 40% drawdowns since it’s IPO or at least 30% drawdowns. And that’s just part of investing in growth companies. No businesses. And I wrote a paper called Power and Challenges of Compounding, which is on our website, but <u>growth companies just don’t go in straight lines. They move more like in a step formation</u>. And if you look at the kind of longer term chart of Tesla, Tesla’s just kind of in a step formation just like Amazon was and Microsoft was.</em> </p>
<p><em>I totally focus on the business fundamentals. I really don’t, I don’t let the stock prices dictate like what I’m thinking about the business. And when I’m looking at a business, a potential company to buy, I try my very best like not to pay any attention to the stock price and just come up with my own idea of what I think the business is worth. And so <u>the key is really to focus on the fundamentals. And if the fundamentals are moving in the right direction, then the stock price will take care of itself over time.</u> The the problem is that if you have all your money in one or even five companies or maybe even 10 companies, it’s really, really hard to deal with that emotionally.</em> </p>
<p><em>Mr. Rogers was not just a TV host who was the central figure for Mr. Rogers neighborhood, but he was also a Presbyterian minister. And I think that that upbringing education and that way of life influenced how he dealt with people. And he had this wonderful expression. He said that <u>there are three ways to ultimate success. The first is to be kind, the second is to be kind, and the third is to be kind</u>. I thought that was really interesting and very powerful and it meshed with how I wanted to try to live life. And it also me meshes with, you know, this idea of reciprocity, which is deep rooted human condition, right? <u>If we give kindness to the world and bringing kindness back, I truly believe that</u>. And, and so he was, and has been influential to how I think about life and how I try my best. I don’t always succeed, but I do try my best to live my life according to Mr. Rogers’ values.</em>  </p>
<p><em>Peter said that, look, you need to look at your life as one ladder. And there’s seven steps to the ladder. <u>These seven steps are pretty much in this order. Health and then family and friends, career, community, spirituality and hobbies.</u> The most important, those of those seven steps is health. Because health is multiplicative, right? If you take health and you multiply it by zero, everything else goes to zero, not good. So you wanna focus on that as first and foremost.</em>  </p>
<p><strong>― Real Success w&#x2F;Christopher Tsai - We Study Billionaires Podcast</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/6pjXzkTYpqgU7hwXz6LgYT">Link</a>] </p>
</blockquote>
<p>In this episode Christopher talked about his family history, investment in Tesla, Microsoft, Visa, and Mastercard, and some other personal development and investment tips. This is what I’ve learned:</p>
<ol>
<li>It completely changed my mind in understanding Tesla. I thought Tesla’s main business is traditional automobile, while EV is a new leading branch in the frontier. But it turns out that it’s wrong. Tesla is actually an electronic software company with a smart undercover of traditional automobile. As traditional auto vehicle companies catching up, Tesla is just moving further and further. Also being aware of what’s happening around Tesla: stock price was falling, sales growth is slowing, BMW and BYD are flooding the market with EV, unfocused CEO Elon Musk, no new models of the car since 2020, etc, I was already starting questioning Tesla, but in fact, the truth is Elon beat almost every milestone, he kept almost every promise, and he deserves his $50B pay package. What Tesla is current going through is as normal as what any other growth companies have experienced.</li>
<li>The key of being a value investor and picking valuable stocks is to focus on the business fundamentals but not stock price.</li>
<li>Diversifying portfolio is a good way to deal with pain and emotions, and stop you from interrupting the compounding process.</li>
</ol>
<blockquote>
<p><strong>In conversation with President Trump - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=blqIZGXWUpU&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>They brought President Donald Trump to the show! They asked great questions and they have 40 min high-quality recap, it’s very impressive. Btw, I do feel President Trump is a really engaging person - you can feel it by just listening to him speaking out. </p>
<blockquote>
<p><strong>Data + AI Summit Keynote Day 1 - Full - Databricks</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UfbyzK488Hk&ab_channel=Databricks">Link</a>]</p>
</blockquote>
<p>Experts, researchers and open source contributors — from Databricks and across the data and AI community gathered in San Francisco June 10 - 13, 2024 to discuss the latest technologies in data management, data warehousing, data governance, generative AI for the enterprise, and data in the era of AI. </p>
<p><u>Notes of “Ali Ghodsi, Co-founder and CEO,Databricks”:</u></p>
<p>There are three problem from AI practitioners: </p>
<ol>
<li><p>Everyone wants AI </p>
<p>Organization don’t care about MMLU performance, they care about using model to do well on their data for their use cases and businesses. According to a survey, 85% of the use cases have not made it into production. This indicates that getting AI on your data into production is hard - people want high quality, low cost, and privacy.</p>
</li>
<li><p>Security and privacy are under pressure</p>
<p>It’s under intense pressure. People care about AI regulation, data privacy, and cyberattacks.</p>
</li>
<li><p>Data estate is fragmented. </p>
<p>Lots of complexity, huge costs, and proprietary lock-in.</p>
</li>
</ol>
<p>Databricks solution to these three problems is data intelligence platform. The idea is: don’t give your data to vendors, instead, own your own data, store them in data lake in a format that’s standard. These are what Databricks is doing:</p>
<ol>
<li>They acquired Tabular because they want the data to be stored in a standard format so that every engine can access to.</li>
<li>They also launched project UniForm, which aims to make sure that UniForm has 100% full compatibility and interoperability for both of Delta Lake and Iceberg projects.</li>
<li>Unity Catalog allows you to do governance to ensure access, control, and security, and also discovery, lineage, auditing, data and model quality monitoring. And They have just open-sourced Unity Catalog.</li>
<li>Data in data lake combining with Mosaic AI’s AI models is called Data Intelligence Platform. This platform trains Gen AI models on your data in isolation for each customer, and leverages that throughout the platform for everything it does. </li>
<li>Data Intelligence is democratized data plus democratized AI. Democratized data means everyone in your organization should be able to access to the data directly. They, including those don’t know how to speak sql, should be able to access to data or get insights from data by spending languages. Democratized AI means everyone should be able to create AI models that understand your data in your organization.</li>
<li>All the Databricks now are available in 100% serverless.</li>
</ol>
<p><u>Note of “Brian Ames, General Motors”:</u> </p>
<p>Their mission is zero crashes, zero emissions, and zero congestion. In order for GM to be part of the future, they need to become a software company. They started from building data silos, on-prem infrastructure, and keeping pace of innovation. Their vision and strategy are to change the culture, move to the cloud, create a data insights factory cloud, and build upon Databricks.</p>
<p>The GMs data insights factory today includes single source of truth (where big data are ingested), trusted data (with functions of GenAI platform, ETL and orchestration, and data warehousing), open ecosystem (with Meta’s LLMs, AI models, and data governance ), and react front end. Majority of the factory is supported by Databricks.</p>
<blockquote>
<p><strong>Morgan Housel: Get Rich, Stay Rich - The Knowledge Project</strong> [<a target="_blank" rel="noopener" href="https://podcasters.spotify.com/pod/show/s8186/episodes/195-Morgan-Housel-Get-Rich--Stay-Rich-e2k69la">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Founder of Rolex: Hans Wilsdorf - Founders</strong> [<a target="_blank" rel="noopener" href="https://open.spotify.com/episode/6nxXutdfEfcR03sCTtlF4X">Link</a>] [<a target="_blank" rel="noopener" href="https://www.joincolossus.com/episodes/6536480/senra-351-the-founder-of-rolex-hans-wilsdorf?tab=transcript">Transcript</a>]</p>
</blockquote>
<blockquote>
<p><strong>China’s AI Journey - Weighty Thoughts</strong> [<a target="_blank" rel="noopener" href="https://weightythoughts.com/p/chinas-ai-journey">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>E156｜自动驾驶领域的GPT时刻来了？聊聊特斯拉V12、FSD入华与RoboTaxi - The Silicon Valleyer with Jane</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?app=desktop&si=HbjIu_tcm8D1h8md&v=noKsqZ81XnA&feature=youtu.be&ab_channel=%E7%A1%85%E8%B0%B7101%E6%92%AD%E5%AE%A2">Link</a>]</p>
</blockquote>
<p>Good discussion about Tesla V12, FSD in China, and RoboTaxi. I learnt new views about end-to-end technology, Musk’s vision, overview of EV market, EV competitors, etc. </p>
<blockquote>
<p><em>It makes so much sense for them so I think they should do it as quickly as possible. We are in the first inning of what should probably be an enormous tectonic shift in technology. And I think if whoever wins in the first inning usually isn’t the one that’s winning by the ninth inning. And so I would encourage anybody that’s winning right now to monetize, get secondaries, take money off the table as fast as possible. Because the future is unknown and the more disruptive the technology is, the more entropy there is, which means that there is going to be more changes not less. And again I would just look at search as an example, I would look at social networking as an example. When you look 20 years later the people who captured all the value were not the one that at the beginning who everybody thought was going to win. And so I think If it plays out similarly, it’s important for the people that are in the lead today, to recognize that it’s too early, and they should monetize their perceived success as quickly as they can to the largest magnitude as possible. - Chamath Palihapitiya</em></p>
<p><em>I think OpenAI is running a very strategic game plan to become part of the tech establishment as quickly as they can, so that they are in the inside looking out as opposed to the outside looking in. They were able to add the former head of the NSA to their board of directors. It’s how you become part of the establishment. Do you think the former head of the NSA no long has a security clearance or knows people in the NSA? No of course not.  And I think that there is a group of people that want to make sure that these kinds of technologies and capabilities are firmly within the hands of the US apparatus and not anybody else. And so I think that that pulls them closer to the kinds of folks that could otherwise give them a hard time or regulate them, etc. So now what happens is when you have senate hearing about this stuff it’s more likely that it’s confidential behind closed door, it’s under the purview of National Security. All these things are beneficial to OpenAI. And secondly they were able to get Elon to drop his lawsuit. So the next logical step is now to create Capital Market distribution, which is really about syndicating ownership of the company to all the big deep pools of money, so that they are also rowing in the same direction in support of OpenAI. That’s what a lot of people don’t get, it’s not about valuations or this and that, this is about creating a highlevel game theory of how to create an international apparatus that supports your corporate objectives. There are a few companies that have done this well, and they are now one of them, the only thing left is to get shares into the hands of the BlackRocks, the t-rows, all the big mutual fund apparatuses of the world that then syndicate to all the individual investors of the world. You have everything, you have government connections, you have no real legal overhang, then the likelihood that an IRS agent all of a sudden decides to audit OpenAI is basically zero. It’s a smart business strategy. - Chamath Palihapitiya</em></p>
<p><em>“Microsoft excels with bundling. It’s their not so secret weapon for dominating new markets. We know the playboo: Office + Teams, Windows + Explorer, Azure + Visual Studio, 365 + OneDrive, &amp; Xbox + Game Pass. - Marc Benioff @X”</em></p>
<p><strong>― Presidential Debate Reaction, Biden Hot Swap?, Tech unemployment, OpenAI considers for-profit &amp; more</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=aEYcZtaZRXQ&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Statistical Learning Course - Stanford Online</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=LvySJGj-88U&list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ&ab_channel=StanfordOnline">Link</a>]</p>
</blockquote>
<p>Last time of watching this series of lectures it was 3 years ago. Happy to see these two old guys again (Trevor Hastie and Robert Tibshirani). I’m planning to review the whole series in my spare time. </p>
<blockquote>
<p><strong>Machine Learning Course - CS 156 Caltech</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLD63A284B7615313A">Link</a>]</p>
</blockquote>
<p>This is an unusual (to me) ML course with a strong focus on theory. It’s taught from a very different perspective that’s supplementary to what I have learned from my ML courses. Definitely going to watch it once I have time.</p>
<blockquote>
<p><strong>EfficientML.ai Lecture, Fall 2023, MIT 6.5940 - MIT HAN Lab</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB">Link</a>] [<a target="_blank" rel="noopener" href="https://hanlab.mit.edu/courses/2023-fall-65940">Website</a>]</p>
</blockquote>
<p>I have to watch this. Feed me knowledge please! ヾ(◍°∇°◍)ﾉﾞ</p>
<h3 id="Papers-and-Reports"><a href="#Papers-and-Reports" class="headerlink" title="Papers and Reports"></a>Papers and Reports</h3><blockquote>
<p><strong>SimPO: Simple Preference Optimization with a Reference-Free Reward</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.14734">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.00650">Link</a>]</p>
</blockquote>
<p>Best preparation book for AI&#x2F;ML job seekers and students.</p>
<blockquote>
<p><strong>The economic potential of generative AI: The next productivity frontier - McKinsey</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier?stcr=C9A75624B81C4A47AB66FFA090CEB42B&cid=other-eml-alt-mip-mck&hlkid=c904212f9070458b85d9cc679f3436d8&hctky=14527191&hdpid=97189783-1eb7-45dc-af69-cc1fdb6f90c1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Microsoft New Future of Work Report 2023</strong> [<a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/publication/microsoft-new-future-of-work-report-2023/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Prompt Report: A Systematic Survey of Prompting Techniques</strong> [<a target="_blank" rel="noopener" href="https://trigaten.github.io/Prompt_Survey_Site/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Situational Awareness: The Decade Ahead</strong> [<a target="_blank" rel="noopener" href="https://situational-awareness.ai/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Better &amp; Faster Large Language Models via Multi-token Prediction</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.19737">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Can Recommender Systems Benefit from Large Language Models: A Survey</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2306.05817">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.16747">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Efficient data generation for source-grounded information-seeking dialogs: A use case for meeting transcripts - Google Research</strong> [<a target="_blank" rel="noopener" href="https://research.google/blog/efficient-data-generation-for-source-grounded-information-seeking-dialogs-a-use-case-for-meeting-transcripts/">Link</a>]</p>
</blockquote>
<p>This open source dataset “Meeting Information Seeking Dialogs” is unique with an aim of improving interaction with meeting recordings through conversational AI models. It allows users to query and engage with transcript content efficiently through a developed agent.</p>
<blockquote>
<p><strong>Meta Large Language Model Compiler: Foundation Models of Compiler Optimization - Meta Systems Research</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/">Link</a>]</p>
</blockquote>
<p>Meta LLM Compiler is a family of models built on Meta Code Llama with additional code optimization and compiler capabilities.</p>
<blockquote>
<p><strong>ESM3: Simulating 500 million years of evolution with a language model - EvolutionaryScale Research</strong> [<a target="_blank" rel="noopener" href="https://www.evolutionaryscale.ai/blog/esm3-release">Link</a>]</p>
</blockquote>
<p>ESM3 is an AI model capable of understanding and predicting the sequence, structure and function of proteins, simulating evolutionary processes, and generating new proteins with specific traits.</p>
<h3 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h3><blockquote>
<p><strong>Tool Use - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://github.com/anthropics/anthropic-cookbook/tree/main/tool_use">Cookbook</a>] [<a target="_blank" rel="noopener" href="https://github.com/anthropics/courses/tree/master/ToolUse">Notebook</a>]</p>
</blockquote>
<p>Anthropic has launched a new feature for its AI assistant, Claude, known as “Tool Use” or “function calling.” </p>
<blockquote>
<p><strong>All Machine Learning Algorithms Implemented in Python &#x2F; Numpy</strong> [<a target="_blank" rel="noopener" href="https://github.com/rushter/MLAlgorithms">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Spreadsheet Is All You Need</strong> [<a target="_blank" rel="noopener" href="https://github.com/dabochen/spreadsheet-is-all-you-need">Link</a>]</p>
</blockquote>
<p>GPT architecture is recreated in spreadsheet.</p>
<blockquote>
<p><strong>Hello Qwen2</strong> [<a target="_blank" rel="noopener" href="https://qwenlm.github.io/blog/qwen2/">Link</a>]</p>
</blockquote>
<p>Alibaba released new open-source LLM called Qwen2, which outperforms Meta’s Llama 3 in specialized tasks. It’s accessible via HuggingFace, with weights available and five model sizes (0.5B, 1.5B, 7B, 57B-14B (MoE), and 72B). Qwen2 has been trained on data in 29 languages, and can handle up to 128K tokens in context length. It has been benchmarked against Meta’s Llama 3 and OpenAI’s GPT-4, achieving top scores. The primary innovation of Qwen2 is its long-context understanding.</p>
<blockquote>
<p><strong>Cohere Cookbooks</strong> [<a target="_blank" rel="noopener" href="https://docs.cohere.com/page/cookbooks">Link</a>]</p>
</blockquote>
<p>A set of tutorials for building agents &#x2F; AI applications.</p>
<blockquote>
<p><strong>Mistral Cookbooks</strong> [<a target="_blank" rel="noopener" href="https://github.com/mistralai/cookbook/tree/main?tab=readme-ov-file">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems - LlamaIndex</strong> [<a target="_blank" rel="noopener" href="https://www.llamaindex.ai/blog/introducing-llama-agents-a-powerful-framework-for-building-production-multi-agent-ai-systems">Link</a>]</p>
</blockquote>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Amazon to expand drone delivery service after clearing FAA hurdle</strong> [<a target="_blank" rel="noopener" href="https://www.cnbc.com/2024/05/30/amazon-drone-delivery-faa-approval.html">Link</a>]</p>
</blockquote>
<p>Amazon’s drone delivery services “Prime Air” was laid out more than a decade ago but has struggled since then. In 2022, Amazon said it would begin testing deliveries in College Station, Texas. In 2023, Prime Air was hit by layoffs. But recently Amazon said it would expand drone operations to Phoenix, Arizona, etc. And it’s expected to expand to other cities in 2025.</p>
<blockquote>
<p><strong>Salesforce’s stock suffers its biggest drop in two decades</strong> [<a target="_blank" rel="noopener" href="https://www.morningstar.com/news/marketwatch/20240530487/salesforces-stock-suffers-its-biggest-drop-in-two-decades">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>NASA’s James Webb Space Telescope Finds Most Distant Known Galaxy</strong> [<a target="_blank" rel="noopener" href="https://blogs.nasa.gov/webb/2024/05/30/nasas-james-webb-space-telescope-finds-most-distant-known-galaxy/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Saudi fund joins $400m funding round of Chinese AI startup Zhipu</strong> [<a target="_blank" rel="noopener" href="https://www.verdict.co.uk/prosperity7-ventures-zhipu-ai-investment/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A PR disaster: Microsoft has lost trust with its users, and Windows Recall is the straw that broke the camel’s back</strong> [<a target="_blank" rel="noopener" href="https://www.windowscentral.com/software-apps/windows-11/microsoft-has-lost-trust-with-its-users-windows-recall-is-the-last-straw">Link</a>]</p>
</blockquote>
<p>As Microsoft has done a lot of things (obtrusive ads, full-screen popups, ignoring app defaults, forcing Microsoft Accounts, etc) to degrade the Windows user experience over the last few years, it lost the trust relationship between Windows users and Microsoft, therefore a tool like Recall is described as literal spyware or malware by users no matter how well you communicate the features to the world. </p>
<blockquote>
<p><strong>Apple Made Once-Unlikely Deal With Sam Altman to Catch Up in AI</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-06-05/why-is-apple-aapl-teaming-up-with-openai-both-companies-need-each-other">Link</a>]</p>
</blockquote>
<p>The deal between Apple and OpenAI will give OpenAI access to hundreds of millions of Apple users, and bring Apple the hottest technology of the AI era - that can pair with its own services.</p>
<blockquote>
<p><strong>Nvidia is now more valuable than Apple at $3.01 trillion</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/6/5/24172363/nvidia-apple-market-cap-valuation-trillion-ai">Link</a>]</p>
</blockquote>
<p>Mark this today, on Jun 5, 2024, Nvidia’s market cap is higher than Apple becomes the second most valuable company in the world.</p>
<blockquote>
<p><strong>SpaceX’s Starship Rocket Successfully Completes 1st Return From Space</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/06/06/science/spacex-starship-fourth-test-flight.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Woman Declared Dead Is Found Alive at Funeral Home</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/06/03/us/nebraska-dead-woman-alive-funeral-home.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>BYD Launches Hybrids With 1,300-Mile Driving Range</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/business/autos/byd-launches-hybrids-with-1-300-mile-driving-range-5a3ae139">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>China’s plan to dominate EV sales around the world</strong> [<a target="_blank" rel="noopener" href="https://arstechnica.com/cars/2024/06/chinas-plan-to-dominate-ev-sales-around-the-world/?utm_source=tldrnewsletter">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Nvidia emails: Elon Musk diverting Tesla GPUs to his other companies</strong> [<a target="_blank" rel="noopener" href="https://arstechnica.com/cars/2024/06/elon-musk-is-diverting-teslas-gpus-to-x-xai-nvidia-emails-say/?utm_source=tldrnewsletter">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How Apple Fell Behind in the AI Arms Race</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/apple-ai-siri-development-behind-9ea65ee8?st=82mud84srao94aq&reflink=desktopwebshare_permalink&utm_source=tldrnewsletter">Link</a>]</p>
</blockquote>
<p>Next week, at Apple’s annual Worldwide Developers Conference, the company is set to join an AI arms race -  announce an array of generative AI upgrades to its software products, including Siri. </p>
<blockquote>
<p><strong>Tesla’s $450 lightning-shaped bottle of mezcal is its most expensive liquor yet</strong> [<a target="_blank" rel="noopener" href="https://www.businessinsider.com/tesla-mezcal-bottle-for-sale-2024-6">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Apple’s Upcoming AI Reveal, Pika Labs Raises $80 Million, Twelve Labs, $50 Million</strong> [<a target="_blank" rel="noopener" href="https://www.forbes.com/sites/charliefink/2024/06/06/apples-upcoming-ai-reveal-pika-labs-raises-80-million-twelve-labs-50-million/?ss=ai">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Among the biggest spenders on sovereign AI is Singapore, whose national supercomputing center is being upgraded with Nvidia’s latest AI chips and where state-owned telecom <a target="_blank" rel="noopener" href="https://www.wsj.com/market-data/quotes/SG/XSES/Z74">Singtel</a> is pushing an expansion of its data center footprint in Southeast Asia in collaboration with Nvidia. The country is also spearheading a large language model that is trained on Southeast Asian languages.</em> </p>
<p><em>Other big projects are taking place in Canada, which last month pledged $1.5 billion as part of a sovereign computing strategy for the country’s startups and researchers, and Japan, which said it is investing about $740 million to build up domestic AI computing power this year following a visit from Huang.</em></p>
<p><em>Similar pushes are spreading across Europe, including those in France and Italy, where telecom companies are building AI supercomputers with Nvidia’s chips to develop local-language large language models. French President Emmanuel Macron last month called on Europe to create public-private partnerships to buy more graphics processing units, or the core chips used to train AI, to push its share of those deployed globally from 3% currently to 20% by 2030 or 2035.</em> </p>
<p><strong>― Nvidia’s New Sales Booster: The Global Push for National AI Champions</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/tech/ai/nvidias-new-sales-booster-the-global-push-for-domestic-ai-champions-6d005ab7?st=3t4jukdsg9da2bt&reflink=desktopwebshare_permalink">Link</a>]</p>
</blockquote>
<p>Cloud-computing giants and big tech companies have been a great source of revenue for NVIDIA, now Sovereign Al is another lever. Governments demand sovereign clouds for their AI infrastructure and sensitive data, and US tech companies such as NVIDIA are eager to build those for them. Question would be how long can they keep this momentum in generating high revenue. </p>
<blockquote>
<p><strong>Do you best creating, thinking, learning, brainstorming, note-taking - Google NotebookLM</strong> [<a target="_blank" rel="noopener" href="https://notebooklm.google/">Link</a>]</p>
</blockquote>
<p>Google upgraded its NotebookLM powered by Gemini 1.5.</p>
<blockquote>
<p><em>There’s one other way Apple is dealing with privacy concerns: making it someone else’s problem. Apple’s <a target="_blank" rel="noopener" href="https://www.theverge.com/2024/6/10/24171936/apple-siri-ai-update-ios18-features-wwdc">revamped Siri</a> can send some queries to <a target="_blank" rel="noopener" href="https://www.theverge.com/2024/6/10/24174786/apple-openai-partnership-chatgpt-wwdc">ChatGPT</a> in the cloud, but only with permission after you ask some really tough questions. That process shifts the privacy question into the hands of OpenAI, which has its own policies, and the user, who has to agree to offload their query. In <a target="_blank" rel="noopener" href="https://go.skimresources.com/?id=1025X1701640&xs=1&url=https://www.youtube.com/watch?v=pMX2cQdPubk&xcust=___vg__p_23940026__t_w__r_https://www.google.com/__d_D">an interview</a> with Marques Brownlee, Apple CEO Tim Cook said that ChatGPT would be called on for requests involving “world knowledge” that are “out of domain of personal context.”</em></p>
<p><em>Apple’s local and cloud split approach for Apple Intelligence isn’t totally novel. Google has a Gemini Nano model that can work locally on Android devices alongside its Pro and Flash models that process on the cloud. Meanwhile, Microsoft Copilot Plus PCs can process AI requests locally while the company continues to lean on its deal with OpenAI and also <a target="_blank" rel="noopener" href="https://www.theverge.com/2024/5/6/24150449/microsoft-is-building-a-large-ai-model-that-could-rival-openai">build its own in-house MAI-1 model</a>. None of Apple’s rivals, however, have so thoroughly emphasized their privacy commitments in comparison.</em></p>
<p><strong>― Here’s how Apple’s AI model tries to keep your data private</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/6/13/24175985/apple-intelligence-ai-model-local-cloud-privacy-how-it-works">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing Apple Intelligence, the personal intelligence system that puts powerful generative models at the core of iPhone, iPad, and Mac</strong> [<a target="_blank" rel="noopener" href="https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Ilya Sutskever Has a New Plan for Safe Superintelligence</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-06-19/openai-co-founder-plans-new-ai-focused-research-lab">Link</a>]</p>
<p><strong>AI Employees Should Have a “Right To Warn” About Looming Trouble - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/ai-employees-should-have-a-right">Link</a>]</p>
</blockquote>
<p>Ilya left OpenAI in mid-May and started Safe Superintelligence Inc. in mid-Jun, with a goal of creating a safe powerful AI system. Daniel Gross (former Apple Inc. AI lead) and Daniel Levy (former AI engineer at OpenAI). </p>
<p>To me, it’s not a bad thing to let OpenAI safety employees leave and start their own business. It’s actually a good thing for both. OpenAI led by Sam is eager to stay the leading AI company and develop AGI as quickly as possible. Having colleagues concerning about AI safety would only slow down the progress. So the goals of OpenAI vision &amp; mission and OpenAI safety team don’t align. Not saying AI safety is not important. I’m saying the AI pioneers and AI safety team should both exist individually and separately so that they are restricting each other in an official, public, and even way, and not conflicting each other from inside.</p>
<blockquote>
<p><strong>Musk’s xAI supercomputer will get server racks from Dell and Super Micro</strong> [<a target="_blank" rel="noopener" href="https://www.fastcompany.com/91143745/dell-super-micro-musk-xai-supercomputer-server-racks">Link</a>]</p>
</blockquote>
<p>Dell and Super Micro Computer will provide server racks for the supercomputer being developed by xAI. The supercomputer aims to power the next iteration of xAI’s chatbot Grok, which requires a vast number of Nvidia GPUs for training. Musk plans to have the supercomputer operational by fall 2025. </p>
<blockquote>
<p><strong>Releasing New AI Research Models to Accelerate Innovation at Scale - Meta News</strong> [<a target="_blank" rel="noopener" href="https://about.fb.com/news/2024/06/releasing-new-ai-research-models-to-accelerate-innovation-at-scale/">Link</a>]</p>
</blockquote>
<ul>
<li><p>Meta Chameleon: 7B &amp; 34B language models </p>
<p>Open source model is catching up GPT-4o. This is the first open source base model that is able to take multimodal inputs and generate outputs. Unfortunately it currently only has a research license. </p>
</li>
<li><p>Meta Multi-Token Prediction LLM</p>
<p>Meta released a language model for code completion using multi-token prediction. The approach was newly proposed in a paper aiming to build better and faster LLMs by using multi-token prediction. [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.19737">Paper</a>]</p>
</li>
<li><p>Meta JASCO: text-to-music models </p>
<p>They released generative text to music models able to accept various conditioning inputs for greater controllability.</p>
</li>
<li><p>Meta AudioSeal: audio watermarking model</p>
<p>This is the first designed specifically for the localized detection of AI-generated speech, available under a commercial license. This would be very useful to detect deep fakes.</p>
</li>
<li><p>Additional RAI artifacts</p>
<p>To ensure geographical and cultural diversity in the capability of text to image models, they developed automatic indicators to evaluate potential geographical disparities in text to image models. And now they released this evaluation code and annotations. [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2308.06198">Paper</a>]</p>
</li>
</ul>
<blockquote>
<p><strong>Claude 3.5 Sonnet - Anthropic News</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/claude-3-5-sonnet?utm_source=www.matthewberman.com&utm_medium=referral&utm_campaign=claude-3-5-is-the-new-king-ex-openai-founder-new-company">Link</a>]</p>
<p><strong>On Claude 3.5 Sonnet - Zvi Mowshowitz</strong> [<a target="_blank" rel="noopener" href="https://thezvi.substack.com/p/on-claude-35-sonnet">Link</a>]</p>
</blockquote>
<p>Claude 3.5 Sonnet achieves higher performance in various key metrics and tasks, outperforms competitor models as well, and performs at twice the speed of Claude 3 Opus and at 1&#x2F;5 the cost. Also, Anthropic introduced a new feature called Artifacts on Claude.ai to expand how users can interact with Claude.</p>
<blockquote>
<p><strong>AI tools are coming to Gmail, Google Drive, and Firefox</strong> [<a target="_blank" rel="noopener" href="https://www.fastcompany.com/91146341/firefox-gmail-google-drive-ai-chatbots-coming-soon">Link</a>]</p>
</blockquote>
<p>Google is integrating AI side panels powered by Gemini into Gmail, Docs, Sheets, Slides, and Google Drive, enhancing writing assistance, summarization, and content creation.</p>
<blockquote>
<p><strong>Firefox starts letting you use AI chatbots in the sidebar</strong> [<a target="_blank" rel="noopener" href="https://www.engadget.com/firefox-starts-letting-you-use-ai-chatbots-in-the-sidebar-144218734.html">Link</a>]</p>
</blockquote>
<p>Mozilla is incorporating AI chatbots into Firefox. ChatGPT, Google Gemini, HuggingChat, or Le Chat Mistral are options for users to choose in the sidebar.</p>
<blockquote>
<p><strong>Meet Sohu, the fastest AI chip of all time. - Etched @X</strong> [<a target="_blank" rel="noopener" href="https://x.com/etched/status/1805625693113663834?s=46">Link</a>]</p>
</blockquote>
<p>Sohu is building the fastest specialized chip for transformer models.</p>
<blockquote>
<p><strong>Gemma 2 is now available to researchers and developers - Google Developers</strong> [<a target="_blank" rel="noopener" href="https://blog.google/technology/developers/google-gemma-2/">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/05/15/2024-May/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/05/15/2024-May/" class="post-title-link" itemprop="url">2024 May</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-05-15 09:08:51" itemprop="dateCreated datePublished" datetime="2024-05-15T09:08:51-04:00">2024-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-13 11:29:16" itemprop="dateModified" datetime="2024-07-13T11:29:16-04:00">2024-07-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>To me, the best model going forward is going to be based on the <strong>weighted performance per parameter and training token count.</strong> Ultimately, a model keeps getting better the longer you train it. Most open model providers could train longer, but it hasn’t been worth their time. We’re starting to see that change.</em></p>
<p><em><strong>The most important models will represent improvements in capability density</strong>, rather than shifting the frontier.</em></p>
<p><em>In some ways, it’s easier to make the model better by training longer compared to anything else, if you have the data.</em></p>
<p><em>The core difference between open and closed LLMs on these charts is <strong>how undertrained open LLMs often are</strong>. The only open model confirmed to be trained on a lot of tokens is DBRX.</em> </p>
<p><strong>―  The End of the “Best Open LLM” - Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/compute-efficient-open-llms?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>Good analysis of the direction of open LLM development in 2023 and 2024. In 2023, models were progressing in MMLU by leveraging more compute budgets to handle scaled active parameters and training tokens. In 2024, the progressing direction is slightly changed to be orthogonal to previous - which is improving on MMLU while keeping compute budgets constant.</p>
<blockquote>
<p><em>The companies that have users interacting with their models consistently have moats through data and habits. The models themselves are not a moat, as I discussed at the end of last year when I tried to <a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/ml-moats">predict machine learning moats</a>, but there are things in the modern large language model (LLM) space that open-source will really struggle to replicate. Concretely, that difference is access to quality and diverse training prompts for fine-tuning. While I want open-source to win out for personal philosophical and financial factors, this obviously is not a walk in the park for the open-source community. It’ll be a siege of a castle with, you guessed it, a moat. We’ll see if the moat holds.</em></p>
<p><strong>―  Model commoditization and product moats - Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/gpt4-commoditization-and-moats">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>The goal of promoting scientific understanding for the betterment of society has a long history. Recently I was pointed to the essay <a target="_blank" rel="noopener" href="https://www.ias.edu/sites/default/files/library/UsefulnessHarpers.pdf">The Usefulness of Useless Knowledge</a> by Abraham Flexner in 1939 which argued how basic scientific research without clear areas for profit will eventually turn into societally improving technologies. If we want LLMs to benefit everyone, my argument is that we need far more than just computer scientists and big-tech-approved social scientists working on these models. We need to continue to promote openness to support this basic feedback loop that has helped society flourish over the last few centuries.</em></p>
<p><em>The word openness has replaced the phrase open-source among most leaders in the open AI movement. It’s the easiest way to get across what your goals are, but it is not better in indicating how you’re actually supporting the open ecosystem. The three words that underpin the one messy word are <strong>disclosure</strong> (the details), <strong>accessibility</strong> (the interfaces and infrastructure), and <strong>availability</strong> (the distribution).</em></p>
<p><strong>―  We disagree on what open-source AI should mean - Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/flavors-of-open-source-ai?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Google: “A Positive Moment”</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/alphabet-a-positive-moment?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>The report of Google Search’s death is exaggerated so far. In fact, search advertising has grown faster at Google than at Microsoft. User searching behavior is harder to change than people expected. Also, Google is leading the development of AI powered tools for Search: 1) “circle to search” is feature allowing a search from an image, text, or video without switching apps. 2) “Point your camera, ask a question” is a feature allowing for multisearch with both images and text for complex questions given an image to the tool. Overall, SGE (Search Generative Experience) is revolutionizing search experience (“10 blue links”) by  introducing a dynamic AI-enhanced experience. So far from I observed AI powers Google Search rather than weakens it.</p>
<blockquote>
<p><strong>Amazon: Wild Margin Expansion - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/amazon-wild-margin-expansion?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>Amazon’s margin expansion: AWS hit $100 B run rate with a 38% operating margin; Ads is surging; delivery costs have been reduced.</p>
<blockquote>
<p><em>The biggest risk is not correctly projecting demand for end-user AI consumption, which would threaten the utilization of the capacity and capital investments made by tech firms today. This would leave them exposed at the height of the valuation bubble, if and when it bursts, just like Cisco’s growth story that<a target="_blank" rel="noopener" href="https://www.wsj.com/amp/articles/SB973215201314032825"> began to unravel in 2000</a>.</em> <em>After all, history may not repeat, but it often rhymes.</em></p>
<p><em>At the Upfront Ventures confab mentioned earlier, Brian Singerman, a partner at Peter Thiel’s Founders Fund, was asked about contrarian areas worth investing in given the current landscape. <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=QBzhRVRIf2Q&t=927s">His response</a>: “Anything not AI”.</em></p>
<p><strong>―  AI’s Bubble Talk Takes a Bite Out Of The Euphoria - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://open.substack.com/pub/aisupremacy/p/ais-bubble-talk-takes-a-bite-out">Link</a>]</p>
</blockquote>
<p>When we talk about investment, we talk about economic values. Current situation of AI is very similar to Cisco’s in 2000. Cisco as an internet company spread the capacity of the World Wide Web, but sooner people realized that there is no economic value in internet company, instead, opportunities are in e-commerce etc. AI is a tool very similar to web tech. Currently, with heightened expectations, people are allocating investments and capital expenditure in AI model development, however, end-user demand is unclear and revenue is relatively minimal. This situation makes AI look like a bubble from a very long term perspective.</p>
<blockquote>
<p><em>Steve Jobs famously said that Apple stands at the intersection of technology and liberal arts. Apple is supposed to enhance and improve our lives in the physical realm, not to replace cherished physical objects indiscriminately.</em></p>
<p><strong>―  Apple’s Dystopian iPad Video - The Rational Walk Newsletter</strong> [<a target="_blank" rel="noopener" href="https://newsletter.rationalwalk.com/p/apples-dystopian-ipad-video">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Key pillars of the new strategy (on gaming):</em></p>
<ul>
<li><em>Expanding PC and cloud gaming options.</em></li>
<li><em>Powerful consoles (still a core part of the vision).</em></li>
<li><em>Game Pass subscriptions as the primary access point.</em></li>
<li><em>Actively bringing Xbox games to rival platforms (PS5, Switch).</em></li>
<li><em>Exploring mobile gaming with the potential for handheld hardware.</em></li>
</ul>
<p><em>Microsoft’s “every screen is an Xbox” approach is a gamble and may take a long time to pay off. But the industry is bound to be device-agnostic over time as it shifts to the cloud and offers cross-play and cross-progression. It’s a matter of when not if.</em></p>
<p><strong>―  Microsoft: AI Inflection - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/microsoft-ai-inflection">Link</a>]</p>
</blockquote>
<p>Highlights: Azure’s growth accelerated sequentially thanks to AI services and was the fastest-growing of the big three (Amazon AWS, Google Cloud, Microsoft Azure). On Search, Microsoft is losing market share to Alphabet. Capex on AI grows roughly 80% YoY. On gaming, it’s diversifying approaches from selling consoles. Copilot and the Office succeed with Enterprise customers.</p>
<blockquote>
<p><em>To founders, my advice is to remain laser-focused on building products and services that customers love, and be thoughtful and rational when making capital allocation decisions. Finding product-market fit is about testing and learning from small bets before doubling down, and it is often better to grow slower and more methodically as that path tends to lead to a more durable and profitable business. An axiom that doesn’t seem to be well understood is that the time it takes to build a company is also often its half-life.</em></p>
<p><strong>―  2023 Annual Letter - Chamath Palihapitiya</strong> [<a target="_blank" rel="noopener" href="https://chamath.substack.com/p/2023-annual-letter">Link</a>]</p>
</blockquote>
<p>This is a very insightful letter about how economic and tech trends of 2023 have shaped their thinking and investment portfolio. What I have learned from this letter: </p>
<ol>
<li><p>Tech industry has shifted their focus from unsustainable “growth at any cost” to more prudent forms of capital allocation. This results in laying off employees and slashing projects that are not relevant to the core business.</p>
</li>
<li><p>Rising of interest rate is one of the reasons of bank crisis. During zero interest rate decade, banks sought higher rates of return by purchasing longer duration assets while the value of them are negatively correlated to interest rate. As those caused losses are known by the public, a liquidity crisis ensued.</p>
</li>
<li><p>The advancement of Gen AI has lowered the barriers of starting a software company, and lowered capital requirement in Bio Tech and material sciences, and changed the process of building companies fundamentally, and empowered new entrants to challenge established businesses.</p>
<ul>
<li><p>The key question is: where will value creation and capture take place? when and where should capital be allocated and company should be started? Some author’s opinions:</p>
<ul>
<li><p>It’s premature to declare winners now. Instead, author suggested people should deeply understand the underlying mechanisms that will be responsible for value creation over next few years.</p>
</li>
<li><p>There are at least two areas of value creation now</p>
<ol>
<li><p>Proprietary data</p>
<p>Example: recent partnership between Reddit and Google</p>
</li>
<li><p>Infrastructure used to run AI application</p>
<p>For apps built on top of language models, responsiveness is a critical lynchpin. However GPUs are not well-suited to run inference.</p>
<p>Example: Author’s investment in Groq’s LPU for inference</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Heightened geopolitical tensions due to Russia-Ukraine conflict, Israel and Hamas, escalating tensions between China and Taiwan, resulted in a de-globalization trend and also a strategic shift in the US. US legislative initiatives aims to fuel a domestic industrial renaissance by incentivizing reshoring and fostering a more secure and resilient supply chain. They include CHIPS Act, Infrastructure Investment, Job Act, Inflation Reduction Act, etc. </p>
<ul>
<li>The author highlights the opportunity for allocators and founders: companies can creatively and strategically tap into different pools of capital-debt, equity, and government funding.</li>
</ul>
</li>
</ol>
<blockquote>
<p><em>OpenAI’s strategy to get its technology in the hands of as many developers as possible — to build as many use cases as possible — is more important than the bot’s flirty disposition, and perhaps even new features like its translation capabilities (<a target="_blank" rel="noopener" href="https://twitter.com/Kantrowitz/status/1790073470753165538">sorry</a>). If OpenAI can become the dominant AI provider by delivering quality intelligence at bargain prices, it could maintain its lead for some time. That is, as long as the cost of this technology doesn’t drop near zero.</em></p>
<p><em>A tight integration with Apple could leave OpenAI with a strong position in consumer technology via the iPhone and an ideal spot in enterprise via its partnership with Microsoft.</em> </p>
<p><strong>―  OpenAI Wants To Get Big Fast, And Four More Takeaways From a Wild Week in AI News - Big Technology</strong> [<a target="_blank" rel="noopener" href="https://www.bigtechnology.com/p/openai-wants-to-get-big-fast">Link</a>]</p>
</blockquote>
<p>As GPT-4o is 2x faster and 50% cheaper, this discourages competitors to develop LLMs to compete and encourages companies to build with OpenAI’s model for their business. This shows that OpenAI wants to get big fast. However, making GPT-4o free disincentivizes users from subscribing the Plus version.</p>
<p>There is a tight and deep bond between OpenAI and Apple. The desktop app has been debuted on Mac and Apple will build OpenAI’s GPT Tech into mobile iOS. </p>
<blockquote>
<p><em>“You can borrow someone else’s stock ideas but you can’t borrow their conviction. True conviction can only be obtained by trusting your own research over that of others. Do the work so you know when to sell. Do the work so you can hold. Do the work so you can stand alone.”</em></p>
<p><em>Investing isn’t about blindly following the herd. It’s about carving your own path, armed with knowledge, patience, and a relentless pursuit of growth and learning.</em></p>
<p><strong>― Hedge Funds’ Top Picks in Q1 - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/hedge-funds-top-picks-in-q1">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>As I’ve dug into this in more detail, I’ve become convinced that they are doing something powerful by <strong>searching over language steps via tree-of-thoughts reasoning</strong>, but it is much smaller of a leap than people believe. The reason for the hyperbole is the goal of linking large language model training and usage to the core components of Deep RL that enabled success like AlphaGo: self-play and look-ahead planning.</em></p>
<p><em>To create the richest optimization setting, having the ability to generate diverse reasoning pathways for scoring and learning from is essential. This is where Tree-of-Thoughts comes in. <strong>The prompting from ToT gives diversity to the generations, which a policy can learn to exploit with access to a PRM</strong>.</em></p>
<p><em>Q seems to be using PRMs to score Tree of Thoughts reasoning data that then is optimized with Offline RL. This wouldn’t look too different from existing RLHF toolings that use offline algorithms like DPO or ILQL that do not need to generate from the LLM during training. The ‘trajectory’ seen by the RL algorithm is the sequence of reasoning steps, so we’re finally doing RLHF in a multi-step fashion rather than contextual bandits!</em></p>
<p><em><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.20050">Let’s Verify Step by Step</a></em>: <em>a good introduction to PRMs.</em></p>
<p><em><em>― The Q</em> hypothesis: Tree-of-thoughts reasoning, process reward models, and supercharging synthetic data - Interconnects</em>*  [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/q-star">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>It’s well known on the street that Google DeepMind has split all projects into three categories: Gemini (the large looming model), Gemini-related in 6-12months (applied research), and fundamental research, which is oddly only &gt; 12 months out. <strong>All of Google DeepMind’s headcount is in the first two categories, with most of it being in the first</strong>.</em></p>
<p><em>Everyone on <strong>Meta’s GenAI technical staff should spend</strong> <strong>about 70% of the time directly on incremental model improvements and 30% of the time on ever-green work.</strong></em> </p>
<p><em>A great <a target="_blank" rel="noopener" href="https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering">read</a> from Francois Chollet on links between prompting LLMs, word2vec, and attention. One of the best ML posts I’ve read in a while.</em></p>
<p><em><a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/mobilepresent?pli=1&slide=id.g2885e521b53_0_5">Slides</a> from Hyung Won Chung’s (OpenAI) talk on LLMs. Great summary of intuitions for the different parts of training. The key point: We can get further with RLHF because the objective function is flexible.</em></p>
<p><strong>― The AI research job market shit show (and my experience) - Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/ai-research-job-market">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>10 Lessons From 2024 Berkshire Hathaway Annual Shareholder Meeting - Capitalist Letters</strong>  [<a target="_blank" rel="noopener" href="https://www.capitalist-letters.com/p/10-lessons-from-2024-berkshire-hathaway">Link</a>]</p>
</blockquote>
<p>What I’ve learned from this article:</p>
<ol>
<li><p>Why did Berkshire trimmed its APPL position?</p>
<p>No concern about Apple’s earnings potential, make sense to take some profits as value is now too high.</p>
</li>
<li><p>Right way to look at share buybacks</p>
<p>A business should pay dividends only if it cannot make good use of the excess capital it has. Good use capital means the Return of Equity, which is on average 12% for American companies. If the company is able to allocate capital better than shareholders themselves and provide them with above average returns, it should retain the earnings and allocate capital itself.</p>
<p>Buybacks only makes sense at the right price and buying back shares just to support stock price is not the best action ti take for shareholders. All investment decisions should be price dependent.</p>
</li>
<li><p>How would he invest small sums of money?</p>
<p>At the time of market crashes or economic downturns, you find exceptional companies trading at ridiculously cheap prices and that’s your opportunity, When you find those companies fairly priced or overvalued and you look for special situations while holding onto your positions in those exceptional companies.</p>
</li>
<li><p>Views on capital allocation</p>
<p>Study picking businesses, not stocks.</p>
</li>
<li><p>Investing in foreign countries</p>
<p>America has been a great country for building wealth and capitalist democracy is the best system of governance ever invented.</p>
</li>
<li><p>Advice on job picking</p>
<p>Remember Steve Jobs’ famous words in the Stanford Commencement speech he gave before his death: “Keep looking, don’t settle!”</p>
</li>
<li><p>On the importance of culture</p>
<p>In Berkshire culture, shareholders feel themselves as the owners of the businesses. Greg Abel will keep the culture alive in the post-Buffett period and this will automatically attract top talent to a place where they are given full responsibility and trust.</p>
</li>
<li><p>When to sell stocks</p>
<ol>
<li>A bigger opportunity comes up, 2.  something drastically changes in the business, and 3. to raise money</li>
</ol>
</li>
<li><p>Effects of consumer behavior on investment decisions</p>
<p>Two types of businesses have durable competitive advantage: 1) Lowest cost suppliers of products and services, 2) suppliers of unique products and services.</p>
</li>
<li><p>How to live a good life?</p>
<p>“I’ve written my obituary the way I’ve lived my life”‘ - Charlie Munger</p>
</li>
</ol>
<blockquote>
<p><strong>NVIDIA: Industrial Revolution - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/nvidia-industrial-revolution">Link</a>]</p>
</blockquote>
<p>Primary drivers of Data Center Revenue: 1) Strong demand (up 29% sequentially) for the Hopper GPU computing platform used for training and inferencing with LLMs, recommendation engines, and GenAl apps, 2) InfiniBand end-to-end solutions (down 5% sequentially due to timing of supply) for networking. NVIDIA started shipping the Spectrum-X Ethernet networking solutions optimized for Al.</p>
<p>In the earning call, three major customer categories are provided: 1) cloud service providers (CSPs) including hyperscalers Amazon Microsoft and Google. 2) enterprise usage: Tesla expanded training Al cluster to 35000 H100 GPUs and used NVIDIA Al for FSD V12. 3) consumer internet companies: Meta’s Llama 3 powering Meta Al was trained on a cluster of 24000 H100 GPUs.</p>
<p>Huang explained in the earning call that AI is not a chip problem only but also a systems problem now. They build AI factories.</p>
<p>For further growth, Blackwell platform is coming, Spectrum-X networking is expanding, new software tools like NIMs is developing.</p>
<blockquote>
<p><em>A lot of current research focuses on LLM architectures, data sources prompting, and alignment strategies. While these can lead to better performance, such developments have 3 inter-related critical flaws-</em> </p>
<ol>
<li><em>They mostly work by increasing the computational costs of training and&#x2F;or inference.</em> </li>
<li><em>They are a lot more fragile than people realize and don’t lead to the across-the-board improvements that a lot of Benchmark Bros pretend.</em> </li>
<li><em>They are incredibly boring. A focus on getting published&#x2F;getting a few pyrrhic victories on benchmarks means that these papers focus on making tweaks instead of trying something new, pushing boundaries, and trying to address the deeper issues underlying these processes.</em></li>
</ol>
<p><strong>― Revolutionizing AI Embeddings with Geometry [Investigations] - Devansh</strong> [<a target="_blank" rel="noopener" href="https://artificialintelligencemadesimple.substack.com/p/revolutionizing-ai-embeddings-with">Link</a>]</p>
</blockquote>
<p>Very few AI research work don’t have # 1 and # 3 flaws and they are really good hard-core work. Time is required to verify whether they are generalizable, widely applicable or not. Especially nowadays the process of scientific research is very different from previous years where there was usually a decade between starting your work and publishing it.</p>
<p>This article highlights some publications in complex embedding and looked into how they improved embeddings by using complex numbers. Current challenges in embedding are 1) sensitivity to outliers 2) limited capacity in capture complex relationship in unstructured text, 3) inconsistency in pairwise rankings of similarities, and 4) computational cost. The next generation complex embedding is benefitting from the following pillars: 1) complex geometry provides richer space to capture nuanced relationships and handle outliers, 2) orthogonality allows each dimension to be independent and distinct, 3) contrastive learning can be used to minimize the distance between similar pairs and maximize the distance between dissimilar pairs. Complex embeddings have a lot of advantages: 1) increasing representation capacity with two components (real and imaginary) of complex numbers, 2) complex geometry allows for orthogonality and thus improves generalization, and also allows use to reach stable convergence quickly, 3) robust features can be captured which improves robustness, and 4) solved limitation of cosine similarity (saturation zones which lead to vanishing gradients during optimization) by angle optimization in complex space.</p>
<blockquote>
<p><em>Llama 3 8B might be the most interesting all-rounder for fine-tuning as it can be fine-tuned no a single GPU when using LoRA.</em></p>
<p><em>Phi-3 is very appealing for mobile devices. A quantized version of it can run on an iPhone 14.</em></p>
<p><strong>― How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?</strong> [<a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/how-good-are-the-latest-open-llms">Link</a>]</p>
</blockquote>
<p>Good paper review article. Highlights key discussions:</p>
<ul>
<li><p>Mixtral 8x22B: The key idea is to replace each feed-forward module in a transformer architecture with 8 expert layers. It achieves lower active parameters (cost) and higher performance (MMLU).</p>
</li>
<li><p>Llama 3: The main difference between Llama 3 and Llama 2 are 1) vocab size has been increased, 2) used grouped-query attention, 3) used both PPO &amp; DPO. The key research finding is that the more data the better performance, no matter what model size is. </p>
<p>“Llama 3 8B might be the most interesting all-rounder for fine-tuning as it can be fine-tuned no a single GPU when using LoRA.”</p>
</li>
<li><p>Phi-3: Key characteristics are 1) it’s based on Llama architecture, 2) trained on 5x fewer tokens than Llama 3, 3) used the same tokenizer with a vocab size of 32064 as Llama2, much smaller than Llama 3 vocab size, 4) has only 3.8B parameters, less than half the size of Llama 3 8B, 5) secret sauce is dataset quality over quantity - it’s trained on heavily filtered web data and synthetic data. </p>
<p>“Phi-3 is very appealing for mobile devices. A quantized version of it can run on an iPhone 14.”</p>
</li>
<li><p>OpenELM: key characteristics are 1) 4 relatively small sizes: 270M, 450M,1.1B, and 3B, 2) instruct version trained with rejection sampling and DPO, 3) slightly better than OLMo in performance, even though trained on 2x fewer tokens, 4) main architecture teak - a layer-wise scaling strategy, 5) sampled a relatively smaller subset of 1.8T tokens from various public datasets, but no clear rationale for subsampling, 6) one main research finding is that there is no clear difference between LoRA and DoRA for parameter efficient fine-tuning.</p>
<p>About the layer-wise scaling strategy: 1) there are N transformer blocks in a model, 2) layers are gradually widened from the early to the later transformer blocks, so for each block: a) number of heads are increased, b) dimension of each layer is increased.</p>
</li>
<li><p>DPO vs PPO: The main difference between DPO and PPO is that “DPO does not require training a separate reward model but uses a classification-like objective to update LLM directly”. </p>
<p>Key findings of the paper and best practices suggested: 1) PPO is generally better than DPO if you use it correctly. DPO suffers from out-of-distribution data, which means instruction data is different from preference data. The solution could be to “add a supervised instruction fine-tuning round on the preference dataset before following up with DPO fine-tuning.”, 2) If you use DPO, make sure to perform SFT on preference data first, 3) “iterative DPO which involves labeling additional data with an existing reward model is better than DPO on existing preference data.”, 4) “If you use PPO, the key is to use large batch sizes, advantage normalization, and parameter update via exponential moving average.”, 5) though PPO is generally better, DPO is more straightforward and will still be a popular go-to option, 6) both can be used. Recall the pipeline behind Llama3: pretraining -&gt; SFT -&gt; rejection sampling -&gt; PPO -&gt; DPO.</p>
</li>
</ul>
<blockquote>
<p><strong>Google I&#x2F;O AI keynote updates 2024 - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/google-io-ai-keynote-updates-2024?r=333z5o&utm_medium=ios&triedRedirect=true">Link</a>] </p>
<p><strong>Streaming Wars Visualized - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://open.substack.com/pub/appeconomyinsights/p/streaming-wars-visualized?r=333z5o&utm_medium=ios">Link</a>]</p>
<p><strong>This Week in Visuals - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/this-week-in-visuals?lli=1&utm_source=profile&utm_medium=reader2">Link</a>]</p>
<p><strong>Gig Economy Shakeup - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/gig-economy-shakeup?r=333z5o&utm_medium=ios&triedRedirect=true">Link</a>]</p>
</blockquote>
<h3 id="Articles"><a href="#Articles" class="headerlink" title="Articles"></a>Articles</h3><blockquote>
<p><strong>Musings on building a Generative AI product - LinkedIn Engineering Blog</strong> [<a target="_blank" rel="noopener" href="https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product">Link</a>]</p>
</blockquote>
<p>This is a very good read about developing Gen AI product for business by using pre-trained LLM. This article elaborates how this product is designed, how each part works specifically, what works and what does not work, what has been improving, and what has been struggling. Some takeaways for me are </p>
<ol>
<li><p>Supervised fine tuning step was done by embedding-based retrieval (EBR) powered by an in-memory database to inject response examples into prompts. </p>
</li>
<li><p>An organizational structure was designed to ensure communication consistency: one horizontal engineering pod for global templates and styles, and several vertical engineering pods for specific tasks such as summarization, job fit assessment, interview tips, etc.</p>
</li>
<li><p>Tricky work: </p>
<ol>
<li><p>Developing end to end automatic evaluation pipeline.</p>
</li>
<li><p>Skills in dynamically discover and invoke APIs &#x2F; agents.</p>
<p>This requires input and output to be ‘LLM friendly’ - JSON or YAML schemes. </p>
</li>
<li><p>Supervised fine tuning by injected responses of internal database.</p>
<p>As evaluation becoming more sophisticated, prompt engineering needs to be improved to reach high quality&#x2F;evaluation scores. The difficulty is that quality scores shoot up fast then plateau so it’s hard to reach a very high score in the late improvement stage. This makes prompt engineering more like an art rather than science. </p>
</li>
<li><p>Tradeoff of capacity and latency</p>
<p>Chain of Thoughts can improve quality and accuracy of responses, but increase latency. TimeToFirstToken (TTFT) &amp; TimeBetweenTokens (TBT) are important to utilization but need to be bounded to limit latency. Besides, they also intend to implement end to end streaming and async non-blocking pipeline.</p>
</li>
</ol>
</li>
</ol>
<blockquote>
<p><em>The concept of open source was devised to ensure developers could use, study, modify, and share software without restrictions. But AI works in fundamentally different ways, and key concepts don’t translate from software to AI neatly, says Maffulli.</em></p>
<p><em>But depending on your goal, dabbling with an AI model could require access to the trained model, its training data, the code used to preprocess this data, the code governing the training process, the underlying architecture of the model, or a host of other, more subtle details.</em></p>
<p><em>Which ingredients you need to meaningfully study and modify models remains open to interpretation.</em> </p>
<p><em>both Llama 2 and Gemma come with licenses that restrict what users can do with the models. That’s anathema to open-source principles: one of the key clauses of the Open Source Definition outlaws the imposition of any restrictions based on use cases.</em></p>
<p><em>All the major AI companies have simply released pretrained models, without the data sets on which they were trained. For people pushing for a stricter definition of open-source AI, Maffulli says, this seriously constrains efforts to modify and study models, automatically disqualifying them as open source.</em></p>
<p><strong>―  The tech industry can’t agree on what open-source AI means. That’s a problem. ― MIT Technology Review</strong> [<a target="_blank" rel="noopener" href="https://www.technologyreview.com/2024/03/25/1090111/tech-industry-open-source-ai-definition-problem/">Link</a>]</p>
</blockquote>
<p>This article argues that the definitions of open-source AI are problematic. ‘Open’ models either have restriction on usage or don’t release details of training data. This does not fit traditional definition of ‘open source’. However, people argue that for the special case of AI, we need different definition of open source. As long as the definition remains vague, it’s problematic, because big tech will define open-source AI to be what suits it. </p>
<blockquote>
<p><strong>Everything I know about the XZ backdoor</strong> [<a target="_blank" rel="noopener" href="https://boehs.org/node/everything-i-know-about-the-xz-backdoor">Link</a>]</p>
<p>Some great high-level technical overview of XZ backdoor [<a target="_blank" rel="noopener" href="https://gynvael.coldwind.pl/?lang=en&id=782">Link</a>] [<a target="_blank" rel="noopener" href="https://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27">Link</a>] [<a target="_blank" rel="noopener" href="https://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27">Link</a>] [<a target="_blank" rel="noopener" href="https://infosec.exchange/@fr0gger/112189232773640259">Infographic</a>] [<a target="_blank" rel="noopener" href="https://research.swtch.com/xz-script">Link</a>] [<a target="_blank" rel="noopener" href="https://bsky.app/profile/filippo.abyssdomain.expert/post/3kowjkx2njy2b">Link</a>]</p>
</blockquote>
<p>A backdoor in xz-utils (used for lossless compression) was recently revealed by Andres Freund (Principle SDE at Microsoft). The backdoor only shows up when a few specific criteria are met at least: 1) running a distro that uses glibc, 2) have version 5.6.0 or 5.6.1 xz installed or liblzma installed. There is a malicious script called <code>build-to-host.m4</code> which checks for various conditions like the architecture of the machine. If those conditions check, the payload is injected into the source tree. The intention of payload is still under investigation. Lasse Collin, one of the maintainer of the repo, has posted an <a target="_blank" rel="noopener" href="https://tukaani.org/xz-backdoor/">update</a> and is working on carefully analyzing the situation. The author Evan Boehs in the article present a timeline of the attack and online investigators’ discoveries of Jia Tan identity (from IP address, LinkedIn, <a target="_blank" rel="noopener" href="https://rheaeve.substack.com/p/xz-backdoor-times-damned-times-and">commit timings</a>, etc), and raises our awareness of the human costs of open source.</p>
<blockquote>
<p><em>Having a crisp mental model around a problem, being able to break it down into steps that are tractable, perfect first-principle thinking, sometimes being prepared (and able to) debate a stubborn AI — these are the skills that will make a great engineer in the future, and likely the same consideration applies to many job categories.</em></p>
<p><strong>―  Why Engineers Should Study Philosophy ―  Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/04/why-engineers-should-study-philosophy?utm_medium=email&utm_source=circ_other&utm_campaign=subbenemail_digitalcontent_monthinreview&hideIntromercial=true&tpcc=subbenemail&deliveryName=SUB_Ben_DigitialContent_MonthInReview_20240507">Link</a>]</p>
</blockquote>
<p>Human comes into a new stage of learning: smartly asking AI questions to get answers as accurate as possible. So prompt engineering is a very important skill in AI era. In order to master prompt engineering, we need to have divide and conquer mindset, perfect first-principle thinking, critical thinking, and skepticism.</p>
<blockquote>
<p><em>If we had infinite capacity for memorisation, it’s clear the transformer approach is better than the human approach - it truly is more effective. But it’s less efficient - transformers have to store so much information about the past that might not be relevant. Transformers (🤖) only decide what’s relevant at <strong>recall time</strong>. The innovation of Mamba (🐍) is allowing the model better ways of forgetting earlier - it’s focusing by choosing what to discard using <strong>Selectivity</strong>, throwing away less relevant information at <strong>memory-making time</strong>.</em></p>
<p><strong>― Mamba Explained</strong> [<a target="_blank" rel="noopener" href="https://thegradient.pub/mamba-explained/">Link</a>]</p>
</blockquote>
<p>A very in-depth explanation of Mamba architecture. So the main difference between Transformer and Mamba is that Transformer stores all past information and decides what is relevant at recall time. While Mamba uses Selectivity to decide what to discard earlier. Mamba ensures both efficiency and effectiveness (space complexity reduces from O(n) to O(1), time complexity reduces from O(n^2) to O(n)). If Transformer has high effectiveness and low efficiency due to large state, and RNN has high efficiency and low effectiveness due to small state, Mamba is in between - Mamba selectively and dynamically compress data into the state.</p>
<blockquote>
<p><strong>The Power of Prompting ― Microsoft Research Blog</strong> [<a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">Link</a>]</p>
</blockquote>
<p>Basically this study demonstrates that GPT-4 is able to outperform a leading model that was fine-tuned specifically for medical application by Medprompt - a composition of several prompting strategies. This shows that fine-tuning might not be necessary in the future though it can boost performance, it is resource-intensive and cost-prohibitive. Simple prompting strategies could serve to transform generalist models into specialists and extending benefits of models to new domains and applications. Similar study was also done in finance domain by JP Morgan with similar results.</p>
<blockquote>
<p><em>Previously, we made some progress matching patterns of neuron activations, called features, to human-interpretable concepts. We used a technique called “dictionary learning”, borrowed from classical machine learning, which isolates patterns of neuron activations that recur across many different contexts.</em></p>
<p><em>In turn, any internal state of the model can be represented in terms of a few active features instead of many active neurons. Just as every English word in a dictionary is made by combining letters, and every sentence is made by combining words, every feature in an Al model is made by combining neurons, and every internal state is made by combining teatures.</em></p>
<p><em>The features are likely to be a faithful part of how the model internally represents the world, and how it uses these representations in its behavior.</em></p>
<p><strong>― Mapping the Mind of a Large Language Model - Anthropic</strong> [<a target="_blank" rel="noopener" href="https://www.anthropic.com/news/mapping-mind-language-model">Link</a>]</p>
</blockquote>
<p>This is an amazing work towards AI safety by Anthropic. The main goal is to understand the inner workings of AI models and identify how millions of concepts are represented inside Claude Sonnet, so that developers can better control AI safety. Previous progress of this work was to match pattern of neuron activations (“features”) to human-interpretable concepts by technique called “dictionary learning”. Now they are scaling up the technique to the vastly larger AI language models. Below is a list of key experiments and findings. </p>
<ol>
<li>Extracted millions of features from the middle layer of Claude 3.0 Sonnet. Features have a depth, breadth, and abstraction reflecting Sonnet’s advanced capabilities.</li>
<li>Find more abstract features - responding to bugs in code, discussion of gender biases in professions, etc.</li>
<li>Measure a “distance” between features based on which neurons appeared in their activation patterns. They find that features with similar concept are close to each other. This demonstrates internal organization of concepts in AI model correspond to human notions of similarity.</li>
<li>By artificially amplifying or suppressing features, they see how Claude’s responses change. This shows that features can be used to change how a model acts.</li>
<li>For the purpose of AI safety, they find features corresponding to the capabilities with misuse potential (code backdoors, developing bio-weapons), different forms of biases (gender discrimination, racist claims about crime), and potentially problematic AI behavior (power-seeking, manipulation, secrecy)</li>
<li>For previous concern about sycophancy, they also find a feature associated with sycophantic praise.</li>
</ol>
<p>This study proposed a good approach to ensure AI safety: use the technique described here to monitor AI systems for dangerous behaviors and to debias outcomes.</p>
<blockquote>
<p><em>To qualify as a “Copilot+ PC” a computer needs distinct CPUs, GPUs, and NPUs (neural processing units) capable of &gt;40 trillion operations per second (TOPS), and a minimum of 16 GB RAM and a 256 GB SSD.</em> </p>
<p><em>All of those analysts who assumed Wal-Mart would squish Amazon in e-commerce thanks to their own mastery of logistics were like all those who assumed Microsoft would win mobile because they won PCs. It turns out that logistics for retail are to logistics for e-commerce as operating systems for a PC are to operating systems for a phone. They look similar, and even have the same name, but require fundamentally different assumptions and priorities.</em></p>
<p><em>I then documented a few seminal decisions made to demote windows, including releasing Office on iPad as soon as he took over, explicitly re-orienting Microsoft around <a target="_blank" rel="noopener" href="https://stratechery.com/2013/services-not-devices/">services instead of devices</a>, isolating the Windows organization from the rest of the company, killing Windows Phone, and finally, in the decision that prompted that Article, splitting up Windows itself. Microsoft was finally, not just strategically but also organizationally, a services company centered on Azure and Office; yes, Windows existed, and still served a purpose, but it didn’t call the shots for the rest of Microsoft’s products.</em></p>
<p><em>That celebration, though, is not because Windows is differentiating the rest of Microsoft, but because the rest of Microsoft is now differentiating Windows. Nadella’s focus on AI and the company’s massive investments in compute are the real drivers of the business, and, going forward, are real potential drivers of Windows.</em></p>
<p><em>This is where the Walmart analogy is useful: McMillon needed to let e-commerce stand on its own and drive the development of a consumer-centric approach to commerce that depended on centralized tech-based solutions; only then could Walmart integrate its stores and online services into an omnichannel solution that makes the company the only realistic long-term rival to Amazon.</em></p>
<p><em>Nadella, similarly, needed to break up Windows and end Ballmer’s dreams of vertical domination so that the company could build a horizontal services business that, a few years later, could actually make Windows into a differentiated operating system that might, for the first time in years, actually drive new customer acquisition.</em></p>
<p><strong>― Windows Returns - Stratechery</strong> [<a target="_blank" rel="noopener" href="https://stratechery.com/2024/windows-returns/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Chatbot Arena results are in: Llama 3 dominates the upper and mid cost-performance front (full analysis) ― Reddit</strong> [<a target="_blank" rel="noopener" href="https://www.reddit.com/r/LocalLLaMA/comments/1cakcfq/chatbot_arena_results_are_in_llama_3_dominates/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora</strong> [<a target="_blank" rel="noopener" href="https://www.philschmid.de/fsdp-qlora-llama3">Link</a>]</p>
</blockquote>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><em>I don’t have an answer to peace in the Middle East, I wish I did, but I do have a very strong view that we are not going to get to peace when we are apologizing or denying crimes against humanity and crime mass rape of women. That’s not the path to peace, the path to peace is not saying this didn’t happen, the path to peace is saying this happened no matter what side of the fence you are on no matter what side of the world you are on, if you are the far right the far left, anywhere on the world, we are not going to let this happen again and we are going to get to peace to make sure.  - Sheryl Sandberg</em></p>
<p><strong>―  In conversation with Sheryl Sandberg, plus open-source AI gene editing explained - All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OxbtNsenZJY&ab_channel=All-InPodcast">Link</a>]</p>
<p>U.N. to Study Reports of Sexual Violence in Israel During Oct. 7 Attack [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/01/29/world/middleeast/israel-hamas-sexual-violence-un.html">Link</a>]</p>
<p>Western media concocts ‘evidence’ UN report on Oct 7 sex crimes failed to deliver [<a target="_blank" rel="noopener" href="https://thegrayzone.com/2024/03/07/media-concocts-un-hamas-rape-report/">Link</a>]</p>
</blockquote>
<p>It’s crazy that what is happening right now in some of the colleges is not to protest sexual violence as a tool of war by Hamas. This kind of ignorance or denial of sexual violence is horrible. People are so polarized to black and white that if something does not fit into their view, they are going to reject it. There are more than two sides to the Middle East story, one of them is sexual violence - mass rape, genital mutilation of men and women, women tied to trees naked bloody leg spread…</p>
<p>There is a long history of the involvement of women’s bodies in Wars. It’s only 30 years ago, people started to say rape is not a tool of War and should be prosecuted as a war crime against humanity. The feminist, human rights, and civil rights groups made this happen. Now it happened again in Gaza according to the report released by U.N., however there are a lot difficulties in proving and testifying the truth e.g. they couldn’t locate a single victim, or they don’t have the victim rights to take pictures. But victims are dead and they cannot speak up. Denying the fact of sexual violence is just unacceptable. And there is such a great <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=zAr9oGSXgak&ab_channel=ScreamsBeforeSilence">documentary</a> shedding lights on the unspeakable sexual violence committed on Oct 7, 2023 that I think everyone should watch.</p>
<p>Good news is that the testimony of eyewitness meets the criteria of any international or global court. So crimes can be proven by any eyewitness for sure.</p>
<blockquote>
<p><strong>John Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=hhiLw5Q_UFg&ab_channel=BerkeleyEECS">Link</a>]</p>
</blockquote>
<p>John Schulman is a research scientist and cofounder of OpenAI, focusing on Reinforcement Learning (RL) algorithms. He gave a talk on making AI more truthful on Apr 24, 2023 in UCB. The ideas and discussions are still helpful and insightful today.</p>
<p>In this talk, John discussed the issue of hallucination with large language models. He claims that behavior cloning or supervised learning is not enough to fix the hallucination problem, instead, reinforcement learning from human feedback (RLHF) can help improve the model’s truthfulness by 1) adjusting output distribution so model is allowed to express uncertainty, challenge premise, admit error, and 2) learning behavior boundaries. In his conceptual model, fine-tuning leads the model to hallucinate when it lacks knowledge. Retrieval and citing external sources can help improve verifiability. John discusses models that can browse the web to answer technical questions, citing relevant sources. </p>
<p>John mentioned three open problems in LLM: 1) how to train models to express uncertainty in natural language, 2) go beyond what human labelers can easily verify (“scalable oversight”), and 3) optimizing for true knowledge rather than human approval.</p>
<blockquote>
<p><strong>The 1-Year Old AI Startup That’s Rivaling OpenAI —  Redpoint’s AI Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=_N2KPEdh69s&ab_channel=UnsupervisedLearning:Redpoint%27sAIPodcast">Link</a>]</p>
</blockquote>
<p>A great interview with the CEO of Mistral Arthur Mensch on the topic of sovereignty and open models as a business strategy. Here are some highlighted points from Arthur:</p>
<ol>
<li>Open-source is going to solidify in the future. It is an infrastructure technology and at the end of the day it should be modifiable and owned by customers. Now Mistral has two offerings, open source one and commercial one, and the aim is to find out the business model to sustain the open source development.</li>
<li>The things that Mistral is best at 1) training model, and 2) specializing models. </li>
<li>The way they think about partnership strategy is to look at what enterprises would need, where they were operating, where the developers were operating, and figure out the channels that would facilitate adoption and spread. To be a multiplatform solution and to replicate the solution to different platforms is a strategy that Mistral is following.</li>
<li>There is still an efficiency upper bound to be pushed. Other than compute to spend on pre-training, there is still research to do on improving model efficiency and strength. On architecture side, we can be more efficient than plain Transformer which spends same amount of compute on every token. Mistral is making model faster. By making model faster, we open up a lot of applications that involve an LLM as a basic brick and then we can figure out how to do planning, explorations, etc. By increasing efficiency, we open up areas of research.</li>
<li>Meta has more GPUs than Mistral do. But Mistral has a good concentration of GPU (number of GPU per person). This is the way to be as efficient as possible to come up with creative ways of training models. Also unit economics need to be considered to make sure that $1 that you spend on training compute eventually accrues to more than $1 revenue.</li>
<li>Transformer is not an optimal architecture. It’s been out there for 7 years now. Everything is co-adapted to it such as training methods, debug methods, the algorithms, and hardware. It’s challenging to find a better one and also beat the baseline. But there are a lot of research on modification of attention to boost memory efficiencies and a lot of things can be done in that direction and similar directions.</li>
<li>About AI regulations and EU AI Act, Arthur states that it does not solve the actual problem of how to make AI safe. Because making AI safe is a hard problem (stochastic model), different from the way we evaluate software before. It’s more like a product problem rather than a regulation problem. We need to rethink continuous integration, verifications, etc and make sure everything is happening as it should be.</li>
<li>Mistral recently released Le Chat to help enterprise start incorporating AI. It gives an assistant that is contextualized on their enterprise data. It’s a tool to be closer to the end user to get feedback for the developer platform and also a tool to get the enterprise into GenAI.</li>
</ol>
<blockquote>
<p><strong>Open Source AI is AI we can Trust — with Soumith Chintala of Meta AI</strong> [<a target="_blank" rel="noopener" href="https://www.latent.space/p/soumith">Link</a>]</p>
</blockquote>
<p>Synthetic data is the next rage of LLM. Soumith pointed out that synthetic data is where we as humans already have good symbolic models off, we need to impart that knowledge to neural networks, and we figured out the synthetic data is a vehicle to impart this knowledge to it. Related to synthetic data but in an unusual way, there is new research on distilling GPT-4 by creating synthetic data from GPT-4, creating mock textbooks inspired by Phi-2 and then fine tuning open source models like Lambda.  </p>
<p>Open source means different things to different people and we haven’t had a community norm definition yet at this very early stage of LLM. When being asked about open source, people in this field are used to highlight the definition of it in advance. In the open source topic, Soumith pointed out that the most beneficial value of open is it makes the distribution very wide and available with no friction so that people can do transformative things in a way that is very accessible. </p>
<blockquote>
<p><strong>Berkshire Hathaway 2024 Annual Meeting Movie: Tribute to Charlie Munger</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=uGrf5PRFSJY&ab_channel=TheCapitalist">Link</a>]</p>
</blockquote>
<p>First year that the annual meeting movie is made public. First year that the annual meeting is without Charlie. Already started to miss his jokes.</p>
<blockquote>
<p><em>I think the reason why the car could have been completely reimagined by Apple is that they have a level of credibility and trust that I think probably no other company has, and absolutely no other tech company has. I think this was the third Steve Jobs story that I left out but in 2001, I launched a 99 cent download store and Steve Jobs just ran total circles around us, but the reason he was able to is he had all the credibility to go to the labels and get deals done for licensing music that nobody could get done before. I think that is an example of what Apple’s able to do which is to use their political capital to change the rules. So if the thing that we could all want is safer roads and autonomous vehicles, there are regions in every town and city that could be completely converted to level 5 autonomous zones. If I had to pick one company that had the credibility to go and change those rules, it’s them. Because they could demonstrate that there was a methodical safe approach to doing something. So the point is that even in these categories that could be totally reimagined, it’s not for a lack of imagination, again it just goes back to a complete lack of will. I understand because if you had 200B dollars of capital on your balance sheet, I think it’s probably easy to get fat and lazy. - Chamath Palihapitiya</em> </p>
<p><strong>―  In conversation with Sam Altman — All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=nSM0xd8xHUM&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>If you are a developer, the key thing to understand is where does model innovation end and your innovation begin, because if you get that wrong you will end up doing a bunch of stuff that the model will just obsolete in a few months. - David Sacks</em></p>
<p><em>The incentive for these folks is going to be push this stuff into the open source. Because if you solve a problem that’s operationally necessary for your business but it isn’t the core part of your business, what incentive do you have to really keep investing in this for the next 5 to 10 years to improve it. You are much better off release it in the open source, let the rest of the community take it over so that it’s available to everybody else, otherwise you are going to be stuck supporting it, and then if and when you ever wanted to switch out a model, GPT-4o, Claude, Llama, it’s going to be costly. The incentive to just push towards open source in this market if you will is so much meaningful than any other market. - Chamath Palihapitiya</em></p>
<p><em>I think the other thing that is probably true is a big measure at Google on the search page in terms of search engineer performance was the bounceback rate, meaning someone does a search, they go off to another site and they come back because they didn’t get the answer they wanted. Then one box launched which shows a short answer on the top, which basically keeps people from having a bad search experience, because they get the result right away. So a key metric is they are going to start to discover which vertical searches will provide the user a better experience than them jumping off to a third party page to get the same content. And then they will be able to monetize that content that they otherwise were not participating in the monetization of. So I think the real victim in all this is that long tale of content on the internet that probably gets cannibalized by the snippet one box experience within the search function. And then I do think that the revenue per search query in some of those categories actually has the potential to go up not down. You keep people on the page so you get more search volume there, you get more searches because of the examples you gave. And then when people do stay, you now have the ability to better monetize that particular search query, because you otherwise would have lost it to the third party content page. Keeping more of the experience integrated they could monetize the search per query higher and they are going to have more queries, and then they are going to have the quality of the queries go up. Going back to our earlier point about precision vs accuracy, my guess is there’s a lot of hedge fund type folks doing a lot of this Precision type of analysis trying to break apart search queries by vertical and try to figure out what the net effect will be of having better AI driven box and snippets. And my guess is that is why there is a lot of buying activity happening. I can tell you Meta and Amazon do not have an Isomorphic Lab and Waymo sitting inside their business, that suddenly pops to a couple hundred billion of market cap and Google does have a few of those. - David Friedberg</em></p>
<p><em>One thing I would say about big companies like Google or Microsoft is that the power of your monopoly determines how many mistakes you get to make. So think about Microsoft completely missed iPhone, remember they screwed up the whole smartphone era and it didn’t matter. Same thing here with Google, they completely screwed up AI. They invented the Transformer, completely missed LLMs. Then they had that fiasco where they have black George Washington. It doesn’t matter, they can make 10 mistakes but their monopoly is so strong, that they can finally get it right by copying the innovator, and they are probably going to be come 5T dollar company.  - David Sacks</em></p>
<p><strong>―  GPT-4o launches, Glue demo, Ohalo breakthrough, Druckenmiller’s bet, did Google kill Perplexity? — All-In Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=vDr1983LIuo&t=547s&ab_channel=All-InPodcast">Link</a>] </p>
</blockquote>
<p>Great conversations and insightful discussions as usual. Love it.</p>
<blockquote>
<p><em>When you are over earning so massively, the rational thing to do for other actors in the arena is to come and attack that margin, and give it to people for slightly cheaper slightly faster slightly better so you can take share. So I think what you’re seeing and what you will see even more now is this incentive for Silicon Valley who has been really reticent to put money into chips, really reticent to put money into hardware. They are going to get pulled into investing this space because there is no choice. - Chamath Palihapitiya</em></p>
<p><em>Why? It’s not that intel was a worse company, but it’s that everything else caught up. And the economic value went to things that sat above them in the stack, then it want to Cisco for a while right, then after Cisco, it went to the browser companies for a little bit, then it went to the app companies, then it went to the device companies, then it went to the mobile companies. So you see this natural tendency for value to push up the stack over time. For AI, we’ve done the step one which is now you’ve given all this value to NVIDIA and now we are going to see it being reallocated. - Chamath Palihapitiya</em></p>
<p><em>The reason why they are asking these questions is that if you go back to the doom dot come boom in 1999, you can see that Cisco had this incredible run. And if you overlay the stock price of Nvidia, it seems to be following that same trajectory. And what happened with Cisco is that when the doc come crash came in 2000, Cisco stock lost a huge part of its value. Obviously Cisco is still around today and it’s a valuable company, but it just hasn’t ever regained the type of market cap it had. The reason this happened is because Cisco got commoditized. So the success and market cap of that company attracted a whole bunch of new entrance and they copied Cisco’s products until they were total commodities. So the question is whether that happened to Nvidia. I think the difference here is that at the end of the day Network equipment which Cisco produced was pretty easy to copy, whereas if you look at Nvidia, these GPU cores are really complicated to make. So it’s a much more complicated product to copy. And then on top of that, they are already in the R&amp;D cycle for the next chip. So I think you can make the case that Nvidia has a much better moat than Cisco. - David Sacks</em></p>
<p><em>I think Nvidia is going to get pulled into competing directly with the hyperscalers. So if you were just selling chips, you probably wouldn’t, but these are big bulky actual machines, then all of a sudden you are like well why don’t I just create my own physical plant and just stack these things, and create racks and racks of these machines. It’s not a far stretch especially because Nvidia actually has the software interface that everybody uses which is CUDA. I think it’s likely that Nvidia goes on a full frontal assault against GCP and Amazon and Microsoft. That’s going to really complicate the relationship that those folks have with each other, but I think it’s inevitable because how do you defend an enormously large market cap, you are forced to go into businesses that are equally lucrative. Now if I look inside of compute and look at the adjacent categories, they are not going to all of a sudden start a competitor to TikTok or a social network, but if you look at the multi hundred billion revenue businesses that are adjacent to the markets that Nvidia enables, the most obvious ones are the hyperscalers. So they are going to be forced to compete otherwise their market cap will shrink and I don’t think they want that, and then it’s going to create a very complicated set of incentives for Microsoft and Google and Meta and Apple and all the rest. And that’s also going to be an accelerant, they are going to pump so much money to help all of these upstarts.  - Chamath Palihapitiya</em></p>
<p><em>Economy is bad without recognizing that it is an inflationary experience whereas economists use the definition of “economic growth” being gross product, and so if gross product or gross revenue is going up they are like oh the economy is healthy we are growing. But the truth is we are funding that growth with leverage at the national level the federal level and at the household a domestic level. We are borrowing money to inflate the revenue numbers , and so the GDP goes up but the debt is going higher, and so the ability for folks to support themselves and buy things that they want to buy and continue to improve their condition in life has declined if things are getting worse… The average American’s ability to improve their condition has largely been driven by their ability to borrow not by their earnings. - David Friedberg</em></p>
<p><strong>Scarlett Johansson vs OpenAI, Nvidia’s trillion-dollar problem, a vibecession, plastic in our balls</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=c9HEjdjyVn4&ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>It’s a fun session and it made my day :). Great discussions about Nvidia’s business, America’s negative economic sentiment, harm of plastics, etc.</p>
<blockquote>
<p><strong>Building with OpenAI What’s Ahead</strong> [<a target="_blank" rel="noopener" href="https://vimeo.com/949419199">Link</a>]</p>
</blockquote>
<h3 id="Papers-and-Reports"><a href="#Papers-and-Reports" class="headerlink" title="Papers and Reports"></a>Papers and Reports</h3><blockquote>
<p><strong>Large Language Models: A Survey</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.06196">Link</a>]</p>
</blockquote>
<p>This is a must-read paper if you would like to have a comprehensive overview of SOTA LLMs, technical details, applications, datasets, benchmarks, challenges, and future directions.</p>
<blockquote>
<p><strong>Little Guide to Building Large Language Models in 2024 - HuggingFace</strong> [<a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/edit?usp=sharing">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.05862">Link</a>]</p>
</blockquote>
<p>Bloomberg fine-tuned GPT-3.5 on their financial data only to find that GPT-4 8k, without specialized finance fine-tuning, beat it on almost all finance tasks. So there is really a moat? Number of parameters matters and data size matters, and they all require compute and money.</p>
<blockquote>
<p><strong>Jamba: A Hybrid Transformer-Mamba Language Model</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.19887">Link</a>] [<a target="_blank" rel="noopener" href="https://www.ai21.com/blog/announcing-jamba">Link</a>]</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=AL1fq05o7H">Mamba paper</a> has been rejected while fruits are reaped fast: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.04081">MoE-Mamba</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.09417">Vision Mamba</a>, and Jamba. It’s funny to see the asymmetric impact in ML sometimes, e.g. FlashAttention has &lt;500 citations and is used everywhere. Github repos used by 10k+ has &lt;100 citations, etc.</p>
<blockquote>
<p><strong>KAN: Kolmogorov-Arnold Networks</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.19756">Link</a>] [<a target="_blank" rel="noopener" href="https://github.com/KindXiaoming/pykan?tab=readme-ov-file#authors-note">authors-note</a>]</p>
</blockquote>
<p>This is a mathematically beautiful idea. The main difference between traditional MLP and KAN is that KAN has learnable activation function on weights, so all weights in KAN are non-linear. KAN outperforms MLP in accuracy and interpretability. Whether in the future KAN is able to replace MLP depends on whether there could be suitable learning algorithms like SGD, AdamW, etc and whether it will be GPU friendly.</p>
<blockquote>
<p><strong>The Platonic Representation Hypothesis</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.07987">Link</a>]</p>
</blockquote>
<p>Interesting paper to read if you like philosophy. This paper argues that there is a platonic representation as a result of convergence of AI models towards a shared statistical model of reality. They show that there is a growing similarity in data representation across different model architectures, training objectives, and data modalities, as the model size, data size, and task diversity are growing. They also proposed three hypothesis for the representation convergence: 1) The multitask scaling hypothesis, 2) The capacity hypothesis, and 3) The simplicity bias hypothesis. And it definitely worths reading the counterexamples and limitations. </p>
<blockquote>
<p><strong>Frontier Safety Framework - Google DeepMind</strong> [<a target="_blank" rel="noopener" href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/introducing-the-frontier-safety-framework/fsf-technical-report.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.04434">Link</a>] </p>
</blockquote>
<p>One main improvement: Multi-head latent attention via compressed latent KV requires smaller amount of KV cache per token but achieves stronger performance. Heads can be compressed differently (taking different portion of compressed latent states), and keys and values can be compressed differently.</p>
<blockquote>
<p><strong>What matters when building vision-language models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.02246">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Unreasonable Ineffectiveness of the Deeper Layers</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.17887">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>RecurrentGemma: Moving Past Transformers for Efficient Open Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.07839">Link</a>]</p>
</blockquote>
<p>This paper published by Google DeepMind proposes language model called <a target="_blank" rel="noopener" href="https://ai.google.dev/gemma/docs/recurrentgemma">RecurrentGemma</a> that can match or exceed the performance of transformer-based models while being more memory efficient.</p>
<blockquote>
<p><strong>Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach - Google’s Tech Report of LearnLM</strong> [<a target="_blank" rel="noopener" href="https://storage.googleapis.com/deepmind-media/LearnLM/LearnLM_paper.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Chameleon: Mixed-Modal Early-Fusion Foundation Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.09818">Link</a>]</p>
</blockquote>
<p>This paper published by Meta proposed a mixed model which uses Transformer architecture under the covers but applies some innovations such as query-key normalization to fix the imbalance between the text and image tokens and other innovations as well.</p>
<blockquote>
<p><strong>Simple and Scalable Strategies to Continually Pre-train Large Language Models</strong> [[Link](<a target="_blank" rel="noopener" href="https://arxiv.org/">https://arxiv.org/</a> pdf&#x2F;2403.08763)]</p>
</blockquote>
<p>Tricks for successful continued pretraining:</p>
<ol>
<li>﻿﻿﻿Re-warming and re-decaying the learning rate.</li>
<li>﻿﻿﻿Adding a small portion (e.g., 5%) of the original pretraining data (D1) to the new dataset (D2) to prevent catastrophic forgetting.<br> Note that smaller fractions like 0.5% and 1% were also effective.</li>
</ol>
<p>Cautious about their validity on model with larger sizes.</p>
<blockquote>
<p><strong>Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.10719">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Algorithmic Progress in Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.05812">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.05405">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Efficient Multimodal Large Language Models: A Survey</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.10739v1">Link</a>]</p>
</blockquote>
<p>Good overview of multimodal LLMs.</p>
<blockquote>
<p><strong>Financial Statement Analysis with Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>LoRA Learns Less and Forgets Less</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.09673">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Lessons from the Trenches on Reproducible Evaluation of Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.14782">Link</a>]</p>
</blockquote>
<p>Challenges and best practices in evaluating LLMs.</p>
<blockquote>
<p><strong>Agent Planning with World Knowledge Model</strong>  [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.14205">Link</a>]</p>
</blockquote>
<h3 id="GitHub-Repo"><a href="#GitHub-Repo" class="headerlink" title="GitHub Repo"></a>GitHub Repo</h3><blockquote>
<p><strong>Google Research Tune Playbook - GitHub</strong> [<a target="_blank" rel="noopener" href="https://github.com/google-research/tuning_playbook">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>ML Engineering - GitHub</strong>  [<a target="_blank" rel="noopener" href="https://github.com/stas00/ml-engineering">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>LLM from Scratch</strong> [<a target="_blank" rel="noopener" href="https://github.com/rasbt/LLMs-from-scratch/tree/main">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Prompt Engineering Guide</strong> [<a target="_blank" rel="noopener" href="https://github.com/dair-ai/Prompt-Engineering-Guide">Link</a>] [<a target="_blank" rel="noopener" href="https://www.promptingguide.ai/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>ChatML + chat templates + Mistral v3 7b full example</strong> [<a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/15F1xyn8497_dUbxZP4zWmPZ3PJx1Oymv?usp=sharing">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Finetune pythia 70M</strong> [<a target="_blank" rel="noopener" href="https://colab.research.google.com/gist/virattt/af36fd12480827da3f8427169b3348cb/finetuning-pythia-70m.ipynb">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Llama3 Implemented from Scratch</strong> [<a target="_blank" rel="noopener" href="https://github.com/naklecha/llama3-from-scratch">Link</a>]</p>
</blockquote>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Intel Inside Ohio</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/features/2024-intel-comeback-chipmaking/">Link</a>]</p>
<p>Intel Ohio One Campus Video Rendering [<a target="_blank" rel="noopener" href="https://vimeo.com/939198943">Link</a>]</p>
</blockquote>
<p>Intel Corp has committed $28B to build a “mega fab” called Ohio One which could be the biggest chip factory on Earth. The Biden administration has agreed to provide Intel with $19.5B in loans and grants to support finance the project.</p>
<blockquote>
<p><strong>EveryONE Medicines: Designing Drugs for Rare Diseases, One at a Time</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/articles/everyone-medicines-designing-drugs-for-rare-diseases-one-at-a-time-a6f98afc">Link</a>]</p>
</blockquote>
<p>Startup EveryONE Medicine aims to develop drugs designed based on genetic information for individual children who have rare, life-threatening neurological diseases. Since the number of patients with diseases caused by rare mutation is significant, the market share is large if EveryONE can scale its process. Although the cost won’t be the same as a standard drugmaker that runs large clinical trials, the challenge is safety without a standard clinical-testing protocol. To be responsible to patients, the initial drugs will have a temporary effect and a wide therapeutic window, so the potential toxicity will be minimized or stopped if there is.</p>
<blockquote>
<p><strong>Voyager 1’s Communication Malfunctions May Show the Spacecraft’s Age</strong> [<a target="_blank" rel="noopener" href="https://www.discovermagazine.com/the-sciences/voyager-1s-communication-malfunctions-may-show-the-spacecrafts-age">Link</a>]</p>
</blockquote>
<p>In Nov 2023, NASA’s over 46-year-old Voyager 1 spacecraft started sending nonsense to Earth. Voyager 1 was initially intended to study Jupiter and Saturn and was built to survive only 5 years of flight, however the trajectory was forged further and further into space and so the mission converted from a two-planet mission to an interstellar mission.</p>
<p>In Dec 2023, the mission team restarted the Flight Data Subsystem (FDS)  but failed to return the subsystem to functional state. On Mar 1 2023, they sent a command “poke” to the probe and received a response on Mar 3. On Mar 10, the mission team finally determined the response carried a readout of FDS memory. By comparing the readout with those received before the issue, the team confirmed that 3% of FDS memory was corrupted. On Apr 4, the team concluded the affected code was contained on a computer chip. To solve the problem, the team decided to divide these affected code into smaller sections and to insert those smaller sections into other operative places in the FDS memory. During Apr 18-20, the team sent out the orders to move some of the affected code and received responses with intelligible systems information. </p>
<blockquote>
<p><strong>Editing the Human Genome with AI</strong> [<a target="_blank" rel="noopener" href="https://www.profluent.bio/blog/editing-the-human-genome-with-ai">Link</a>]</p>
</blockquote>
<p>Berkeley based startup Profluent Bio used an AI based protein language model to create and train on an entirely new library of Cas proteins that do not exist in nature today and eventually find one called ‘OpenCRISPR-1’ that is able to replace or improve the ones that are on the market today. The goal of this AI model is to learn what sequence of DNA generated what structure of protein that’s really good at gene editing. The new library of Cas proteins is created by simulation of trillions of letters. They made ‘OpenCRISPR-1’ publicly available under an open source license so anyone can use this particular Cas protein.</p>
<blockquote>
<p><strong>Sony and Apollo in Talks to Acquire Paramount</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/05/05/business/media/sony-apollo-paramount.html">Link</a>]</p>
</blockquote>
<p>Paramount’s stock declined 44% in 2022 and another 12% in 2023. It’s experiencing declining revenue as consumers abandon traditional pay-TV and it’s losing streaming business. Berkshire sold its entire Paramount shares in March 2023 and soon Sony Pictures and Apollo Globals Management reached out to Paramount board expressing interest of acquisition. Now Paramount decided to open negotiation with them after exclusive talks with Hollywood studio Skydance. This deal would break the Paramount and potentially transform the media landscape if successful. Otherwise an office of the CEO as the replacement of CEO Bob Bakish will be preparing a long term plan for the company.</p>
<blockquote>
<p><strong>AlphaFold 3 predicts the structure and interactions of all of life’s molecules</strong> [<a target="_blank" rel="noopener" href="https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/">Link</a>]</p>
</blockquote>
<p>Previously, Google DeepMind AlphaFold project took 3D images of proteins and the DNA sequence that codes for those proteins and then they built a predictive model that predicted the 3D structure of protein base on DNA sequence. What is difference in AlphaFold 3 is that all small molecules are included. The way how small molecules are bind together with the protein is part of the predictive model. This is a breakthrough in that off target effect could be minimized by taking consideration of other molecules’ interactions in the biochemistry environment. Google has a drug development subsidiary called Isomorphic Labs. They kept all of IP for AlphaFold 3. They published a web viewer for non-commercial scientists to do fundamental research but only Isomorphic Labs can make it for commercial use. </p>
<blockquote>
<p><strong>Introducing GPT-4o and making more capabilities available for free in ChatGPT</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/spring-update/">Link</a>]</p>
</blockquote>
<p>I missed the live announcement but watched the recording. GPT-4o is amazing.</p>
<p>One of the interesting technical difference made is tokenizer delta. GPT-4 and GPT-4-Turbo both had a tokenizer with a vocabulary of 100k tokens. GPT-4o has a tokenizer with 200k tokens to work better for native multimodality and multilingualism. The more tokens the more efficient in generating characters.</p>
<blockquote>
<p><em>“Our goal is to make it effortless for people to go anywhere and get anything,” said Dara Khosrowshahi, CEO of Uber. “We’re excited that this new strategic partnership with Instacart will bring the magic of Uber Eats to even more consumers, drive more business for restaurants, and create more earnings opportunities for couriers.”</em></p>
<h5 id="―-Uber-Eats-to-Power-Restaurant-Delivery-on-Instacart-Link"><a href="#―-Uber-Eats-to-Power-Restaurant-Delivery-on-Instacart-Link" class="headerlink" title="―  Uber Eats to Power Restaurant Delivery on Instacart [Link]"></a>―  Uber Eats to Power Restaurant Delivery on Instacart [<a target="_blank" rel="noopener" href="https://investor.uber.com/news-events/news/press-release-details/2024/Uber-Eats-to-Power-Restaurant-Delivery-on-Instacart/">Link</a>]</h5></blockquote>
<blockquote>
<p><strong>Project Astra: Our vision for the future of AI assistants</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=nXVvvRhiGjI&ab_channel=Google">Link</a>]</p>
<p><strong>Google Keynote (Google I&#x2F;O 24’)</strong> [<a target="_blank" rel="noopener" href="https://io.google/2024/explore/a6eb8619-5c2e-4671-84cb-b938c27103be/">Link</a>]</p>
</blockquote>
<p>This developer conference is about Google’s AI related product updates. Highlighted features: 1) AI Overview for search 2) Ask Photos, 3) 2M context window, 4) Google Workspace, 5) NotebookLM, 6) Project Astra, 7) Imagen 3, 8) Music AI Sandbox, 9) Veo, 10) Trillium TPU, 11) Google Serach, 12) Asking Questions with Videos, 13) Gemini interacting with Gmail and data, 14) Gemini AI Teammate, 15) Gemini App, and upgrades, 16) Gemini Trip Planning.</p>
<blockquote>
<p><em>Leike went public with some reasons for his resignation on Friday morning. “I have been disagreeing with OpenAI leadership about the company’s core priorities for quite some time, until we finally reached a breaking point,” Leike wrote in a series of posts on X. “I believe much more of our bandwidth should be spent getting ready for the next generations of models, on security, monitoring, preparedness, safety, adversarial robustness, (super)alignment, confidentiality, societal impact, and related topics. These problems are quite hard to get right, and I am concerned we aren’t on a trajectory to get there.”</em></p>
<p><strong>―  OpenAI created a team to control ‘superintelligent’ AI — then let it wither, source says</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/05/18/openai-created-a-team-to-control-superintelligent-ai-then-let-it-wither-source-says/">Link</a>]</p>
</blockquote>
<blockquote>
<p>Other News:</p>
<p><strong>Encampment Protesters Set Monday Deadline for Harvard to Begin Negotiations</strong> [<a target="_blank" rel="noopener" href="https://www.thecrimson.com/article/2024/5/3/yard-encampment-negotiation-deadline/">Link</a>]</p>
<p><strong>Israel Gaza war: History of the conflict explained</strong> [<a target="_blank" rel="noopener" href="https://www.bbc.com/news/newsbeat-44124396">Link</a>]</p>
<p><strong>Cyber Stuck: First Tesla Cybertruck On Nantucket Has A Rough Day</strong>  [<a target="_blank" rel="noopener" href="https://nantucketcurrent.com/news/cyber-stuck-first-tesla-cybertruck-on-nantucket-has-a-rough-day">Link</a>]</p>
<p><strong>Apple apologizes after ad backlash</strong> [<a target="_blank" rel="noopener" href="https://www.linkedin.com/news/story/apple-apologizes-after-ad-backlash-6024884/">Link</a>]</p>
<p><strong>Apple nears deal with OpenAI to put ChatGPT on iPhone: Report</strong> [<a target="_blank" rel="noopener" href="https://www.businesstoday.in/technology/news/story/apple-nears-deal-with-openai-to-put-chatgpt-on-iphone-report-429178-2024-05-11">Link</a>] [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-05-11/apple-closes-in-on-deal-with-openai-to-put-chatgpt-on-iphone">Link</a>]</p>
<p><strong>Reddit announces another big data-sharing AI deal — this time with OpenAI</strong> [<a target="_blank" rel="noopener" href="https://www.businessinsider.com/reddit-openai-deal-ai-data-partnership-2024-5">Link</a>]</p>
<p><strong>Apple Will Revamp Siri to Catch Up to Its Chatbot Competitors</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/05/10/business/apple-siri-ai-chatgpt.html?unlocked_article_code=1.q00.NlEa.TZR9DORdS4C-&smid=url-share">Link</a>]</p>
<p><strong>OpenAI strikes deal to bring Reddit content to ChatGPT</strong> [<a target="_blank" rel="noopener" href="https://www.reuters.com/markets/deals/openai-strikes-deal-bring-reddit-content-chatgpt-2024-05-16/">Link</a>]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/05/11/Is-AI-a-Bubble/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/digital-di/2024/05/11/Is-AI-a-Bubble/" class="post-title-link" itemprop="url">Is AI a Bubble?</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-05-11 23:54:35" itemprop="dateCreated datePublished" datetime="2024-05-11T23:54:35-04:00">2024-05-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-12 15:05:09" itemprop="dateModified" datetime="2024-05-12T15:05:09-04:00">2024-05-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><em>Random words:</em></p>
<p><em>Feeling deep loneliness on New York City’s bustling streets. When I was in small town, I’ve never said goodbye such frequently.</em></p>
<p>Back to the topic:</p>
<p>When we talk about investment, we talk about economic values. Current situation of AI is very similar to Cisco’s in 2000. Cisco as an internet company spread the capacity of the World Wide Web, but sooner people realized that there is no economic value in internet company, instead, opportunities are in e-commerce etc. AI is a tool very similar to web tech. Currently, with heightened expectations, people are allocating investments and capital expenditure in AI model development, however, end-user demand is unclear and revenue is relatively minimal. This situation makes AI look like a bubble from a very long term perspective.</p>
<p>Stepping closer to it, there is still room in the market to party. GPUs for training and inference are increasingly on demand. First round of beneficiaries are Cloud and Ad. Second round could be hardware or something else. Although it looks like a Capitalism’s scam which is getting more money to the big tech, as small open-source models are released, moats are expected to be  disintegrated and distributed. I’ve seen more and more enterprises going to have Gen AI integrated to their business or operation now. Enterprise is going to be continuously transformed to be more efficient and productive, as well as human life with this long lasting attention on AI. This kind of long lasting attention and consistent innovation are something different from internet tech in 2000 and will probably create a momentum against bubble.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/digital-di/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/digital-di/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/digital-di/js/comments.js"></script><script src="/digital-di/js/utils.js"></script><script src="/digital-di/js/motion.js"></script><script src="/digital-di/js/schemes/muse.js"></script><script src="/digital-di/js/next-boot.js"></script>

  






  





</body>
</html>
