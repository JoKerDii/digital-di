<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/digital-di/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/digital-di/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/digital-di/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/digital-di/images/logo.svg" color="#222">

<link rel="stylesheet" href="/digital-di/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/digital-di/","images":"/digital-di/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/digital-di/js/config.js"></script>

    <meta name="description" content="Substack You don’t get paid for working hard. You get paid based on how hard you are to replace. You get paid based on how much value you deliver. Focus on being able to produce value and money will f">
<meta property="og:type" content="article">
<meta property="og:title" content="2024 April">
<meta property="og:url" content="https://jokerdii.github.io/digital-di/2024/04/13/2024-April/index.html">
<meta property="og:site_name" content="Digital Di">
<meta property="og:description" content="Substack You don’t get paid for working hard. You get paid based on how hard you are to replace. You get paid based on how much value you deliver. Focus on being able to produce value and money will f">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jokerdii.github.io/digital-di/images/ins_emails1.JPG">
<meta property="og:image" content="https://jokerdii.github.io/digital-di/images/ins_emails2.JPG">
<meta property="og:image" content="https://jokerdii.github.io/digital-di/images/ins_emails3.JPG">
<meta property="og:image" content="https://jokerdii.github.io/digital-di/images/ins_emails4.JPG">
<meta property="article:published_time" content="2024-04-14T03:48:32.000Z">
<meta property="article:modified_time" content="2024-04-23T04:10:38.570Z">
<meta property="article:author" content="Di Zhen">
<meta property="article:tag" content="readings">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jokerdii.github.io/digital-di/images/ins_emails1.JPG">


<link rel="canonical" href="https://jokerdii.github.io/digital-di/2024/04/13/2024-April/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jokerdii.github.io/digital-di/2024/04/13/2024-April/","path":"2024/04/13/2024-April/","title":"2024 April"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>2024 April | Digital Di</title>
  








  <noscript>
    <link rel="stylesheet" href="/digital-di/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/digital-di/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Digital Di</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Substack"><span class="nav-number">1.</span> <span class="nav-text">Substack</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Harvard-Business-Review"><span class="nav-number">2.</span> <span class="nav-text">Harvard Business Review</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#News"><span class="nav-number">3.</span> <span class="nav-text">News</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Interviews"><span class="nav-number">4.</span> <span class="nav-text">Interviews</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Papers-and-Reports"><span class="nav-number">5.</span> <span class="nav-text">Papers and Reports</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/digital-di/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/04/13/2024-April/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Digital Di">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="2024 April | Digital Di">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2024 April
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-13 23:48:32" itemprop="dateCreated datePublished" datetime="2024-04-13T23:48:32-04:00">2024-04-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-23 00:10:38" itemprop="dateModified" datetime="2024-04-23T00:10:38-04:00">2024-04-23</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h4 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a><strong>Substack</strong></h4><blockquote>
<p><em>You don’t get paid for working hard.</em></p>
<p><em>You get paid based on how hard you are to replace.</em></p>
<p><em>You get paid based on how much value you deliver.</em></p>
<p><em>Focus on being able to produce value and money will follow.</em></p>
<p><strong>―  Andrew Lokenauth</strong></p>
</blockquote>
<p>What he’s saying is so true - Don’t work so hard and end up losing yourself. I’m glad I followed this guy.</p>
<blockquote>
<p><em>There is a popular saying on Wall Street. While IPO means Initial Public Offering, it also means “It’s Probably Overpriced” (coined by Ken Fisher).</em></p>
<p><em>I don’t invest in brand-new IPOs during the first six months. Why? Shares tend to underperform out of the gate for new public companies and often bottom around the tail end of the lock-up period, with anticipation of selling pressure from insiders.  It’s also critical to gain insights from the first few quarters to form an opinion about the management team.</em></p>
<ul>
<li><em>Do they forecast conservatively?</em></li>
<li><em>Do they consistently beat their guidance?</em></li>
</ul>
<p><em>If not, it might be a sign that they are running out of steam and may have embellished their prospects in the S-1. But we need several quarters to understand the dynamic at play.</em></p>
<p><strong>―  “Rubrik IPO: Key Takeaways”, App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/rubrik-ipo-key-takeaways">Article</a>]</p>
</blockquote>
<p>An analysis of Rubrik, a Microsoft-backed cybersecurity company going public. I’ve got some opinions from the author in terms of company performance and strategic investment.</p>
<blockquote>
<p><strong>Intel Unleashes Enterprise AI with Gaudi 3</strong> [<a target="_blank" rel="noopener" href="https://aisupremacy.substack.com/p/intel-unleashes-enterprise-ai-with">Link</a>]</p>
</blockquote>
<p>It seems Intel was a huge beneficiary of Biden’s CHIPS Act. In late March 2024, Intel will receive up to $8.5 billion in grants and $11 billion in loans from the US government to produce cutting-edge semiconductors.</p>
<blockquote>
<p><strong>US Banks: Uncertain Year</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/us-banks-uncertain-year">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Formula 1 Economics</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/formula-1-economics?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Boeing vs Airbus</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/boeing-vs-airbus?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The End of the “Best Open LLM”</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/compute-efficient-open-llms?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>We disagree on what open-source AI should mean</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/flavors-of-open-source-ai?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>DBRX: The new best open model and Databricks’ ML strategy</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/databricks-dbrx-open-llm?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Llama 3: Scaling open LLMs to AGI</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/llama-3-and-scaling-open-llms?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<h4 id="Harvard-Business-Review"><a href="#Harvard-Business-Review" class="headerlink" title="Harvard Business Review"></a><strong>Harvard Business Review</strong></h4><blockquote>
<p><em>As Columbia Business School professor Rita McGrath points out, it’s about identifying “the strategic inflection points” at which the cost of waiting exceeds to cost acting — in other words, identifying the most strategic point to enter a market or adopt a technology, balancing the risks and opportunities based on market readiness, technological maturity and organizational capacity.</em></p>
<p><em>This speaks to the growing adoption of agile, “act, learn, build” approaches over traditional “prove-plan-execute” orientations. The popularity of techniques like <a target="_blank" rel="noopener" href="https://hbr.org/1995/07/discovery-driven-planning">discovery-driven planning</a>, <a target="_blank" rel="noopener" href="https://hbr.org/2013/05/why-the-lean-start-up-changes-everything">the lean startup</a>, and other agile approaches and propagated this philosophy in which, rather than building bullet-proof business cases, one makes small steps, learning from them, and deciding whether to invest further.</em></p>
<p><strong>―  “6 Strategic Concepts That Set High-Performing Companies Apart”, Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/03/6-strategic-concepts-that-set-high-performing-companies-apart">Article</a>]</p>
</blockquote>
<p>It’s a very good read. It provided real world business examples such as Nvidia’s partnership with ARM Holdings and Amazon’s Alexa offering for the strategic concept “borrow someone’s road”, Microsoft’s decision to make Office available on Apple’s iOS devices in 2014 and Microsoft’s partnership with Adobe, Salesforce, and Google for the strategic concept “Parter with a third party”, Deere &amp; Co’s decision on openly investing in precision agriculture technologies for the strategic concept “reveal your strategy”, Mastercard’s “Beyond Cash” initiative in 2012 for the strategic concept “be good”, Ferrari’s strategic entry into the luxury SUV market for the strategic concept “let the competition go”, and Tesla’s modular approach to battery manufacturing for the strategic concept “adopt small scale attacks”. </p>
<blockquote>
<p><em>Gig work is structured in a way that strengthens the alignment between customers and companies and deepens the divide between customers and workers, leading to systemic imbalances in its service triangle.</em> </p>
<p><em>Bridging the customer-worker divide can result in higher customer trust and platform commitment, both by the customer and the worker.</em> </p>
<p><em>To start, platforms need to increase transparency, reduce information asymmetry, and price their services clearly, allowing customers to better understand what they are paying for rather than only seeing an aggregated total at the end of the transaction. This, in turn, can help customers get used to the idea that if workers are to be paid fairly, gig work cannot be a free or low-cost service.</em></p>
<p><em>Gig workers might be working through an app, but they are not robots, and they deserve to be treated respectfully and thoughtfully. So tip well, rate appropriately, and work together to make the experience as smooth as possible both for yourself and for workers.</em></p>
<p><strong>―  “How Gig Work Pits Customers Against Workers”, Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2024/04/how-gig-work-pits-customers-against-workers">Article</a>]</p>
</blockquote>
<p>This is a good article for better understanding how gig work structured differently than other business model, and what the key points are for better business performance and triangle relationships.</p>
<blockquote>
<p><em>TCP&#x2F;IP unlocked new economic value by dramatically lowering the cost of connections. Similarly, blockchain could dramatically reduce the cost of transactions. It has the potential to become the system of record for all transactions. If that happens, the economy will once again undergo a radical shift, as new, blockchain-based sources of influence and control emerge.</em></p>
<p><em>“Smart contracts” may be the most transformative blockchain application at the moment. These automate payments and the transfer of currency or other assets as negotiated conditions are met. For example, a smart contract might send a payment to a supplier as soon as a shipment is delivered. A firm could signal via blockchain that a particular good has been receivedor the product could have GPS functionality, which would automatically log a location update that, in turn, triggered a payment. We’ve already seen a few early experiments with such self-executing contracts in the areas of venture funding, banking, and digital rights management.</em></p>
<p><em>The implications are fascinating. Firms are built on contracts, from incorporation to buyer-supplier relationships to employee relations. If contracts are automated, then what will happen to traditional firm structures, processes, and intermediaries like lawyers and accountants? And what about managers? Their roles would all radically change. Before we get too excited here, though, let’s remember that we are decades away from the widespread adoption of smart contracts. They cannot be effective, for instance, without institutional buy-in. A tremendous degree of coordination and clarity on how smart contracts are designed, verified, implemented, and enforced will be required. We believe the institutions responsible for those daunting tasks will take a long time to evolve, And the technology challenges especially security are daunting.</em></p>
<p><strong>―  “The Truth About Blockchain”, Harvard Business Review</strong> [<a target="_blank" rel="noopener" href="https://hbr.org/2017/01/the-truth-about-blockchain">Article</a>]</p>
</blockquote>
<p>This is the second Blockchain related article I have read from Harvard Business Review. Different authors have different perspectives. Unlike the previous article with a lot of concerns and cautions about Web3, this article seems more optimistic. It proposed a framework for adopting blockchain to revolutionize modern business, and a guidance to Blockchain investment. It points out that Blockchain has great potentials in boosting the efficiency and reducing the cost for all transactions and then explained the reason why the adoption of Blockchain would be slow by making a comparison with TCP&#x2F;IP, which took more than 30 years to reshape the economy by dramatically lowering the cost of connections. This is an interesting comparison: e-mail enabled bilateral messaging as the first application of TCP&#x2F;IP, while bitcoin enables bilateral financial transactions as the first application of Blockchain. It reminds me about what people (Jun Lei, Huateng Ma, Lei Ding, etc) were thinking about internet mindset and business model back in 2000s.</p>
<p>In the end, the authors proposed a four-quadrant framework for adopting Blockchain step by step. The four quadrants are created by two dimensions: novelty (equivalent to the amount of efforts required to ensure users understand the problem) and complexity (equivalent to the amount of coordination and collaboration required to produce values). With the increase of both dimensions, the adoption will require more institutional change. An example of “low novelty and low complexity” is simply adding bitcoin as an alternative transaction method. An example of “low novelty and high complexity” is building a new, fully formed cryptocurrency system which requires wide adoption from every monetary transaction party and consumers’ complete understanding of cryptocurrency. An example of “high novelty and low complexity” is building a local private network on which multiple organizations are connected via a distributed ledger. An example of “high novelty and high complexity” is building “smart contracts”.</p>
<h4 id="News"><a href="#News" class="headerlink" title="News"></a><strong>News</strong></h4><blockquote>
<p><strong>Does Amazon’s cashless Just Walk Out technology rely on 1,000 workers in India?</strong> [<a target="_blank" rel="noopener" href="https://www.usatoday.com/story/money/shopping/2024/04/04/amazon-just-walk-out-indian-workers/73204975007/">Link</a>]</p>
<p><strong>Amazon insists Just Walk Out isn’t secretly run by workers watching you shop</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/4/17/24133029/amazon-just-walk-out-cashierless-ai-india">Link</a>]</p>
<p><strong>An update on Amazon’s plans for Just Walk Out and checkout-free technology</strong> [<a target="_blank" rel="noopener" href="https://www.aboutamazon.com/news/retail/amazon-just-walk-out-dash-cart-grocery-shopping-checkout-stores">Link</a>]</p>
</blockquote>
<p>It’s been reported that there are over 1000 Indian workers behind the cameras of Just Walk Out. It sounds dystopian and reminds me of “Snowpiercer” movie in 2013. In 2022, about 700 of every 1000 Just Walk Out sales had to be reviewed by Amazon’s team in India, according to The Information. Amazon spokesperson explained that the technology is made by AI (computer vision and deep learning) while it does rely on human moderators and data labelers. Amazon clarified that it’s not true that Just Walk Out relies on human reviewers. They said object detection and receipt generation are completely AI powered, so no human watching live videos. But human are responsible for labeling and annotation for data preparation, which also requires watching videos.</p>
<p>I guess the technology was not able to complete the task end-to-end by itself without supervision or it’s still on the developing stage? I believe it could be Amazon’s strategy to build and test Just Walk Out, Amazon Dash Cart, and Amazon One at the same time while improving AI system, since they are “just getting started”. As Amazon found out that customers prefer Dash Cart in large stores, it has already expanded Dash Cart to all Amazon Fresh stores as well as third-party grocers. And customers prefer Just Walk Out in small stores, so it’s available now in 140+ thrid-party locations. Customers love Amazon One’s security and convenience regardless the scale of stores, so it’s now available at 500+ Whole Foods Market stores, some Amazon stores, and 150+ third-party locations.</p>
<blockquote>
<p><em>Data centres consume water directly to prevent information technology equipment from overheating. They also consume water indirectly from coal-powered electricity generation.</em></p>
<p><em>The report said that if 100 million users had a conversation with ChatGPT, the chatbot “would consume 50,000 cubic metres of water – the same as 20 Olympic-sized swimming pools – whereas the equivalent in Google searches would only consume one swimming pool”.</em></p>
<p><strong>―  China’s thirsty data centres, AI industy could use more water than size of South Korea’s population by 2030: report warns</strong> [<a target="_blank" rel="noopener" href="https://www.scmp.com/news/china/science/article/3259230/chinas-growing-data-centres-and-ai-industry-could-strain-scarce-water-resources-according-new-report?utm_source=copy-link&utm_campaign=3259230&utm_medium=share_widget">Link</a>]</p>
</blockquote>
<p>The rapid growth of AI could dramatically increase demand on water resources. AI eats tokens, consumes compute, and drinks water.</p>
<blockquote>
<p><strong>15 Graphs That Explain the State of AI in 2024</strong> [<a target="_blank" rel="noopener" href="https://spectrum.ieee.org/ai-index-2024">Link</a>]</p>
</blockquote>
<p>Stanford Institute for Human-Centered Artificial Intelligence (HAI) published 2024’s AI Index report [<a target="_blank" rel="noopener" href="https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf">Link</a>]. 502-page reading journey started.</p>
<blockquote>
<p><img src="/digital-di/./images/ins_emails1.JPG" alt="ins_emails1"></p>
<p><img src="/digital-di/./images/ins_emails2.JPG" alt="ins_emails2"></p>
<p><img src="/digital-di/./images/ins_emails3.JPG" alt="ins_emails3"></p>
<p><img src="/digital-di/./images/ins_emails4.JPG" alt="ins_emails4"></p>
<p><strong>―  Leaked emails reveal why Mark Zuckerberg bought Instagram</strong> [<a target="_blank" rel="noopener" href="https://www.cnbctv18.com/business/leaked-emails-reveal-why-mark-zuckerberg-bought-instagram-19399861.htm">Link</a>]</p>
</blockquote>
<p>Zuckerberg’s discussion of Instagram acquisition back in 2012 proved his corporate strategic foresights. He was aiming to buy the time and network effect, rather than simply neutralizing competitors or improving products. He bought Instagram for $1B, today it is worth $500B. It’s very impressive.</p>
<blockquote>
<p><strong>Introducing Meta Llama 3: The most capable openly available LLM to date</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/meta-llama-3/">Link</a>]</p>
</blockquote>
<p>Meta released early versions of Llama 3. Pretrained and instruction-fine-tuned Llama3 with 8B and 70B parameters are now open-source. Its 405B version is still training.</p>
<blockquote>
<p><em>The race to lead A.I. has become a desperate hunt for the digital data needed to advance the technology. To obtain that data, tech companies including OpenAI, Google and Meta have cut corners, ignored corporate policies and debated bending the law, according to an examination by The New York Times.</em></p>
<p><em>Tech companies are so hungry for new data that some are developing “synthetic” information. This is not organic data created by humans, but text, images and code that A.I. models produce — in other words, the systems learn from what they themselves generate.</em></p>
<p><strong>―  How Tech Giants Cut Corners to Harvest Data for A.I.</strong> [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html">Link</a>]</p>
</blockquote>
<p>OpenAI developed a speech recognition tool ‘Whisper’ to transcribe the audio from YouTube videos, generating text data for AI system. Google employees know OpenAI had harvested YouTube videos for data but they didn’t stop OpenAI because Google had also used transcripts of YouTube videos for training AI models. Google’s rules about the legal usage of YouTube videos is vague and OpenAI’s employee were wading into a legal gray area.</p>
<p>As many tech companies such as Meta and OpenAI reached the stage of data shortage, OpenAI started to train AI models by using synthetic data synthesized by two different AI models, one produces the data, the other judges the information.</p>
<blockquote>
<p><strong>Grok-1.5 Vision Preview</strong> [<a target="_blank" rel="noopener" href="https://x.ai/blog/grok-1.5v">Link</a>]</p>
</blockquote>
<p>Musk released the preview of first multimodal model Grok-1.5V. It is able to understand both textual and visual information. One unique feature is that it adopts Rust, JAX, and Kubernetes to construct its distributed training architecture.</p>
<blockquote>
<p><em>One page of the Microsoft presentation highlights a variety of “common” federal uses for OpenAI, including for defense. One bullet point under “Advanced Computer Vision Training” reads: “Battle Management Systems: Using the DALL-E models to create images to train battle management systems.” Just as it sounds, a battle management system is a command-and-control software suite that provides military leaders with a situational overview of a combat scenario, allowing them to coordinate things like artillery fire, airstrike target identification, and troop movements. The reference to computer vision training suggests artificial images conjured by DALL-E could help Pentagon computers better “see” conditions on the battlefield, a particular boon for finding — and annihilating — targets.</em></p>
<p><em>OpenAI spokesperson Liz Bourgeous said OpenAI was not involved in the Microsoft pitch and that it had not sold any tools to the Department of Defense. “OpenAI’s policies prohibit the use of our tools to develop or use weapons, injure others or destroy property,” she wrote. “We were not involved in this presentation and have not had conversations with U.S. defense agencies regarding the hypothetical use cases it describes.”</em></p>
<p><em>Microsoft told The Intercept that if the Pentagon used DALL-E or any other OpenAI tool through a contract with Microsoft, it would be subject to the usage policies of the latter company. Still, any use of OpenAI technology to help the Pentagon more effectively kill and destroy would be a dramatic turnaround for the company, which describes its mission as developing safety-focused artificial intelligence that can benefit all of humanity.</em></p>
<p><strong>―  Microsoft Pitched OpenAI’s DALL-E as Battlefield Tool for U.S. Military</strong>  [<a target="_blank" rel="noopener" href="https://theintercept.com/2024/04/10/microsoft-openai-dalle-ai-military-use/">Link</a>]</p>
</blockquote>
<p>Other than what has mentioned in the news, by cooperating with Department of Defense, AI can understand how human battle and defense, which is hard to learn from current textual and visual information from the internet. So it’s possible that this is the first step of AI troop.</p>
<blockquote>
<p><em>Microsoft scientists developed what they call a qubit virtualization system. This combines quantum error-correction techniques with strategies to determine which errors need to be fixed and the best way to fix them.</em></p>
<p><em>The company also developed a way to diagnose and correct qubit errors without disrupting them, a technique it calls “active syndrome extraction.” The act of measuring a quantum state such as superposition typically destroys it. To avoid this, active syndrome extraction instead learns details about the qubits that are related to noise, as opposed to their quantum states, Svore explains. The ability to account for this noise can permit longer and more complex quantum computations to proceed without failure, all without destroying the logical qubits.</em> </p>
<p><strong>―  Microsoft Tests New Path to Reliable Quantum Computers 1,000 physical qubits for each logical one? Try a dozen, says Redmond</strong> [<a target="_blank" rel="noopener" href="https://spectrum.ieee.org/microsoft-quantum-computer-quantinuum">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Think about it in the sense of another broad, diverse category like cars. When they were first invented, you just bought “a car.” Then a little later, you could choose between a big car, a small car, and a tractor. Nowadays, there are hundreds of cars released every year, but you probably don’t need to be aware of even one in ten of them, because nine out of ten are not a car you need or even a car as you understand the term. Similarly, we’re moving from the big&#x2F;small&#x2F;tractor era of AI toward the proliferation era, and even AI specialists can’t keep up with and test all the models coming out.</em></p>
<p><strong>―  Too Many Models</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/04/19/too-many-models/">Link</a>]</p>
</blockquote>
<p>This week, the speed of releasing LLMs becomes about 10 per week. This article provides good explanation about why we don’t need to keep up with it or test all released models. Car is a good analogy to AI model nowadays. There are all kinds of brands and sizes, and designed for different purposes. Hundreds of cars are released every year, but you don’t need to know them. Majority of the models are not groundbreaking but whenever there is big step, you will be aware of it.  </p>
<blockquote>
<p><strong>Our next-generation Meta Training and Inference Accelerator</strong>  [<a target="_blank" rel="noopener" href="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/">Link</a>]</p>
<p><strong>Meta’s new AI chips run faster than before</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/4/10/24125924/meta-mtia-ai-chips-algorithm-training">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Stable Diffusion 3</strong> [<a target="_blank" rel="noopener" href="https://stability.ai/news/stable-diffusion-3">Link</a>]</p>
<p><strong>Stable Diffusion 3 API now available as Stable Assistant effort looms</strong> [<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/stable-diffusion-3-api-now-available-as-stable-assist-effort-looms/">Link</a>]</p>
<p><strong>Stable Diffusion 3: Research Paper</strong> [<a target="_blank" rel="noopener" href="https://stability.ai/news/stable-diffusion-3-research-paper">Link</a>]</p>
</blockquote>
<blockquote>
<p>Other news:</p>
<p><strong>Elon Musk says Tesla will reveal its robotaxi on August 8th</strong> [<a target="_blank" rel="noopener" href="https://www.theverge.com/2024/4/5/24122384/tesla-robotaxi-reveal-date-elon-musk-august-8">Link</a>]</p>
<p><strong>SpaceX launches Starlink satellites on record 20th reflight of a Falcon 9 rocket first stage</strong> [<a target="_blank" rel="noopener" href="https://www.space.com/spacex-falcon-9-20th-launch-starlink-group-6-49">Link</a>]</p>
<p><strong>Deploy your Chatbot on Databricks AI with RAG, DBRX Instruct, Vector Search &amp; Databricks Foundation Models</strong> [<a target="_blank" rel="noopener" href="https://notebooks.databricks.com/demos/llm-rag-chatbot/index.html">Link</a>]</p>
<p><strong>Adobe’s ‘Ethical’ Firefly AI Was Trained on Midjourney Images</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2024-04-12/adobe-s-ai-firefly-used-ai-generated-images-from-rivals-for-training">Link</a>]</p>
<p><strong>Exclusive: Microsoft’s OpenAI partnership could face EU antitrust probe, sources say</strong> [<a target="_blank" rel="noopener" href="https://www.reuters.com/technology/microsofts-openai-partnership-could-face-eu-antitrust-probe-sources-say-2024-04-18/">Link</a>]</p>
</blockquote>
<h4 id="Interviews"><a href="#Interviews" class="headerlink" title="Interviews"></a><strong>Interviews</strong></h4><blockquote>
<p> <em>If someone whom you don’t trust or an adversary gets something more powerful, then I think that that could be an issue. Probably the best way to mitigate that is to have good open source AI that becomes the standard and in a lot of ways can become the leader. It just ensures that it’s a much more even and balanced playing field.</em></p>
<p><strong>―  Mark Zuckerberg - Llama 3, $10B Models, Caesar Augustus, &amp; 1 GW Datacenters</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=bc6uFV9CJGg">Link</a>]</p>
</blockquote>
<p>What I learned from this interview: The future of Meta AI would be a kind of AI general assistant product where you give it complicated tasks and then it goes away and does them. Meta will probably build bigger clusters. No one has built 1GW data center yet but building it could just be a matter of time. Open source can be both bad and good. People can use LLM to do harmful things, while what Mask worries more about is the concentration of AI, where there is an untrustworthy actor having the super strong AI. Open source software can make AI not getting stuck in one company but can be broadly deployed to a lot of different systems. People can set standards on how it works and AI can get checked and upgraded together. </p>
<blockquote>
<p><em>It is clear that inference was going to be a scaled problem. Everyone else had been looking at inference as you take one chip, you run a model on it, it runs whatever. But what happened with AlphaGo was we ported the software over, and even though we had 170 GPUs vs 48 TPUs, the 48 TPUs won 99 out of 100 games with the exact same software. What that meant was compute was going to result in better performance. And so the insight was - let’s build scaled inference.</em></p>
<p><em>(Nvidia) They have the ecosystem. It’s a double-sided market. If they have a kernel-based approach they already won. There’s no catching up. The other way that they are very good is vertical integration and forward integration. What happens is Nvidia over and over again decides that they want to move up the stack, and whatever the customers are doing, they start doing it.</em></p>
<p><em>Nvidia is incredible at training. And I think the design decision that they made including things like HBM, were really oriented around the world back then, which was everything is about training. There weren’t any real world application. None of you guys were really building anything in the wild where you needed super fast inference.</em></p>
<p><em>What we saw over and over again was you would spend 100% of your compute on training, you would get something that would work well enough to go into production, and then it would flip to about 5%-10% training and 90%-95% inference. But the amount of training would stay the same, the inference would grow massively. And so every time we would have a success at Google, all of a sudden, we would have a disaster, we called it the success disaster, where we can’t afford to get enough compute for inference.</em></p>
<p><em>HBM is this High Bandwidth Memory which is required to get performance, because the speed at which you can run these applications depends on how quickly you can read that into memory. There’s a finite supply, it’s only for data centers, so they can’t reach into the supply for mobile or other things, like you can with other parts. Also Nvidia is the largest buyer of super caps in the world and all sorts of other components. The 400 gigabit cables, they’ve bought them all out. So if you want to compete, it doesn’t matter how good of a product you design, they’ve bought out the entire supply chain for years.</em></p>
<p><em>The biggest difference between training and inference is when you are training, the number of tokens that you are training on is measured in month, like how many tokens can we train on this month. In inference, what matters is how many tokens you can generate per millisecond or a couple milliseconds.</em> </p>
<p><em>It’s fair to say that Nvida is the exemplar in training but really isn’t yet the equivalent scaled winner in inference.</em></p>
<p><em>In order to get the latency down, we had to design a completely new chip architecture, we had to design a completely new networking architecture, an entirely new system, an entirely new runtime, an entirely new compiler, and entirely new orchestration layer. We had to throw everything away and it had to be compatible with PyTorch and what other people actually developing in.</em></p>
<p><em>I think Facebook announced that by the end of this year, they are going to have the equivalent of 650000 H100s. By the end of this year, Grok will have deployed 100000 of our LPUs which do outperform the H100s on a throughput and on a latency basis. So we will probably get pretty close to the equivalent of Meta ourselves. By the end of next year, we are going to deploy 1.5M LPUs, for comparison, last year Nvidia deployed a total of 500000 H100s. So 1.5M means Grok will probably have more inference GenAI capacity than all of the hyperscalers and clouds service providers combined. So probably about 50% of the inference compute in the world.</em></p>
<p><em>I get asked a lot should we be afraid of AI and my answer to that is, if  you think back to Galileo, someone who got in a lot of trouble. The reason he got in trouble was he invented the telescope, popularized it, and made some claims that we were much smaller than everyone wanted to believe. The better the telescope got the more obvious it became that we were small. In a large sense, LLMs are the telescope for the mind, it’s become clear that intelligence is larger than we are and it makes us feel really really small and it’s scary. But what happened over time was as we realized the universe was larger than we thought and we got used to that, we started to realize how beautiful it was and our place in the universe. And I think that’s what’s going to happen. We’re going to realize intelligence is more vast than we ever imagined. And we are going to understand our place in it, and we are not going to be afraid of it.</em></p>
<p><strong>―  Conversation with Groq CEO Jonathan Ross</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UneoszmxRGg&ab_channel=SocialCapital">Link</a>]</p>
</blockquote>
<p>This is a very insightful conversation especially in the part of comparison of training and inference. The answer to the final question is fascinating to end the conversation. A great takeaway that “intelligence is a telescope for the mind, in that we realize that we are small, while then also opportunity to see intelligence is vast and to not be afraid of it.”.</p>
<h4 id="Papers-and-Reports"><a href="#Papers-and-Reports" class="headerlink" title="Papers and Reports"></a><strong>Papers and Reports</strong></h4><blockquote>
<p><strong>2024 Generative AI Prediction Report from CB insights</strong> [<a target="_blank" rel="noopener" href="https://www.cbinsights.com/reports/CB-Insights_Generative-AI-Predictions-2024.pdf?utm_medium=email&_hsenc=p2ANqtz-9Ufhxz7mEW7sv4Kc0EtzE3m4UO4cBLN9U0p84fdXvKQQZPt1iee0UEjCqVCV5qhB6FfOI_gGQA4NoVqQbPYL8d8lc1BQ&_hsmi=228539474&utm_content=228539474&utm_source=hs_automation">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>ReALM: Reference Resolution As Language Modeling</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.20329">Link</a>]</p>
</blockquote>
<p>Apple proposed the ReALM model with 80M, 250M, 1B, and 3B parameters. It can be used on mobile devices and laptops. The task of ReALM is “Given relevant entities and a task the user wants to perform, we wish to extract the entity (or entities) that are pertinent to the current user query. “. The relevant entities can be on-screen entities, conversational entities, and background entities. The analysis shows that ReALM beats MARRs and has similar performance with GPT-4.</p>
<blockquote>
<p><strong>Scaling Laws for Neural Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2001.08361.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>CodeGemma: Open Code Models Based on Gemma</strong>  [<a target="_blank" rel="noopener" href="https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.07143.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>OpenEQA: Embodies Question Answering in the Era of Foundation Models</strong> [<a target="_blank" rel="noopener" href="https://open-eqa.github.io/assets/pdfs/paper.pdf">Link</a>] [<a target="_blank" rel="noopener" href="https://open-eqa.github.io/">Link</a>]</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/digital-di/tags/readings/" rel="tag"># readings</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/digital-di/2024/04/13/hello-world/" rel="prev" title="Hello World">
                  <i class="fa fa-angle-left"></i> Hello World
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/digital-di/2024/04/21/Concerns-about-AI/" rel="next" title="Concerns about AI">
                  Concerns about AI <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/digital-di/js/comments.js"></script><script src="/digital-di/js/utils.js"></script><script src="/digital-di/js/motion.js"></script><script src="/digital-di/js/schemes/muse.js"></script><script src="/digital-di/js/next-boot.js"></script>

  






  





</body>
</html>
