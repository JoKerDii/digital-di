<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/digital-di/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/digital-di/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/digital-di/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/digital-di/images/logo.svg" color="#222">

<link rel="stylesheet" href="/digital-di/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/digital-di/","images":"/digital-di/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/digital-di/js/config.js"></script>

    <meta name="description" content="Substack “This incident shows clearly that Windows must prioritize change and innovation in the area of end-to-end resilience. […] Examples of innovation include the recently announced VBS enclaves, w">
<meta property="og:type" content="article">
<meta property="og:title" content="2024-August">
<meta property="og:url" content="https://jokerdii.github.io/digital-di/2024/08/19/2024-August/index.html">
<meta property="og:site_name" content="Di&#39;s Blog">
<meta property="og:description" content="Substack “This incident shows clearly that Windows must prioritize change and innovation in the area of end-to-end resilience. […] Examples of innovation include the recently announced VBS enclaves, w">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jokerdii.github.io/digital-di/images/new-post-training-approach.png">
<meta property="article:published_time" content="2024-08-19T04:04:43.000Z">
<meta property="article:modified_time" content="2024-08-20T04:54:07.742Z">
<meta property="article:author" content="Di Zhen">
<meta property="article:tag" content="readings">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jokerdii.github.io/digital-di/images/new-post-training-approach.png">


<link rel="canonical" href="https://jokerdii.github.io/digital-di/2024/08/19/2024-August/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jokerdii.github.io/digital-di/2024/08/19/2024-August/","path":"2024/08/19/2024-August/","title":"2024-August"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>2024-August | Di's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/digital-di/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/digital-di/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Di's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Substack"><span class="nav-number">1.</span> <span class="nav-text">Substack</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Articles-and-Blogs"><span class="nav-number">2.</span> <span class="nav-text">Articles and Blogs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YouTube-and-Podcasts"><span class="nav-number">3.</span> <span class="nav-text">YouTube and Podcasts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Paper-and-Reports"><span class="nav-number">4.</span> <span class="nav-text">Paper and Reports</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GitHub"><span class="nav-number">5.</span> <span class="nav-text">GitHub</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#News"><span class="nav-number">6.</span> <span class="nav-text">News</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/digital-di/archives/">
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/08/19/2024-August/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="2024-August | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2024-August
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-08-19 00:04:43" itemprop="dateCreated datePublished" datetime="2024-08-19T00:04:43-04:00">2024-08-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-08-20 00:54:07" itemprop="dateModified" datetime="2024-08-20T00:54:07-04:00">2024-08-20</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>“This incident shows clearly that Windows must prioritize change and innovation in the area of end-to-end resilience. […] Examples of innovation include the recently announced VBS enclaves, which provide an isolated compute environment that does not require kernel mode drivers to be tamper resistant.” - John Cable, Microsoft VP of Program management</em></p>
<p><strong>― Microsoft: Azure Slowdown - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/microsoft-azure-slowdown">Link</a>]</p>
</blockquote>
<p>Microsoft Azure decelerated by 1 point sequentially to 30% YoY, while Google Cloud accelerated.</p>
<p>Recent business highlights: 1) global IT outage caused by a faulty update by CrowdStrike affected 8.5 M Windows PCs, 2) Microsoft facing investigation by UK’s CMA over hiring former Inflection AI Staff and the partnership with the startup.</p>
<blockquote>
<p><em>According to <a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/netflix-ad-tech-focus">Nielsen</a>, Prime Video captured <strong>3.1% of US TV Time</strong> in June (a decline of 0.1 points Y&#x2F;Y). Prime Video captures just over a third of Netflix’s market share (and more than Disney+ and Paramount+ combined).</em></p>
<p><em>As Amazon continues to invest in live sports and expand its content catalog, Prime members may find themselves spending more time with the service they already pay for. Prime Video may have started as a loss leader, but if it can become the go-to streaming platform for ad-supported content, it could evolve into a significant revenue driver, even for a behemoth like Amazon.</em></p>
<p><strong>― Amazon: This Team is Cooking - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/amazon-this-team-is-cooking">Link</a>]</p>
</blockquote>
<blockquote>
<ul>
<li><em><strong>Portfolio rebalancing</strong>: Apple stock surged 24% between May 1st and June 30th. As a result, Buffett would have seen AAPL take up nearly 60% of Berkshire’s portfolio. A stake reduction is a typical move to rebalance a portfolio and lower its risk profile.</em></li>
<li><em><strong>Valuation</strong>: Apple is valued above 30 times forward earnings. That makes it less likely to deliver alpha for shareholders. It’s possible Buffett felt like the odds of market-beating returns at this level were subpar.</em> </li>
<li><em><strong>Taxes matter</strong>: Buffett told shareholders in May that he finds the current tax rate on capital gains relatively low, potentially prompting him to realize his significant AAPL gains while the rate is reasonable.</em></li>
<li><em><strong>No place to hide</strong>: Buffett is building up his cash pile and waiting for a “fat pitch.”</em></li>
</ul>
<p><em><strong>The Buffett Indicator</strong></em>:* This ratio compares the total market capitalization of US stocks to the country’s GDP. It’s often used to gauge whether stock valuations in the US are overinflated. It reached <strong>138%</strong> during the dot-com bubble, which was considered high at the time. Low and behold, the indicator hit <strong>190%</strong> at the end of June.*</p>
<p><strong>― Berkshire Slashes Apple Stake - App Economy Insights</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/berkshire-slashes-apple-stake">Link</a>]</p>
</blockquote>
<p>Factors of today’s macro environment: 1) The AI Bubble, 2) The Yen Carry Trade, 3) Potential Recession.</p>
<blockquote>
<p><strong>Llama 3.1’s Impact on China, Kuaishou’s AI Video Generator Goes Global, and Alibaba Backs $2.8B AI Firm - Recode China AI</strong> [<a target="_blank" rel="noopener" href="https://recodechinaai.substack.com/p/llama-31s-impact-on-china-kuaishous">Link</a>]</p>
</blockquote>
<p>Highlights key AI news in China: 1) Kuaishou’s global launch of its AI video generator, Kling AI, and Zhipu AI’s introduction of Ying, show China’s progress in AI video generation. 2) Alibaba, Tencent, and state-backed AI funds poured $690 M into the $2.8 B AI firm Baichuan AI.</p>
<blockquote>
<p><strong>State of AI in Venture Capital 2024 - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/932e0055-a2be-47a8-a898-dc455f777009">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>“AI CapEx” is a euphemism for building physical data centers with land, power, steel and industrial capacity. There’s been a lot of investment in data centers and AI chips, but not AGI in sight. You can buy all the shovels you want, but if the mine ain’t making money, we have a problem. If there’s no gold in the mine, the shovels aren’t worth very much. BigTech hyperscalers and VCs might have gotten this all wrong.</em></p>
<p><strong>― OpenAI’s SearchGPT and the Impossible Promises of AI - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/openais-searchgpt-and-the-impossible">Link</a>]</p>
</blockquote>
<p>This article points out that industry is facing immense financial pressures and strategic uncertainties. The concerns are as follows: 1) OpenAI’s operating costs exceed $ 8 B, with a projected loss of $5 B in 2024, 2) annual AI revenue to justify the investment in data centers and chips is unlikely to be achieved by 2025, 3) integrating SearchGPT into ChatGPT is a risky bet because users don’t use ChatGPT frequently enough for it to be a successful search tool, 4) competitive market has pushed many AI startups out of the market, AI innovation cannot compete with market dominance (e.g. Microsoft’s attempts to integrate AI into Bing), 5) Big tech companies have accepted that they are possibly over-investing in AI due to FOMO (fear of missing out), leading to unsustainable financial practices, 6) Nvidia’s revenue is risky since it comes majorly from a few tech giants.</p>
<blockquote>
<p><em>The Morningstar framework: The framework is built on 5 “moat sources”:</em></p>
<ul>
<li><em>Intangible assets (Coca-Cola)</em></li>
<li><em>Switching Costs (Oracle)</em></li>
<li><em>Network Effects (CME Group)</em></li>
<li><em>Cost Advantages (UPS)</em></li>
<li><em>Efficient Scale (Kinder Morgan)</em></li>
</ul>
<p><strong>― 5 Wide Moat Businesses - Invest in Quality</strong> [<a target="_blank" rel="noopener" href="https://www.investinassets.net/p/5-wide-moat-businesses">Link</a>]</p>
</blockquote>
<p>Intangible assest: Coca-Cola, SANOFI, Unilever, Johnson &amp; Johnson.</p>
<p>Switching Costs: Oracle, Intuitive Surgical, ADP.</p>
<p>Network Effect: Mastercard, eBay, CME Group, Facebook.</p>
<p>Cost Advantage: Amazon, Novo Nordisk.</p>
<p>Efficient Scale: UPS, nationalgrid, Carnival</p>
<blockquote>
<p><strong>AI: Are we in another dot-com bubble? - AI Musings by Mu</strong> [<a target="_blank" rel="noopener" href="https://kelvinmu.substack.com/p/ai-are-we-in-another-dot-com-bubble">Link</a>]</p>
</blockquote>
<p>A comprehensive analysis comparing current AI cycle to the internet&#x2F;telecom cycle of the 90s. The author examines the technological, economic, and capital differences between the two eras and concludes that while a bubble may be inevitable in the long run, we are still far from reaching that point.</p>
<p>Key points:</p>
<p>Similarities between AI cycle since Nov 2022 and internet cycle of the 90s: 1) Both cycles have similar ecosystem structures, with companies providing infrastructure, enablement, and applications. 2) Occur amid equity bull markets, driven by favorable economic conditions. 3) Require significant infrastructure investments. 4) Attract significant VC interest, leading to high valuations.</p>
<p>Differences between AI cycle since Nov 2022 and internet cycle of the 90s: 1) AI companies are generating revenue much earlier than dot-com companies did, with more sustainable business models. 2) The current economic environment is less robust than in the 90s, leading to a more cautious investment climate. 3) AI investments are primarily equity-funded by big tech, unlike the debt-financed dot-com boom. 4) Valuations of AI companies, while high, are more grounded in near-term earnings than those during the dot-com era.</p>
<p>Bubble Likelihood: The article argues that while there are risks, the current AI cycle is less likely to be in a bubble compared to the dot-com era. The more cautious investment environment, sustainable business models, and the structured flow of capital contribute to this conclusion.</p>
<p>Lessons from Dot-Com Bubble: 1) Infrastructure buildouts take time. 2) Being a first mover can be a disadvantage, as seen with early internet companies that were later overtaken by more successful competitors. 3) The importance of being critical and not getting swept up in the hype, learning from the past to navigate the present.</p>
<blockquote>
<p><em>To recap the above post, they do the new normal, including:</em></p>
<ul>
<li><em>Human preference data and <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.08673v1">HelpSteer</a> style grading of attributes for regularization.</em></li>
<li><em>High-quality reward models for filtering.</em></li>
<li><em>Replacement of human demonstrations with model completions in some domains.</em></li>
<li><em>Multi-round RLHF — “We iterate data and model qualities jointly to improve them in a unified flywheel.”</em></li>
<li><em>A very large suite of data curation techniques, including prompt re-writing and refining for expansion of costly datasets, filtering math and code answers with outcomes (correctness or execution), filtering with LLMs-as-a-judge, and other new normal stuff.</em></li>
</ul>
<p><strong>― A recipe for frontier model post-training - Nathan Lambert, Interconnects</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/frontier-model-post-training">Link</a>]</p>
</blockquote>
<p>Recent papers and reports (Llama 3.1, Nemotron 340B, and Apple foundation model) have made it clear that a new default recipe exists for high-quality RLHF. It has a few assumptions:</p>
<ul>
<li>Synthetic data can be of higher quality than humans, especially for demonstrations on challenging tasks.</li>
<li>Reinforcement learning from human feedback (RLHF) can scale far further than instruction tuning.</li>
<li>It takes multiple rounds of training and generation to reach your best model.</li>
<li>Data filtering is the most important part of training.</li>
</ul>
<p>It becomes clear that the post training is highly correlated with the style and robustness gains.</p>
<p>The new normal seems to be converged as follows:</p>
<p><img src="/digital-di/./images/new-post-training-approach.png" alt="post-training"></p>
<blockquote>
<p><strong>OpenAI and Generative AI are at a Crossroads - AI Supremacy</strong> [<a target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/openai-and-generative-ai-are-at-a">Link</a>]</p>
</blockquote>
<p>Views of AI landscape.</p>
<blockquote>
<p><strong>At least five interesting things for your weekend (#45) - Noahpinion</strong> [<a target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/at-least-five-interesting-things-68b">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>GPT-5: Everything You Need to Know - The Algorithmic Bridge</strong> [<a target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/gpt-5-everything-you-need-to-know-10a">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>New LLM Pre-training and Post-training Paradigms - Ahead of AI</strong> [<a target="_blank" rel="noopener" href="https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>You don’t have to be a manager - Elena’s Growth Scoop</strong> [<a target="_blank" rel="noopener" href="https://www.elenaverna.com/p/you-dont-have-to-be-a-manager">Link</a>]</p>
</blockquote>
<h3 id="Articles-and-Blogs"><a href="#Articles-and-Blogs" class="headerlink" title="Articles and Blogs"></a>Articles and Blogs</h3><blockquote>
<p><strong>In the Age of A.I., What Makes People Unique? - The New Yorker</strong> [<a target="_blank" rel="noopener" href="https://www.newyorker.com/culture/open-questions/in-the-age-of-ai-what-makes-people-unique">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How To Get Promoted (Without Getting Lucky) - The Developing Dev</strong> [<a target="_blank" rel="noopener" href="https://www.developing.dev/p/how-to-get-promoted-without-getting">Link</a>]</p>
<p><strong>How to Get Rich (without getting lucky) - Naval @ X</strong> [<a target="_blank" rel="noopener" href="https://x.com/naval/status/1002103360646823936">Link</a>]</p>
</blockquote>
<p>Key takeaways: 1) know what you organization considers impactful, 2) learn to sell your ideas, set directions, grow and help others, 3) build your brand by embracing accountability and sharing your results, 4) become a good collaborator and be transparent to your manager about goals and gaps, 5) protect your focus time - “<strong>what you work on is more important than how hard you work</strong>“, do work that you enjoy and has impact.</p>
<blockquote>
<p><strong>Is Consistency Hurting Your Sustainability? - Leadership Letters</strong> [<a target="_blank" rel="noopener" href="https://www.leadership-letters.com/p/is-consistency-hurting-your-sustainability">Link</a>]</p>
</blockquote>
<p>Key takeaways: 1) it’s ok to be inconsistent sometimes, you should update your plan that respects flexibility, balance priorities, or adjust your expectations, 2) Life is not a sprint, taking a pause and pushing goals to the future is not always bad, 3) consistency is about never giving up, 4) don’t set consistency as a goal, find out what is your real goal, so that accepting and developing “bounce-back” plan is possible</p>
<blockquote>
<p><strong>McKinsey’s 2024 annual book recommendations</strong> [<a target="_blank" rel="noopener" href="https://www.mckinsey.com/featured-insights/annual-book-recommendations">Link</a>]</p>
</blockquote>
<p>Have selected some books and added them into my read list: 1) God, Human, Animal, Machine: Technology, Metaphor, and the Search for Meaning by Meghan O’Gieblyn, 2) Outlive: The Science &amp; Art of Longevity by Peter Attia, 3) The Journey of Leadership: How CEOs Learn to Lead from the Inside Out by Dana Maor, Hans-Werner Kaas, Kurt Strovink, and Ramesh Srinivasan, 4) Slow Productivity: The Lost Art of Accomplishment Without Burnout by Cal Newport, 5) How Legendary Leaders Speak: 451 Proven Communication Strategies of the World’s Top Leaders  by Peter D. Andrei.</p>
<blockquote>
<p><strong>Paid Advertising 101: A Guide for Startup Founders - Kaya</strong> [<a target="_blank" rel="noopener" href="https://www.usekaya.com/blog/paid-advertising-101">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Building A Generative AI Platform - Chip Huyen</strong> [<a target="_blank" rel="noopener" href="https://huyenchip.com/2024/07/25/genai-platform.html">Link</a>]</p>
</blockquote>
<p>This blog post outlines common themes in building generative AI systems. It covers many of the building blocks a company should consider when deploying its models to production. </p>
<blockquote>
<p><strong>AI’s $600B Question - David Cahn, Sequoia</strong> [<a target="_blank" rel="noopener" href="https://www.sequoiacap.com/article/ais-600b-question/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Calculating GPU memory for serving LLMs - Substratus</strong> [<a target="_blank" rel="noopener" href="https://www.substratus.ai/blog/calculating-gpu-memory-for-llm">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Social media for startup founders: A practical guide to building an online presence - a16zcrypto</strong> [<a target="_blank" rel="noopener" href="https://a16zcrypto.com/posts/article/social-media-for-startups-guide/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Long Context RAG Performance of LLMs - Databricks</strong> [<a target="_blank" rel="noopener" href="https://www.databricks.com/blog/long-context-rag-performance-llms">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>An AI engineer’s tips for writing better AI prompts - coda</strong> [<a target="_blank" rel="noopener" href="https://coda.io/blog/ai/ai-engineer-tips-ai-prompts">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Grok-2 Beta Release - X.AI</strong>  [<a target="_blank" rel="noopener" href="https://x.ai/blog/grok-2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How to Prune and Distill Llama-3.1 8B to an NVIDIA Llama-3.1-Minitron 4B Model - NVIDIA Developer</strong> [<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>A practitioner’s guide to testing and running large GPU clusters for training generative AI models - together.ai</strong> [<a target="_blank" rel="noopener" href="https://www.together.ai/blog/a-practitioners-guide-to-testing-and-running-large-gpu-clusters-for-training-generative-ai-models">Link</a>]</p>
</blockquote>
<h3 id="YouTube-and-Podcasts"><a href="#YouTube-and-Podcasts" class="headerlink" title="YouTube and Podcasts"></a>YouTube and Podcasts</h3><blockquote>
<p><strong>Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Kbk9BiPhm7o">Link</a>]</p>
</blockquote>
<p>Eight hours interview..</p>
<blockquote>
<p><strong>Kamala surges, Trump at NABJ, recession fears, Middle East escalation, Ackman postpones IPO - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rj71DPhvpiE">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI and The Next Computing Platforms With Jensen Huang and Mark Zuckerberg - NVIDIA</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=w-cmMcMZoZ4">Link</a>]</p>
</blockquote>
<p>Nvidia CEO Jensen and Zuckerberg discuss the future of AI.</p>
<blockquote>
<p><em>There’s a famous quote from an economist Simon Kuznets who said there’s four kinds of countries in the world there’s developed countries undeveloped countries Japan and Argentina. And I think the reason he said that is that Japan has been in the state since the 90s so they had a massive property and Equity bubble collapse. And they’ve not had to deal with anything that looked like typical economic issues since then and part of it is because the Govern plays a very big hand in the Japanese economy, there’s a lot of price controls there. So I don’t know I’m not sure what it is that we can learn there that you can extrapolate to the rest of the world. - Chamath Palihapitiya</em></p>
<p><em>When you have massive amounts of debt it definitely limits your flexibility. It’s just arithmetic, you are going to pay for it with either economic contraction, higher taxes, or inflation. Those are the three places it goes. - David Sacks &amp; David Friedberg</em></p>
<p><em>Well so it looks like since the start of the year they’ve sold 55% of their Holdings in apple. And if you look at the end of the year, this is what berkshire’s stock Holdings were in their non-majority owned businesses. So businesses that they don’t own the business outright and 50% of their portfolio was in Apple at $174 billion. We obviously saw Apple’s stock price Peak highest level ever just a few days ago, but it has since come down as it was reported that since the start of the year. Now Berkshire sold 55% of this position, so some people are arguing that they’ve got a point of view on the company strategy and comp competitive kind of landscape. Some folks have argued that the valuation multiple has gotten too high trading at nearly 30 times earnings the stock has risen 900% since Berkshire bought the stock in 2016. Bagger nicely done yeah and some people would argue that the percent of the portfolio is too high at over 50%, as you can see here at the start of the year. But you know I’ll kind of provide some of the counterarguments you know Warren Buffett does not do much analysis on corporate strategy when he provides reviews of the stocks that he’s picked he often finds and talks a lot about great managers that generate great returns. And he sticks with them and he sticks with them sometimes for many many decades. The management in this company has not changed the return profile on cash invested and cash returned has only improved since he put money in. They’re generating more cash flow they’re offering more dividends they’re doing more stock BuyBacks and he’s happy to be concentrated over the years he’s made large bets on single companies to the point that sometimes he just outright buys the entire company like he did with. Geico in 1996 he always talks a lot about finding a company that is run by great managers that has a premium product with a nice high margin and a durable moat strong brand value. As I look at kind of what’s really gone on here it feels to me like the difference between Apple and some of the other big Holdings in its portfolio is that many of those other businesses are regulated monopolies. So BNSF Railway is regulated by the Federal Railroad Administration Berkshire energy which owns mid americ is a regulated utility. The prices that they charge consumers are set by the government so they have a market that’s locked in the prices are set they have locked in distribution they have locked in utility value and the same is true in the insurance business. Geico’s rates are approved and set effectively by state Regulators Berkshire has a moat because they’ve got the largest Capital base and they’ve got this machine that just keeps generating cash and the rates are publicly set by government Apple. However is not regulated and it is very clear that apple is facing very deep and severe Financial impact from the regulatory authorities that are overseeing the business so if you look at the Google antitrust we’re going to get into the Google deal in a second. There’s a real regulatory risk there because Google’s paying Apple $20 billion a year to be the default search engine. Apple also has a very deep relationship with China they have a lot of manufacturing being done in China and they sell a lot of product into China. So as Regulators start to take a harder look as they said they’re going to at companies relationships with China that’s a real risk to Apple. Advertising tracking users and then the subscription fees that are charged to Consumers and most importantly we’ve talked a lot about the 30% Vig that Apple takes on their App Store and how Regulators are now stepping in and take a look at this. So because this business is not yet a regulated Monopoly it may be a monopoly in many senses of the world it’s not regulated yet. And that transition could be financially painful for Apple once they get to the other side it starts to look a lot more like a large scale Burkshire type business. So that that’s my kind of summary take on what’s going on with apple.  - David Friedberg</em></p>
<p><em>There’s very little kind of editorialization going on with respect to showing the rankings of the new sources. The ranking of the new sources is typically set by some ranking algorithm. The algorithm is usually around click-throughs views popularity of the sites, how many visitors there are, so there are other metrics that drive the order. So for example if NBC CNN Fox News all have kind of higher rankings than some smaller publication, they’re going to end up Hing the the ranking algorithm, because they have a higher quality score. There’s also measures on how often people click through and come back, the bounceback rate, so if they click through an article and then come back that can actually reduce the ranking versus if they click through and stay on the site. So there’s a lot of factors that go into the ranking algorithm. The thing that probably upsets people is that there isn’t any transparency into this, so there’s no understanding on how these things are ranked, how they’re set, and it’s probably very good guidance and feedback that there should be more transparency and openness. And I’m not necessarily trying to defend anyone’s product or behavior, I’m just saying that there’s a certainly a lack of understanding on why one thing is being shown versus another. I’ll also say Sach there’s probably the case or there might be the case that there’s many more sites potentially putting out pro Harris articles, and there are putting out pro Trump articles which can start to overweight the the algorithm as you know or overweight the rankings that are showing up. So that might also be feeding into this that that the general news media bias is what you’re actually seeing versus a Google bias. - David Friedberg</em></p>
<p><em>I just want to show you one chart because important for you to understand the number of people in journalism. This is from 1971 to 2022 who say the identifying Republican has just absolutely plummeted. I know this and this is what I’m trying to explain to you Sacks, is a incredible opportunity for your party since you know you’re passionate about this is to invest in more journalism, invest in more journalists, because I don’t buy this Independence the fact that they’re claiming they’re independent in journalism. I believe that’s cap I believe they say that the Gap is 33% now between people who say they’re Democrats and people who say they’re Republican in journalism that is a key piece to this problem. And layered on top of it, I agree with you that Google is filled with liberal people, and I agree with you Chamath, that they need to intervene and put at the top of the search results in news. These are the you know this is what we’re indexing, this is the percentage that’s left leaning, this is the percentage that’s right leaning, and there are a lot of organizations that examine and rate Publications on their bias left and right, And that’s something that Google could do that’s very unique and that could move the whole show that you’re saying which is they could showcase that up top. So to my friends at Google who are listening do a better job of just being more transparent, so we don’t have this tension in society. - Jason Calacanis</em></p>
<p><strong>― Yen Carry Trade, Recession odds grow, Buffett cash pile, Google ruled monopoly, Kamala picks Walz - All-in Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=LRKDisV_pcI">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Ross Taylor on LLM reasoning, Llama fine-tuning, Galactica, agents - Interconnects AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=KNsnarhMZRo&feature=youtu.be">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Interviewing Sebastian Raschka on the state of open LLMs, Llama 3.1, and AI education - Interconnects AI</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=-q79uzz1Wik">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Here you can see that their (Starbucks) net revenue growth was only 1% year-over-year, but their operating margin’s been on the decline, so they have not really been able to boost their operating margin very much in the past 5 years. So while they’ve raised prices, they’ve had a really hard time making more money and that’s because the cost of food and the cost of Labor and the cost of rent, and the capital expenditures needed to upgrade stores has far exceeded the ability for them to grow revenue and compete. And now revenue is flatlining because consumers are getting tapped out with respect to how much they can spend and there’s only so much Innovation you can really do to charge more, get people to come in the store more and drive up revenue. - David Friedberg</em></p>
<p><em>Brian Nickel has an incredible reputation prior to Chipotle. He ran Taco Bell and he ran Taco Bell for several years and made it one of the most profitable Quick Serve Restaurants (QSR) in the world. He did this by focusing on every nickel. He is notorious for being a Cost Cutter, for being an efficiency driver, for being a productivity Hound. He goes into the business and he figures out every step in the supply chain, every step of the operating activities of the employee in the stores. So he was recruited heavily. I don’t know if you guys remember Chipotle’s founder was running Chipotle and at the time there was a lot of investor activism around Chipotle because they were wasting money like no one’s business. The guy had a private Jet, he was flying his management team back and forth between Denver and New York. They were spending money on crazy projects. And the board fired the CEO founder of Chipotle, brought in Nickel. Nickel came in and made Chipotle an incredibly profitable growing business. And the expectation is he’ll come and do the same here that maybe over the years Starbucks’s success has bred laziness. Starbucks’s success has bred fat slowness productivity decline, and that this guy is the right guy to come in and find all the nickels. And Brian Nichol is probably the right guy which is why you’re seeing the stock kind of rally as hard as it has. - David Friedberg</em></p>
<p><em>But the thing about Starbucks is they realized early on that when you can customize a consumer experience, the consumer comes back more frequently. So when you see your name written on that cup, you feel like you’re getting your product, you’re not buying an off-the-shelf product, you’re getting a custom personalized experience. What that led to is people customizing their drinks and what did they find that they liked when they customized their drinks sugary sweet add-ons. And then that became more and more of the standard menu and then that just kept evolving. And that’s just the consumer feedback mechanism working which is to Chamath’s point, led to 60 gram sugar drinks that are now the standard product at Starbucks, not an espresso or a cappuccino which is how they started, and it’s really unfortunate. - David Friedberg</em></p>
<p><em>So arguably I would say that trying to step in and cap prices will reduce competition, and as a result will reduce investment in improving productivity. And we have seen this countless times with every socialist experiment in human history has started with caps on food, and it has resulted in spread lines like you see in the image behind me today as we can see in Soviet Russia. This is a mistake, it is a problem, it is anti-American, it is anti-free Market, it is anti- innovation, it is anti- productivity, and ultimately it’s anti- liberty and I cannot stand it. - David Friedberg</em></p>
<p><em>To support your point, and what Chamath was messaging on our chat, look at Walmart stocks up 7% today, because they offer lower priced solutions to consumers, and Dollar General and Dollar Tree are rallying as well, when the market competes, consumers benefit, and there are companies that will win. And the companies that try to price gouge, and the companies that try to charge too much will lose. Starbucks has been trying to charge too much for sugar water, they have a real problem they are now tackling. Walmart is trying to bring value to consumers, they are winning. That is how free markets work. When the government steps in and says here’s how much margin you can make or here’s how much prices should be, it ruins everything, and the entire incentive structure goes away, and you end up with breadlines. - David Friedberg</em></p>
<p><strong>― Break up Google, Starbucks CEO out, Kamala’s price controls, Boeing disaster, Kursk offensive - All-in Podcasts</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xA5B6quoahY">Link</a>] </p>
</blockquote>
<h3 id="Paper-and-Reports"><a href="#Paper-and-Reports" class="headerlink" title="Paper and Reports"></a>Paper and Reports</h3><blockquote>
<p><strong>Gradient Boosting Reinforcement Learning</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.08250v1">Link</a>]</p>
</blockquote>
<p>Gradient-Boosting RL (GBRL) brings the advantages of GradientBoosting Trees (GBT) to reinforcement learning. </p>
<blockquote>
<p><strong>SpreadsheetLLM: Encoding Spreadsheets for Large Language Models</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09025">Link</a>]</p>
</blockquote>
<p>A great paper that outlines how you can turn a spreadsheet into a representation that is useful to a modern LLM. This can be used for Q&#x2F;A, formatting, and other data operations.</p>
<blockquote>
<p><strong>OpenAI Revenue</strong> [<a target="_blank" rel="noopener" href="https://futuresearch.ai/openai-revenue-report">Link</a>] </p>
</blockquote>
<blockquote>
<p><strong>The Llama 3 Herd of Models - Meta Research</strong> [<a target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">Link</a>]</p>
</blockquote>
<p>This is a 92 pages paper, a comprehensive guide for LLM researchers and engineers.</p>
<blockquote>
<p><strong>SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09413v1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>KAN or MLP: A Fairer Comparison</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.16674">Link</a>]</p>
</blockquote>
<p>Controlled study finds MLP generally outperforms KAN across various tasks. MLP outperformed KAN in machine learning (86.16% vs. 85.96%), computer vision (85.88% vs. 77.88%), NLP (80.45% vs. 79.95%), and audio processing (17.74% vs. 15.49%). KAN excelled only in symbolic formula representation (1.2e-3 RMSE vs. 7.4e-3). </p>
<blockquote>
<p><strong>NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.11963">Link</a>]</p>
</blockquote>
<p>The problem of current evaluation methods is that they are inadequate for assessing LLM performance on long context, however reasoning on long texts becomes more and more demanded. So they present a framework called NeedleBench for evaluating the long-context capabilities of LLMs across extensive text lengths. By some experiments, they find that current LLMs are struggling with complex reasoning tasks when it comes to long texts, showing a potential improvement room for LLMs.</p>
<blockquote>
<p><strong>Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.16833">Link</a>]</p>
</blockquote>
<p>This study investigates how large language models handle question-answering tasks under two conditions: when they receive comprehensive context information (long-context) versus when they are given only selected chunks of the necessary information (RAG). It shows that long context surpasses RAG significantly for Gemini-1.5-Pro, GPT-4O and GPT-3.5-Turbo. </p>
<blockquote>
<p><strong>A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.12994v2">Link</a>]</p>
</blockquote>
<p>This paper summarizes 38 prompt engineering techniques for LLM reasoning and lists the types of problems and datasets they have been used with.</p>
<blockquote>
<p><strong>Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.13121">Link</a>]</p>
</blockquote>
<p>This paper explores the capabilities of long-context language models (LCLMs) in handling tasks traditionally dependent on external tools like retrieval systems, RAG (Retrieval-Augmented Generation), and SQL databases. It reveals that LCLMs, such as Gemini 1.5 Pro, GPT-4o, and Claude 3 Opus, can perform competitively with specialized models in tasks like retrieval and RAG. In particular, at the 128k token context length, LCLMs rival the performance of state-of-the-art retrieval systems and even surpass some multi-modal retrieval models. However, LCLMs struggle significantly with more complex tasks requiring multi-hop compositional reasoning, such as SQL-like tasks. The findings also highlight the importance of prompt design, as performance can vary greatly depending on the prompting strategies used.</p>
<blockquote>
<p><strong>Apple Intelligence Foundation Language Models - Apple</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.21075">Link</a>]</p>
</blockquote>
<p>This report describes the architecture, the data used to train the model, the training process, how the models are optimized for inference, and the evaluation results, for the foundation language model developed to power Apple Intelligence features.</p>
<p>Notice that Apple includes the fundamentals of their RL methods, including a different type of soft margin loss for the reward model, regularizing binary preferences with absolute scores, their rejection sampling algorithm (iTeC) that is very similar to Meta’s approach, and their leave-one-out Mirror Descent RL algorithm, MDLOO. </p>
<blockquote>
<p><strong>Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.07666v1">Link</a>]</p>
</blockquote>
<p>This survey provides an in-depth review of model merging techniques, an increasingly popular method in machine learning that doesn’t require raw training data or expensive computation. </p>
<blockquote>
<p><strong>Causal Agent based on Large Language Model</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.06849v1">Link</a>]</p>
</blockquote>
<p>Causal Agent is an agent framework equipped with tools, memory, and reasoning modules to handle causal problems. </p>
<blockquote>
<p><strong>Transformer Explainer</strong> [<a target="_blank" rel="noopener" href="https://poloclub.github.io/transformer-explainer">Link</a>] [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.04619">Paper</a>]</p>
</blockquote>
<p>Interactive visualization tool designed for non-experts to learn about Transformers.</p>
<blockquote>
<p><strong>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery - Sakana.AI</strong> [<a target="_blank" rel="noopener" href="https://sakana.ai/ai-scientist/">Link</a>]</p>
</blockquote>
<h3 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h3><blockquote>
<p><strong>Multimodal Report Generation Agent - Llamaindex</strong> [<a target="_blank" rel="noopener" href="https://github.com/run-llama/llama_parse/blob/main/examples/multimodal/multimodal_report_generation_agent.ipynb">Link</a>]</p>
</blockquote>
<h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Google has an illegal monopoly on search, judge rules. Here’s what’s next - CNN</strong> [<a target="_blank" rel="noopener" href="https://amp-cnn-com.cdn.ampproject.org/c/s/amp.cnn.com/cnn/2024/08/05/business/google-loses-antitrust-lawsuit-doj">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Berkshire Hathaway sells off large share of Apple and increases cash holdings - The Guardian</strong> [<a target="_blank" rel="noopener" href="https://www.theguardian.com/business/article/2024/aug/03/berkshire-hathaway-warren-buffett-sells-off-apple-increases-cash-holdings">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Having accurate, reliable benchmarks for AI models matters, and not just for the bragging rights of the firms making them. Benchmarks “define and drive progress”, telling model-makers where they stand and incentivising them to improve, says Percy Liang of the Institute for Human-Centred Artificial Intelligence at Stanford University. Benchmarks chart the field’s overall progress and show how AI systems compare with humans at specific tasks. They can also help users decide which model to use for a particular job and identify promising new entrants in the space, says Clémentine Fourrier, a specialist in evaluating LLMs at Hugging Face, a startup that provides tools for AI developers.</em></p>
<p><strong>― GPT, Claude, Llama? How to tell which AI model is best - The Economist</strong> [<a target="_blank" rel="noopener" href="https://www.economist.com/science-and-technology/2024/07/31/gpt-claude-llama-how-to-tell-which-ai-model-is-best">Link</a>]</p>
</blockquote>
<p>Current benchmark MMLU (massive multi-task language understanding) has a few problems: 1) too easy for today’s models leading to the problem of ‘saturation’. New alternatives are developed such as MMLU-Pro, GPQA, MUSR, etc, 2) training data comes from internet which is a source of questions and answers for MMLU, resulting in a problem called “contamination”, 3) answers in MMLU tests are sometimes wrong or correct answers are more than one, 4) small changes in the way questions are posed to models can significantly affect their scores.</p>
<p>There are some trustworthy automated testing systems other than ChatBotArena leaderboard: HELM (holistic evaluation of language models) built by Dr Liang’s team at Stanford, and EleutherAI Harness uses by Dr Fourrier’s teams at Hugging Face for open source models.</p>
<p>As model gain new skills, new benchmarks are being developed to assess them. For example, GAIA tests model on real world problem solving, NoCha provides novel challenge, etc. However, new benchmarks are expensive to develop because they require human experts to create a detailed set of questions and answers. Dr Liang is working on project AutoBencher, Anthropic started funding the creation of benchmarks with a focus of AI safety.</p>
<blockquote>
<p><strong>GPT-4o mini: advancing cost-efficient intelligence - OpenAI News</strong> [<a target="_blank" rel="noopener" href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/">Link</a>]</p>
</blockquote>
<p>GPT-4o is small and intelligent. It’s probably distilled from current or unreleased version of OpenAI’s models, similar to what Claude did with Claude Haiku and Google with Gemini Flash.</p>
<blockquote>
<p><strong>Made by Google 2024: Pixel 9, Gemini, a new foldable and other things to expect from the event - TechCrunch</strong> [<a target="_blank" rel="noopener" href="https://techcrunch.com/2024/08/06/made-by-google-2024-pixel-9-gemini-a-new-foldable-and-other-things-to-expect-from-the-event/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>MIT releases comprehensive database of AI risks - VentureBeat</strong> [<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/mit-releases-comprehensive-database-of-ai-risks/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Apple will let other digital wallets into Apple Pay, and even be the default - ars technica</strong> [<a target="_blank" rel="noopener" href="https://arstechnica.com/gadgets/2024/08/apple-will-let-other-digital-wallets-into-apple-pay-and-even-be-the-default/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Apple Aiming to Launch Tabletop Robotic Home Device as Soon as 2026 With Pricing Around $1,000</strong> [<a target="_blank" rel="noopener" href="https://www.macrumors.com/2024/08/14/apple-tabletop-robotic-home-device-2026/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Sakana AI’s ‘AI Scientist’ conducts research autonomously, challenging scientific norms - VentureBeat</strong> [<a target="_blank" rel="noopener" href="https://venturebeat.com/ai/sakana-ai-scientist-conducts-research-autonomously-challenging-scientific-norms/">Link</a>]</p>
</blockquote>
<p>Sakana AI unveils world’s first fully automatic ‘AI-Scientist’ generating complete research papers.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/digital-di/tags/readings/" rel="tag"># readings</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/digital-di/2024/08/11/The-Wisdom-of-the-Bullfrog/" rel="prev" title="The Wisdom of the Bullfrog">
                  <i class="fa fa-angle-left"></i> The Wisdom of the Bullfrog
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/digital-di/js/comments.js"></script><script src="/digital-di/js/utils.js"></script><script src="/digital-di/js/motion.js"></script><script src="/digital-di/js/schemes/muse.js"></script><script src="/digital-di/js/next-boot.js"></script>

  






  





</body>
</html>
