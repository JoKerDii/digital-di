<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/digital-di/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/digital-di/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/digital-di/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/digital-di/images/logo.svg" color="#222">

<link rel="stylesheet" href="/digital-di/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/digital-di/","images":"/digital-di/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/digital-di/js/config.js"></script>

    <meta name="description" content="News Intel Inside Ohio [Link] Intel Ohio One Campus Video Rendering [Link]  Intel Corp has committed $28B to build a “mega fab” called Ohio One which could be the biggest chip factory on Earth. The Bi">
<meta property="og:type" content="article">
<meta property="og:title" content="2024 May">
<meta property="og:url" content="https://jokerdii.github.io/digital-di/2024/05/04/2024-May/index.html">
<meta property="og:site_name" content="Digital Di">
<meta property="og:description" content="News Intel Inside Ohio [Link] Intel Ohio One Campus Video Rendering [Link]  Intel Corp has committed $28B to build a “mega fab” called Ohio One which could be the biggest chip factory on Earth. The Bi">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-05-04T13:08:51.000Z">
<meta property="article:modified_time" content="2024-05-07T03:49:23.468Z">
<meta property="article:author" content="Di Zhen">
<meta property="article:tag" content="readings">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jokerdii.github.io/digital-di/2024/05/04/2024-May/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jokerdii.github.io/digital-di/2024/05/04/2024-May/","path":"2024/05/04/2024-May/","title":"2024 May"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>2024 May | Digital Di</title>
  








  <noscript>
    <link rel="stylesheet" href="/digital-di/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/digital-di/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Digital Di</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#News"><span class="nav-number">1.</span> <span class="nav-text">News</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Substack"><span class="nav-number">2.</span> <span class="nav-text">Substack</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Articles"><span class="nav-number">3.</span> <span class="nav-text">Articles</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YouTube"><span class="nav-number">4.</span> <span class="nav-text">YouTube</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Papers-and-Reports"><span class="nav-number">5.</span> <span class="nav-text">Papers and Reports</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/digital-di/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/digital-di/2024/05/04/2024-May/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/digital-di/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Digital Di">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="2024 May | Digital Di">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2024 May
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-05-04 09:08:51" itemprop="dateCreated datePublished" datetime="2024-05-04T09:08:51-04:00">2024-05-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-05-06 23:49:23" itemprop="dateModified" datetime="2024-05-06T23:49:23-04:00">2024-05-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h3 id="News"><a href="#News" class="headerlink" title="News"></a>News</h3><blockquote>
<p><strong>Intel Inside Ohio</strong> [<a target="_blank" rel="noopener" href="https://www.bloomberg.com/features/2024-intel-comeback-chipmaking/">Link</a>]</p>
<p>Intel Ohio One Campus Video Rendering [<a target="_blank" rel="noopener" href="https://vimeo.com/939198943">Link</a>]</p>
</blockquote>
<p>Intel Corp has committed $28B to build a “mega fab” called Ohio One which could be the biggest chip factory on Earth. The Biden administration has agreed to provide Intel with $19.5B in loans and grants to support finance the project.</p>
<blockquote>
<p><strong>EveryONE Medicines: Designing Drugs for Rare Diseases, One at a Time</strong> [<a target="_blank" rel="noopener" href="https://www.wsj.com/articles/everyone-medicines-designing-drugs-for-rare-diseases-one-at-a-time-a6f98afc">Link</a>]</p>
</blockquote>
<p>Startup EveryONE Medicine aims to develop drugs designed based on genetic information for individual children who have rare, life-threatening neurological diseases. Since the number of patients with diseases caused by rare mutation is significant, the market share is large if EveryONE can scale its process. Although the cost won’t be the same as a standard drugmaker that runs large clinical trials, the challenge is safety without a standard clinical-testing protocol. To be responsible to patients, the initial drugs will have a temporary effect and a wide therapeutic window, so the potential toxicity will be minimized or stopped if there is.</p>
<blockquote>
<p><strong>Voyager 1’s Communication Malfunctions May Show the Spacecraft’s Age</strong> [<a target="_blank" rel="noopener" href="https://www.discovermagazine.com/the-sciences/voyager-1s-communication-malfunctions-may-show-the-spacecrafts-age">Link</a>]</p>
</blockquote>
<p>In Nov 2023, NASA’s over 46-year-old Voyager 1 spacecraft started sending nonsense to Earth. Voyager 1 was initially intended to study Jupiter and Saturn and was built to survive only 5 years of flight, however the trajectory was forged further and further into space and so the mission converted from a two-planet mission to an interstellar mission.</p>
<p>In Dec 2023, the mission team restarted the Flight Data Subsystem (FDS)  but failed to return the subsystem to functional state. On Mar 1 2023, they sent a command “poke” to the probe and received a response on Mar 3. On Mar 10, the mission team finally determined the response carried a readout of FDS memory. By comparing the readout with those received before the issue, the team confirmed that 3% of FDS memory was corrupted. On Apr 4, the team concluded the affected code was contained on a computer chip. To solve the problem, the team decided to divide these affected code into smaller sections and to insert those smaller sections into other operative places in the FDS memory. During Apr 18-20, the team sent out the orders to move some of the affected code and received responses with intelligible systems information. </p>
<blockquote>
<p><strong>Encampment Protesters Set Monday Deadline for Harvard to Begin Negotiations</strong> [<a target="_blank" rel="noopener" href="https://www.thecrimson.com/article/2024/5/3/yard-encampment-negotiation-deadline/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Israel Gaza war: History of the conflict explained</strong> [<a target="_blank" rel="noopener" href="https://www.bbc.com/news/newsbeat-44124396">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Editing the Human Genome with AI</strong> [<a target="_blank" rel="noopener" href="https://www.profluent.bio/blog/editing-the-human-genome-with-ai">Link</a>]</p>
</blockquote>
<p>Berkeley based startup Profluent Bio used an AI based protein language model to create and train on an entirely new library of Cas proteins that do not exist in nature today and eventually find one called ‘OpenCRISPR-1’ that is able to replace or improve the ones that are on the market today. The goal of this AI model is to learn what sequence of DNA generated what structure of protein that’s really good at gene editing. The new library of Cas proteins is created by simulation of trillions of letters. They made ‘OpenCRISPR-1’ publicly available under an open source license so anyone can use this particular Cas protein.</p>
<h3 id="Substack"><a href="#Substack" class="headerlink" title="Substack"></a>Substack</h3><blockquote>
<p><em>To me, the best model going forward is going to be based on the <strong>weighted performance per parameter and training token count.</strong> Ultimately, a model keeps getting better the longer you train it. Most open model providers could train longer, but it hasn’t been worth their time. We’re starting to see that change.</em></p>
<p><em><strong>The most important models will represent improvements in capability density</strong>, rather than shifting the frontier.</em></p>
<p><em>In some ways, it’s easier to make the model better by training longer compared to anything else, if you have the data.</em></p>
<p><em>The core difference between open and closed LLMs on these charts is <strong>how undertrained open LLMs often are</strong>. The only open model confirmed to be trained on a lot of tokens is DBRX.</em> </p>
<p><strong>―  The End of the “Best Open LLM”</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/compute-efficient-open-llms?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>Good analysis of the direction of open LLM development in 2023 and 2024. In 2023, models were progressing in MMLU by leveraging more compute budgets to handle scaled active parameters and training tokens. In 2024, the progressing direction is slightly changed to be orthogonal to previous - which is improving on MMLU while keeping compute budgets constant.</p>
<blockquote>
<p><em>The companies that have users interacting with their models consistently have moats through data and habits. The models themselves are not a moat, as I discussed at the end of last year when I tried to <a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/ml-moats">predict machine learning moats</a>, but there are things in the modern large language model (LLM) space that open-source will really struggle to replicate. Concretely, that difference is access to quality and diverse training prompts for fine-tuning. While I want open-source to win out for personal philosophical and financial factors, this obviously is not a walk in the park for the open-source community. It’ll be a siege of a castle with, you guessed it, a moat. We’ll see if the moat holds.</em></p>
<p><strong>―  Model commoditization and product moats</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/gpt4-commoditization-and-moats">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>The goal of promoting scientific understanding for the betterment of society has a long history. Recently I was pointed to the essay <a target="_blank" rel="noopener" href="https://www.ias.edu/sites/default/files/library/UsefulnessHarpers.pdf">The Usefulness of Useless Knowledge</a> by Abraham Flexner in 1939 which argued how basic scientific research without clear areas for profit will eventually turn into societally improving technologies. If we want LLMs to benefit everyone, my argument is that we need far more than just computer scientists and big-tech-approved social scientists working on these models. We need to continue to promote openness to support this basic feedback loop that has helped society flourish over the last few centuries.</em></p>
<p><em>The word openness has replaced the phrase open-source among most leaders in the open AI movement. It’s the easiest way to get across what your goals are, but it is not better in indicating how you’re actually supporting the open ecosystem. The three words that underpin the one messy word are <strong>disclosure</strong> (the details), <strong>accessibility</strong> (the interfaces and infrastructure), and <strong>availability</strong> (the distribution).</em></p>
<p><strong>―  We disagree on what open-source AI should mean</strong> [<a target="_blank" rel="noopener" href="https://www.interconnects.ai/p/flavors-of-open-source-ai?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Google: “A Positive Moment”</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/alphabet-a-positive-moment?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>The report of Google Search’s death is exaggerated so far. In fact, search advertising has grown faster at Google than at Microsoft. User searching behavior is harder to change than people expected. Also, Google is leading the development of AI powered tools for Search: 1) “circle to search” is feature allowing a search from an image, text, or video without switching apps. 2) “Point your camera, ask a question” is a feature allowing for multisearch with both images and text for complex questions given an image to the tool. Overall, SGE (Search Generative Experience) is revolutionizing search experience (“10 blue links”) by  introducing a dynamic AI-enhanced experience. So far from I observed AI powers Google Search rather than weakens it.</p>
<blockquote>
<p><strong>Amazon: Wild Margin Expansion</strong> [<a target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/amazon-wild-margin-expansion?utm_source=profile&utm_medium=reader2">Link</a>]</p>
</blockquote>
<p>Amazon’s margin expansion: AWS hit $100 B run rate with a 38% operating margin; Ads is surging; delivery costs have been reduced.</p>
<h3 id="Articles"><a href="#Articles" class="headerlink" title="Articles"></a>Articles</h3><blockquote>
<p><strong>The tech industry can’t agree on what open-source AI means. That’s a problem. ― MIT Technology Review</strong> [<a target="_blank" rel="noopener" href="https://www.technologyreview.com/2024/03/25/1090111/tech-industry-open-source-ai-definition-problem/">Link</a>]</p>
</blockquote>
<p>This article argues that the definitions of open-source AI are problematic. Without change in the current trajectory, big tech will define open-source AI to be what suits it.</p>
<blockquote>
<p><strong>Everything I know about the XZ backdoor</strong> [<a target="_blank" rel="noopener" href="https://boehs.org/node/everything-i-know-about-the-xz-backdoor">Link</a>]</p>
<p>Some great high-level technical overview of XZ backdoor [<a target="_blank" rel="noopener" href="https://gynvael.coldwind.pl/?lang=en&id=782">Link</a>] [<a target="_blank" rel="noopener" href="https://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27">Link</a>] [<a target="_blank" rel="noopener" href="https://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27">Link</a>] [<a target="_blank" rel="noopener" href="https://infosec.exchange/@fr0gger/112189232773640259">Infographic</a>] [<a target="_blank" rel="noopener" href="https://research.swtch.com/xz-script">Link</a>] [<a target="_blank" rel="noopener" href="https://bsky.app/profile/filippo.abyssdomain.expert/post/3kowjkx2njy2b">Link</a>]</p>
</blockquote>
<p>A backdoor in xz-utils (used for lossless compression) was recently revealed by Andres Freund (Principle SDE at Microsoft). The backdoor only shows up when a few specific criteria are met at least: 1) running a distro that uses glibc, 2) have version 5.6.0 or 5.6.1 xz installed or liblzma installed. There is a malicious script called <code>build-to-host.m4</code> which checks for various conditions like the architecture of the machine. If those conditions check, the payload is injected into the source tree. The intention of payload is still under investigation. Lasse Collin, one of the maintainer of the repo, has posted an <a target="_blank" rel="noopener" href="https://tukaani.org/xz-backdoor/">update</a> and is working on carefully analyzing the situation. The author Evan Boehs in the article present a timeline of the attack and online investigators’ discoveries of Jia Tan identity (from IP address, LinkedIn, <a target="_blank" rel="noopener" href="https://rheaeve.substack.com/p/xz-backdoor-times-damned-times-and">commit timings</a>, etc), and raises our awareness of the human costs of open source.</p>
<h3 id="YouTube"><a href="#YouTube" class="headerlink" title="YouTube"></a>YouTube</h3><blockquote>
<p><em>I don’t have an answer to peace in the Middle East, I wish I did, but I do have a very strong view that we are not going to get to peace when we are apologizing or denying crimes against humanity and crime mass rape of women. That’s not the path to peace, the path to peace is not saying this didn’t happen, the path to peace is saying this happened no matter what side of the fence you are on no matter what side of the world you are on, if you are the far right the far left, anywhere on the world, we are not going to let this happen again and we are going to get to peace to make sure.  - Sheryl Sandberg</em></p>
<p><strong>In conversation with Sheryl Sandberg, plus open-source AI gene editing explained</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OxbtNsenZJY&ab_channel=All-InPodcast">Link</a>]</p>
<p>U.N. to Study Reports of Sexual Violence in Israel During Oct. 7 Attack [<a target="_blank" rel="noopener" href="https://www.nytimes.com/2024/01/29/world/middleeast/israel-hamas-sexual-violence-un.html">Link</a>]</p>
<p>Western media concocts ‘evidence’ UN report on Oct 7 sex crimes failed to deliver [<a target="_blank" rel="noopener" href="https://thegrayzone.com/2024/03/07/media-concocts-un-hamas-rape-report/">Link</a>]</p>
</blockquote>
<p>It’s crazy that what is happening right now in some of the colleges is not to protest sexual violence as a tool of war by Hamas. This kind of ignorance or denial of sexual violence is horrible. People are so polarized to black and white that if something does not fit into their view, they are going to reject it. There are more than two sides to the Middle East story, one of them is sexual violence - mass rape, genital mutilation of men and women, women tied to trees naked bloody leg spread…</p>
<p>There is a long history of the involvement of women’s bodies in Wars. It’s only 30 years ago, people started to say rape is not a tool of War and should be prosecuted as a war crime against humanity. The feminist, human rights, and civil rights groups made this happen. Now it happened again in Gaza according to the report released by U.N., however there are a lot difficulties in proving and testifying the truth e.g. they couldn’t locate a single victim, or they don’t have the victim rights to take pictures. But victims are dead and they cannot speak up. Denying the fact of sexual violence is just unacceptable. And there is such a great <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=zAr9oGSXgak&ab_channel=ScreamsBeforeSilence">documentary</a> shedding lights on the unspeakable sexual violence committed on Oct 7, 2023 that I think everyone should watch.</p>
<p>Good news is that the testimony of eyewitness meets the criteria of any international or global court. So crimes can be proven by any eyewitness for sure.</p>
<blockquote>
<p><strong>John Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=hhiLw5Q_UFg&ab_channel=BerkeleyEECS">Link</a>]</p>
</blockquote>
<p>John Schulman is a research scientist and cofounder of OpenAI, focusing on Reinforcement Learning (RL) algorithms. He gave a talk on making AI more truthful on Apr 24, 2023 in UCB. The ideas and discussions are still helpful and insightful today.</p>
<p>In this talk, John discussed the issue of hallucination with large language models. He claims that behavior cloning or supervised learning is not enough to fix the hallucination problem, instead, reinforcement learning from human feedback (RLHF) can help improve the model’s truthfulness by 1) adjusting output distribution so model is allowed to express uncertainty, challenge premise, admit error, and 2) learning behavior boundaries. In his conceptual model, fine-tuning leads the model to hallucinate when it lacks knowledge. Retrieval and citing external sources can help improve verifiability. John discusses models that can browse the web to answer technical questions, citing relevant sources. </p>
<p>John mentioned three open problems in LLM: 1) how to train models to express uncertainty in natural language, 2) go beyond what human labelers can easily verify (“scalable oversight”), and 3) optimizing for true knowledge rather than human approval.</p>
<blockquote>
<p><strong>The 1-Year Old AI Startup That’s Rivaling OpenAI —  Redpoint’s AI Podcast</strong> [<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=_N2KPEdh69s&ab_channel=UnsupervisedLearning:Redpoint%27sAIPodcast">Link</a>]</p>
</blockquote>
<p>A great interview with the CEO of Mistral Arthur Mensch on the topic of sovereignty and open models as a business strategy. Here are some highlighted points from Arthur:</p>
<ol>
<li>Open-source is going to solidify in the future. It is an infrastructure technology and at the end of the day it should be modifiable and owned by customers. Now Mistral has two offerings, open source one and commercial one, and the aim is to find out the business model to sustain the open source development.</li>
<li>The things that Mistral is best at 1) training model, and 2) specializing models. </li>
<li>The way they think about partnership strategy is to look at what enterprises would need, where they were operating, where the developers were operating, and figure out the channels that would facilitate adoption and spread. To be a multiplatform solution and to replicate the solution to different platforms is a strategy that Mistral is following.</li>
<li>There is still an efficiency upper bound to be pushed. Other than compute to spend on pre-training, there is still research to do on improving model efficiency and strength. On architecture side, we can be more efficient than plain Transformer which spends same amount of compute on every token. Mistral is making model faster. By making model faster, we open up a lot of applications that involve an LLM as a basic brick and then we can figure out how to do planning, explorations, etc. By increasing efficiency, we open up areas of research.</li>
<li>Meta has more GPUs than Mistral do. But Mistral has a good concentration of GPU (number of GPU per person). This is the way to be as efficient as possible to come up with creative ways of training models. Also unit economics need to be considered to make sure that $1 that you spend on training compute eventually accrues to more than $1 revenue.</li>
<li>Transformer is not an optimal architecture. It’s been out there for 7 years now. Everything is co-adapted to it such as training methods, debug methods, the algorithms, and hardware. It’s challenging to find a better one and also beat the baseline. But there are a lot of research on modification of attention to boost memory efficiencies and a lot of things can be done in that direction and similar directions.</li>
<li>About AI regulations and EU AI Act, Arthur states that it does not solve the actual problem of how to make AI safe. Because making AI safe is a hard problem (stochastic model), different from the way we evaluate software before. It’s more like a product problem rather than a regulation problem. We need to rethink continuous integration, verifications, etc and make sure everything is happening as it should be.</li>
<li>Mistral recently released Le Chat to help enterprise start incorporating AI. It gives an assistant that is contextualized on their enterprise data. It’s a tool to be closer to the end user to get feedback for the developer platform and also a tool to get the enterprise into GenAI.</li>
</ol>
<blockquote>
<p><strong>Open Source AI is AI we can Trust — with Soumith Chintala of Meta AI</strong> [<a target="_blank" rel="noopener" href="https://www.latent.space/p/soumith">Link</a>]</p>
</blockquote>
<p>Synthetic data is the next rage of LLM. Soumith pointed out that synthetic data is where we as humans already have good symbolic models off, we need to impart that knowledge to neural networks, and we figured out the synthetic data is a vehicle to impart this knowledge to it. Related to synthetic data but in an unusual way, there is new research on distilling GPT-4 by creating synthetic data from GPT-4, creating mock textbooks inspired by Phi-2 and then fine tuning open source models like Lambda.  </p>
<p>Open source means different things to different people and we haven’t had a community norm definition yet at this very early stage of LLM. When being asked about open source, people in this field are used to highlight the definition of it in advance. In the open source topic, Soumith pointed out that the most beneficial value of open is it makes the distribution very wide and available with no friction so that people can do transformative things in a way that is very accessible. </p>
<h3 id="Papers-and-Reports"><a href="#Papers-and-Reports" class="headerlink" title="Papers and Reports"></a>Papers and Reports</h3><blockquote>
<p><strong>Little Guide to Building Large Language Models in 2024 - HuggingFace</strong> [<a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/1IkzESdOwdmwvPxIELYJi8--K3EZ98_cL6c5ZcLKSyVg/edit?usp=sharing">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.05862">Link</a>]</p>
</blockquote>
<p>Bloomberg fine-tuned GPT-3.5 on their financial data only to find that GPT-4 8k, without specialized finance fine-tuning, beat it on almost all finance tasks. So there is really a moat?</p>
<blockquote>
<p><strong>Jamba: A Hybrid Transformer-Mamba Language Model</strong> [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.19887">Link</a>] [<a target="_blank" rel="noopener" href="https://www.ai21.com/blog/announcing-jamba">Link</a>]</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=AL1fq05o7H">Mamba paper</a> has been rejected while fruits are reaped fast: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.04081">MoE-Mamba</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.09417">Vision Mamba</a>, and Jamba. It’s funny to see the asymmetric impact in ML sometimes, e.g. FlashAttention has &lt;500 citations and is used everywhere. Github repos used by 10k+ has &lt;100 citations, etc.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/digital-di/tags/readings/" rel="tag"># readings</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/digital-di/2024/04/30/2024-April/" rel="prev" title="2024 April">
                  <i class="fa fa-angle-left"></i> 2024 April
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/digital-di/js/comments.js"></script><script src="/digital-di/js/utils.js"></script><script src="/digital-di/js/motion.js"></script><script src="/digital-di/js/schemes/muse.js"></script><script src="/digital-di/js/next-boot.js"></script>

  






  





</body>
</html>
